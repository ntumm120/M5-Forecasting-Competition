{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,BayesianRidge, Lasso\n",
    "from statistics import mean\n",
    "from math import sqrt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import Input, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    calendar = pd.read_csv('calendar.csv')\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar.shape[0], calendar.shape[1]))\n",
    "    sell_prices = pd.read_csv('sell_prices.csv')\n",
    "    sell_prices = reduce_mem_usage(sell_prices)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices.shape[0], sell_prices.shape[1]))\n",
    "    sales_train_validation = pd.read_csv('sales_train_validation.csv')\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    return calendar, sell_prices, sales_train_validation, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_and_merge(calendar, sell_prices, sales_train_validation, submission, nrows = 55000000, merge = False):\n",
    "    \n",
    "    # melt sales data, get it ready for training\n",
    "    sales_train_validation = pd.melt(sales_train_validation, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    print('Melted sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
    "    sales_train_validation = reduce_mem_usage(sales_train_validation)\n",
    "    \n",
    "    # seperate test dataframes\n",
    "    test1_rows = [row for row in submission['id'] if 'validation' in row]\n",
    "    test2_rows = [row for row in submission['id'] if 'evaluation' in row]\n",
    "    test1 = submission[submission['id'].isin(test1_rows)]\n",
    "    test2 = submission[submission['id'].isin(test2_rows)]\n",
    "    \n",
    "    # change column names\n",
    "    test1.columns = ['id', 'd_1914', 'd_1915', 'd_1916', 'd_1917', 'd_1918', 'd_1919', 'd_1920', 'd_1921', 'd_1922', 'd_1923', 'd_1924', 'd_1925', 'd_1926', 'd_1927', 'd_1928', 'd_1929', 'd_1930', 'd_1931', \n",
    "                      'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937', 'd_1938', 'd_1939', 'd_1940', 'd_1941']\n",
    "    test2.columns = ['id', 'd_1942', 'd_1943', 'd_1944', 'd_1945', 'd_1946', 'd_1947', 'd_1948', 'd_1949', 'd_1950', 'd_1951', 'd_1952', 'd_1953', 'd_1954', 'd_1955', 'd_1956', 'd_1957', 'd_1958', 'd_1959', \n",
    "                      'd_1960', 'd_1961', 'd_1962', 'd_1963', 'd_1964', 'd_1965', 'd_1966', 'd_1967', 'd_1968', 'd_1969']\n",
    "    \n",
    "    # get product table\n",
    "    product = sales_train_validation[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()\n",
    "    \n",
    "    # merge with product table\n",
    "    test2['id'] = test2['id'].str.replace('_evaluation','_validation')\n",
    "    test1 = test1.merge(product, how = 'left', on = 'id')\n",
    "    test2 = test2.merge(product, how = 'left', on = 'id')\n",
    "    test2['id'] = test2['id'].str.replace('_validation','_evaluation')\n",
    "    \n",
    "    # \n",
    "    test1 = pd.melt(test1, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    test2 = pd.melt(test2, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    \n",
    "    sales_train_validation['part'] = 'train'\n",
    "    test1['part'] = 'test1'\n",
    "    test2['part'] = 'test2'\n",
    "    \n",
    "    data = pd.concat([sales_train_validation, test1, test2], axis = 0)\n",
    "    \n",
    "    del sales_train_validation, test1, test2\n",
    "    \n",
    "    # get only a sample for fst training\n",
    "    data = data.loc[nrows:]\n",
    "    \n",
    "    # drop some calendar features\n",
    "    calendar.drop(['weekday', 'wday', 'month', 'year'], inplace = True, axis = 1)\n",
    "    \n",
    "    # delete test2 for now\n",
    "    data = data[data['part'] != 'test2']\n",
    "    \n",
    "    if merge:\n",
    "        # notebook crash with the entire dataset (maybee use tensorflow, dask, pyspark xD)\n",
    "        data = pd.merge(data, calendar, how = 'left', left_on = ['day'], right_on = ['d'])\n",
    "        data.drop(['d', 'day'], inplace = True, axis = 1)\n",
    "        # get the sell price data (this feature should be very important)\n",
    "        data = data.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "        print('Our final dataset to train has {} rows and {} columns'.format(data.shape[0], data.shape[1]))\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Sales train validation has 30490 rows and 1919 columns\n",
      "Melted sales train validation has 58327370 rows and 8 columns\n",
      "Mem. usage decreased to 3226.27 Mb (9.4% reduction)\n",
      "Our final dataset to train has 31181090 rows and 18 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "calendar, sell_prices, sales_train_validation, submission = read_data()\n",
    "\n",
    "data = melt_and_merge(calendar, sell_prices, sales_train_validation, submission, nrows = 28000000, merge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def transform(data):\n",
    "    \n",
    "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for feature in nan_features:\n",
    "        data[feature].fillna('unknown', inplace = True)\n",
    "        \n",
    "    cat = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for feature in cat:\n",
    "        encoder = LabelEncoder()\n",
    "        data[feature] = encoder.fit_transform(data[feature])\n",
    "        \n",
    "    data = reduce_mem_usage(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(data):\n",
    "    \n",
    "    data_fe = data[['id', 'demand']]\n",
    "    \n",
    "    window = 28\n",
    "    periods = [7, 14, 28, 84]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    # most recent lag data\n",
    "    for period in periods:\n",
    "        data_fe['demand_rolling_mean_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).mean())\n",
    "        data_fe['demand_rolling_std_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).std())\n",
    "        \n",
    "    # reduce memory\n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "    \n",
    "    # get time features\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    time_features = ['year', 'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear']\n",
    "    dtype = np.int16\n",
    "    for time_feature in time_features:\n",
    "        data[time_feature] = getattr(data['date'].dt, time_feature).astype(dtype)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31181090 entries, 0 to 31181089\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id            object \n",
      " 1   item_id       object \n",
      " 2   dept_id       object \n",
      " 3   cat_id        object \n",
      " 4   store_id      object \n",
      " 5   state_id      object \n",
      " 6   demand        int64  \n",
      " 7   part          object \n",
      " 8   date          object \n",
      " 9   wm_yr_wk      int16  \n",
      " 10  event_name_1  object \n",
      " 11  event_type_1  object \n",
      " 12  event_name_2  object \n",
      " 13  event_type_2  object \n",
      " 14  snap_CA       int8   \n",
      " 15  snap_TX       int8   \n",
      " 16  snap_WI       int8   \n",
      " 17  sell_price    float16\n",
      "dtypes: float16(1), int16(1), int64(1), int8(3), object(12)\n",
      "memory usage: 3.5+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "def run_lgb(data, features, cat_features):\n",
    "    \n",
    "    # reset_index\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    # going to evaluate with the last 28 days\n",
    "    x_train = data[data['date'] <= '2016-04-24']\n",
    "    y_train = x_train['demand']\n",
    "    test = data[data['date'] >= '2016-04-25']\n",
    "\n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.09,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 200,\n",
    "        'lambda_l1': 0.4,\n",
    "        'lambda_l2': 0.4}\n",
    "    \n",
    "    oof = np.zeros(len(x_train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    # GroupKFold by week, month to avoid leakage and overfitting \n",
    "    kf = GroupKFold(6)\n",
    "    \n",
    "    # get subgroups for each week, year pair\n",
    "    group = x_train['week'].astype(str) + '_' + x_train['year'].astype(str)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(x_train, y_train, group)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        train_set = lgb.Dataset(x_train.iloc[trn_idx][features], y_train.iloc[trn_idx], \n",
    "                                categorical_feature = cat_features)\n",
    "        val_set = lgb.Dataset(x_train.iloc[val_idx][features], y_train.iloc[val_idx], \n",
    "                              categorical_feature = cat_features)\n",
    "        \n",
    "        # train with custom loss function and evaluation metric\n",
    "        model = lgb.train(params, train_set, num_boost_round = 10000, early_stopping_rounds = 50, \n",
    "                          valid_sets = [train_set, val_set], verbose_eval = 20, fobj = custom_asymmetric_train, \n",
    "                          feval = custom_asymmetric_valid)\n",
    "    \n",
    "        model.save_model(\"LightGBM_CV.lgb\")\n",
    "        \n",
    "        # predict oof\n",
    "        oof[val_idx] = model.predict(x_train.iloc[val_idx][features])\n",
    "\n",
    "        # predict test\n",
    "        preds += model.predict(test[features]) / 6\n",
    "        \n",
    "        print('-'*50)\n",
    "        print('\\n')\n",
    "        \n",
    "    oof_rmse = np.sqrt(metrics.mean_squared_error(y_train, oof))\n",
    "    print(f'Our out of folds rmse is {oof_rmse}')\n",
    "        \n",
    "    test = test[['id', 'date', 'demand']]\n",
    "    test['demand'] = preds\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, submission):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.to_csv('May3rdsub.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOUSEHOLD_1_478_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_478</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOUSEHOLD_1_479_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_479</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.519531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUSEHOLD_1_480_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_480</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOUSEHOLD_1_481_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_481</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUSEHOLD_1_482_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_482</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.380859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id          item_id      dept_id     cat_id  \\\n",
       "0  HOUSEHOLD_1_478_CA_4_validation  HOUSEHOLD_1_478  HOUSEHOLD_1  HOUSEHOLD   \n",
       "1  HOUSEHOLD_1_479_CA_4_validation  HOUSEHOLD_1_479  HOUSEHOLD_1  HOUSEHOLD   \n",
       "2  HOUSEHOLD_1_480_CA_4_validation  HOUSEHOLD_1_480  HOUSEHOLD_1  HOUSEHOLD   \n",
       "3  HOUSEHOLD_1_481_CA_4_validation  HOUSEHOLD_1_481  HOUSEHOLD_1  HOUSEHOLD   \n",
       "4  HOUSEHOLD_1_482_CA_4_validation  HOUSEHOLD_1_482  HOUSEHOLD_1  HOUSEHOLD   \n",
       "\n",
       "  store_id state_id  demand   part        date  wm_yr_wk event_name_1  \\\n",
       "0     CA_4       CA       0  train  2013-08-04     11328          NaN   \n",
       "1     CA_4       CA       0  train  2013-08-04     11328          NaN   \n",
       "2     CA_4       CA       0  train  2013-08-04     11328          NaN   \n",
       "3     CA_4       CA       0  train  2013-08-04     11328          NaN   \n",
       "4     CA_4       CA       1  train  2013-08-04     11328          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "0          NaN          NaN          NaN        1        0        0   \n",
       "1          NaN          NaN          NaN        1        0        0   \n",
       "2          NaN          NaN          NaN        1        0        0   \n",
       "3          NaN          NaN          NaN        1        0        0   \n",
       "4          NaN          NaN          NaN        1        0        0   \n",
       "\n",
       "   sell_price  \n",
       "0    2.669922  \n",
       "1    7.519531  \n",
       "2         NaN  \n",
       "3    4.968750  \n",
       "4    3.380859  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1011.04 Mb (61.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = lag_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t7', \n",
    "            'demand_rolling_mean_t14', 'demand_rolling_mean_t28', 'demand_rolling_mean_t84',\n",
    "                'demand_rolling_std_t7', 'demand_rolling_std_t14', 'demand_rolling_std_t28', 'demand_rolling_std_t84']\n",
    "    \n",
    "cat_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', \n",
    "                    'event_name_2', 'event_type_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>demand_rolling_mean_t14</th>\n",
       "      <th>demand_rolling_std_t14</th>\n",
       "      <th>demand_rolling_mean_t28</th>\n",
       "      <th>demand_rolling_std_t28</th>\n",
       "      <th>demand_rolling_mean_t84</th>\n",
       "      <th>demand_rolling_std_t84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOUSEHOLD_1_478_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_478</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOUSEHOLD_1_479_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_479</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUSEHOLD_1_480_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_480</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOUSEHOLD_1_481_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_481</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUSEHOLD_1_482_CA_4_validation</td>\n",
       "      <td>HOUSEHOLD_1_482</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>11328</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id          item_id      dept_id     cat_id  \\\n",
       "0  HOUSEHOLD_1_478_CA_4_validation  HOUSEHOLD_1_478  HOUSEHOLD_1  HOUSEHOLD   \n",
       "1  HOUSEHOLD_1_479_CA_4_validation  HOUSEHOLD_1_479  HOUSEHOLD_1  HOUSEHOLD   \n",
       "2  HOUSEHOLD_1_480_CA_4_validation  HOUSEHOLD_1_480  HOUSEHOLD_1  HOUSEHOLD   \n",
       "3  HOUSEHOLD_1_481_CA_4_validation  HOUSEHOLD_1_481  HOUSEHOLD_1  HOUSEHOLD   \n",
       "4  HOUSEHOLD_1_482_CA_4_validation  HOUSEHOLD_1_482  HOUSEHOLD_1  HOUSEHOLD   \n",
       "\n",
       "  store_id state_id  demand   part       date  wm_yr_wk  ... dayofweek  \\\n",
       "0     CA_4       CA       0  train 2013-08-04     11328  ...         6   \n",
       "1     CA_4       CA       0  train 2013-08-04     11328  ...         6   \n",
       "2     CA_4       CA       0  train 2013-08-04     11328  ...         6   \n",
       "3     CA_4       CA       0  train 2013-08-04     11328  ...         6   \n",
       "4     CA_4       CA       1  train 2013-08-04     11328  ...         6   \n",
       "\n",
       "  dayofyear demand_rolling_mean_t7 demand_rolling_std_t7  \\\n",
       "0       216                    NaN                   NaN   \n",
       "1       216                    NaN                   NaN   \n",
       "2       216                    NaN                   NaN   \n",
       "3       216                    NaN                   NaN   \n",
       "4       216                    NaN                   NaN   \n",
       "\n",
       "   demand_rolling_mean_t14  demand_rolling_std_t14  demand_rolling_mean_t28  \\\n",
       "0                      NaN                     NaN                      NaN   \n",
       "1                      NaN                     NaN                      NaN   \n",
       "2                      NaN                     NaN                      NaN   \n",
       "3                      NaN                     NaN                      NaN   \n",
       "4                      NaN                     NaN                      NaN   \n",
       "\n",
       "   demand_rolling_std_t28  demand_rolling_mean_t84  demand_rolling_std_t84  \n",
       "0                     NaN                      NaN                     NaN  \n",
       "1                     NaN                      NaN                     NaN  \n",
       "2                     NaN                      NaN                     NaN  \n",
       "3                     NaN                      NaN                     NaN  \n",
       "4                     NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata = data[(data['date'] > '2013-11-23')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_asymmetric_train(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual < 0, -2 * residual, -2 * residual * 1.15)\n",
    "    hess = np.where(residual < 0, 2, 2 * 1.15)\n",
    "    return grad, hess\n",
    "\n",
    "def custom_asymmetric_valid(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    loss = np.where(residual < 0, (residual ** 2) , (residual ** 2) * 1.15) \n",
    "    return \"custom_asymmetric_eval\", np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>demand_rolling_mean_t14</th>\n",
       "      <th>demand_rolling_std_t14</th>\n",
       "      <th>demand_rolling_mean_t28</th>\n",
       "      <th>demand_rolling_std_t28</th>\n",
       "      <th>demand_rolling_mean_t84</th>\n",
       "      <th>demand_rolling_std_t84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>11344</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>328</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.976074</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.693848</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>0.646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>11344</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>328</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.267334</td>\n",
       "      <td>0.178589</td>\n",
       "      <td>0.390137</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.440918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>11344</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>11344</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>328</td>\n",
       "      <td>2.857422</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>2.427734</td>\n",
       "      <td>2.208984</td>\n",
       "      <td>2.177734</td>\n",
       "      <td>2.074219</td>\n",
       "      <td>1.845703</td>\n",
       "      <td>1.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>11344</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>328</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>1.120117</td>\n",
       "      <td>1.190430</td>\n",
       "      <td>1.197266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  demand   part       date  wm_yr_wk  ... dayofweek dayofyear  \\\n",
       "0       CA       2  train 2013-11-24     11344  ...         6       328   \n",
       "1       CA       0  train 2013-11-24     11344  ...         6       328   \n",
       "2       CA       0  train 2013-11-24     11344  ...         6       328   \n",
       "3       CA       3  train 2013-11-24     11344  ...         6       328   \n",
       "4       CA       0  train 2013-11-24     11344  ...         6       328   \n",
       "\n",
       "  demand_rolling_mean_t7 demand_rolling_std_t7  demand_rolling_mean_t14  \\\n",
       "0               0.571289              0.976074                 0.428467   \n",
       "1               0.142822              0.377930                 0.071411   \n",
       "2               0.000000              0.000000                 0.000000   \n",
       "3               2.857422              2.968750                 2.427734   \n",
       "4               0.428467              0.534668                 0.928711   \n",
       "\n",
       "   demand_rolling_std_t14  demand_rolling_mean_t28  demand_rolling_std_t28  \\\n",
       "0                0.755859                 0.500000                0.693848   \n",
       "1                0.267334                 0.178589                0.390137   \n",
       "2                0.000000                 0.000000                0.000000   \n",
       "3                2.208984                 2.177734                2.074219   \n",
       "4                0.997070                 0.928711                1.120117   \n",
       "\n",
       "   demand_rolling_mean_t84  demand_rolling_std_t84  \n",
       "0                 0.440430                0.646484  \n",
       "1                 0.214233                0.440918  \n",
       "2                 0.000000                0.000000  \n",
       "3                 1.845703                1.820312  \n",
       "4                 1.190430                1.197266  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1801.29 Mb (51.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "ldata = transform(ldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1801.29 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "ldata = reduce_mem_usage(ldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_test = run_lgb(ldata, features, cat_features)\n",
    "predict(next_test, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
