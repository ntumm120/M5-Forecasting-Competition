{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,BayesianRidge, Lasso\n",
    "from statistics import mean\n",
    "from math import sqrt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import Input, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    calendar = pd.read_csv('calendar.csv')\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar.shape[0], calendar.shape[1]))\n",
    "    sell_prices = pd.read_csv('sell_prices.csv')\n",
    "    sell_prices = reduce_mem_usage(sell_prices)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices.shape[0], sell_prices.shape[1]))\n",
    "    sales_train_validation = pd.read_csv('sales_train_validation.csv')\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    return calendar, sell_prices, sales_train_validation, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_and_merge(calendar, sell_prices, sales_train_validation, submission, nrows = 55000000, merge = False):\n",
    "    \n",
    "    # melt sales data, get it ready for training\n",
    "    sales_train_validation = pd.melt(sales_train_validation, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    print('Melted sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
    "    sales_train_validation = reduce_mem_usage(sales_train_validation)\n",
    "    \n",
    "    # seperate test dataframes\n",
    "    test1_rows = [row for row in submission['id'] if 'validation' in row]\n",
    "    test2_rows = [row for row in submission['id'] if 'evaluation' in row]\n",
    "    test1 = submission[submission['id'].isin(test1_rows)]\n",
    "    test2 = submission[submission['id'].isin(test2_rows)]\n",
    "    \n",
    "    # change column names\n",
    "    test1.columns = ['id', 'd_1914', 'd_1915', 'd_1916', 'd_1917', 'd_1918', 'd_1919', 'd_1920', 'd_1921', 'd_1922', 'd_1923', 'd_1924', 'd_1925', 'd_1926', 'd_1927', 'd_1928', 'd_1929', 'd_1930', 'd_1931', \n",
    "                      'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937', 'd_1938', 'd_1939', 'd_1940', 'd_1941']\n",
    "    test2.columns = ['id', 'd_1942', 'd_1943', 'd_1944', 'd_1945', 'd_1946', 'd_1947', 'd_1948', 'd_1949', 'd_1950', 'd_1951', 'd_1952', 'd_1953', 'd_1954', 'd_1955', 'd_1956', 'd_1957', 'd_1958', 'd_1959', \n",
    "                      'd_1960', 'd_1961', 'd_1962', 'd_1963', 'd_1964', 'd_1965', 'd_1966', 'd_1967', 'd_1968', 'd_1969']\n",
    "    \n",
    "    # get product table\n",
    "    product = sales_train_validation[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()\n",
    "    \n",
    "    # merge with product table\n",
    "    test2['id'] = test2['id'].str.replace('_evaluation','_validation')\n",
    "    test1 = test1.merge(product, how = 'left', on = 'id')\n",
    "    test2 = test2.merge(product, how = 'left', on = 'id')\n",
    "    test2['id'] = test2['id'].str.replace('_validation','_evaluation')\n",
    "    \n",
    "    test1 = pd.melt(test1, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    test2 = pd.melt(test2, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    \n",
    "    sales_train_validation['part'] = 'train'\n",
    "    test1['part'] = 'test1'\n",
    "    test2['part'] = 'test2'\n",
    "    \n",
    "    data = pd.concat([sales_train_validation, test1, test2], axis = 0)\n",
    "    \n",
    "    del sales_train_validation, test1, test2\n",
    "    \n",
    "    data = data.loc[nrows:]\n",
    "    \n",
    "    calendar.drop(['weekday', 'wday', 'month', 'year'], inplace = True, axis = 1)\n",
    "    \n",
    "    # delete test2 for now, don't delete when we do next stage of testing in June \n",
    "    data = data[data['part'] != 'test2']\n",
    "    \n",
    "    if merge:\n",
    "        data = pd.merge(data, calendar, how = 'left', left_on = ['day'], right_on = ['d'])\n",
    "        data.drop(['d', 'day'], inplace = True, axis = 1)\n",
    "        data = data.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "        print('Our final dataset to train has {} rows and {} columns'.format(data.shape[0], data.shape[1]))\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Sales train validation has 30490 rows and 1919 columns\n",
      "Melted sales train validation has 58327370 rows and 8 columns\n",
      "Mem. usage decreased to 3226.27 Mb (9.4% reduction)\n",
      "Our final dataset to train has 29181090 rows and 18 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "calendar, sell_prices, sales_train_validation, submission = read_data()\n",
    "\n",
    "data = melt_and_merge(calendar, sell_prices, sales_train_validation, submission, nrows = 30000000, merge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17381460</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381461</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381462</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381463</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381464</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "17381460  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "17381461  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "17381462  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "17381463  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "17381464  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "\n",
       "         store_id state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "17381460     CA_1       CA       1  train 2015-05-02     11514          NaN   \n",
       "17381461     CA_1       CA       0  train 2015-05-02     11514          NaN   \n",
       "17381462     CA_1       CA       1  train 2015-05-02     11514          NaN   \n",
       "17381463     CA_1       CA       6  train 2015-05-02     11514          NaN   \n",
       "17381464     CA_1       CA       3  train 2015-05-02     11514          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "17381460          NaN          NaN          NaN        1        0        1   \n",
       "17381461          NaN          NaN          NaN        1        0        1   \n",
       "17381462          NaN          NaN          NaN        1        0        1   \n",
       "17381463          NaN          NaN          NaN        1        0        1   \n",
       "17381464          NaN          NaN          NaN        1        0        1   \n",
       "\n",
       "          sell_price  \n",
       "17381460    8.257812  \n",
       "17381461    3.970703  \n",
       "17381462    2.970703  \n",
       "17381463    4.640625  \n",
       "17381464    2.880859  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '05-01-2015'\n",
    "\n",
    "mask = (data['date'] > start_date)\n",
    "data = data.loc[mask]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'sales'      \n",
    "END_TEST = 1913      \n",
    "ID_COLS = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfab3fe2888841208a1304b8b0384cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Don't run this cell unless we need visualization of WRMSSE\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import gc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "class WRMSSEEvaluator_dashboard(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 'all'  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')]\\\n",
    "                     .columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')]\\\n",
    "                               .columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], \n",
    "                                 axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)\\\n",
    "                    [valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns]\\\n",
    "                    .set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index()\\\n",
    "                   .rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left',\n",
    "                                    on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd'])\\\n",
    "                    .unstack(level=2)['value']\\\n",
    "                    .loc[zip(self.train_df.item_id, self.train_df.store_id), :]\\\n",
    "                    .reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns],\n",
    "                               weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt) \n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, \n",
    "                                       np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape \\\n",
    "               == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, \n",
    "                                       columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], \n",
    "                                 valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "\n",
    "            valid_preds_grp = valid_preds.groupby(group_id)[self.valid_target_columns].sum()\n",
    "            setattr(self, f'lv{i + 1}_valid_preds', valid_preds_grp)\n",
    "            \n",
    "            lv_scores = self.rmsse(valid_preds_grp, i + 1)\n",
    "            setattr(self, f'lv{i + 1}_scores', lv_scores)\n",
    "            \n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, \n",
    "                                  sort=False).prod(axis=1)\n",
    "            \n",
    "            all_scores.append(lv_scores.sum())\n",
    "            \n",
    "        self.all_scores = all_scores\n",
    "\n",
    "        return np.mean(all_scores)\n",
    "    \n",
    "\n",
    "    \n",
    "def create_viz_df(df,lv):\n",
    "    \n",
    "    df = df.T.reset_index()\n",
    "    if lv in [6,7,8,9,11,12]:\n",
    "        df.columns = [i[0] + '_' + i[1] if i != ('index','') \\\n",
    "                      else i[0] for i in df.columns]\n",
    "    df = df.merge(calendar.loc[:, ['d','date']], how='left', \n",
    "                  left_on='index', right_on='d')\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    df = df.set_index('date')\n",
    "    df = df.drop(['index', 'd'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_dashboard(evaluator, by_level_only=False, model_name=None):\n",
    "    \n",
    "    wrmsses = [np.mean(evaluator.all_scores)] + evaluator.all_scores\n",
    "    labels = ['Overall'] + [f'Level {i}' for i in range(1, 13)]\n",
    "\n",
    "    ## WRMSSE by Level\n",
    "    plt.figure(figsize=(12,5))\n",
    "    ax = sns.barplot(x=labels, y=wrmsses)\n",
    "    ax.set(xlabel='', ylabel='WRMSSE')\n",
    "    \n",
    "    #######################ALTERATION##########################\n",
    "    title = 'WRMSSE by Level'\n",
    "    if model_name: \n",
    "        title = f'WRMSSE by Level for {model_name}'\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    #######################ALTERATION-COMPLETE##########################\n",
    "\n",
    "  \n",
    "    for index, val in enumerate(wrmsses):\n",
    "        ax.text(index*1, val+.01, round(val,4), color='black', \n",
    "                ha=\"center\")\n",
    "        \n",
    "    #######################ALTERATION##########################\n",
    "    if by_level_only:       # stops function early for quick plotting of \n",
    "        plt.show()          # for quick plotting of levels\n",
    "        return\n",
    "    #######################ALTERATION-COMPLETE##########################\n",
    "\n",
    "    # configuration array for the charts\n",
    "    n_rows = [1, 1, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    n_cols = [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    width = [7, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
    "    height = [4, 3, 12, 3, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "    \n",
    "    for i in range(1,13):\n",
    "        \n",
    "        scores = getattr(evaluator, f'lv{i}_scores')\n",
    "        weights = getattr(evaluator, f'lv{i}_weight')\n",
    "        \n",
    "        if i > 1 and i < 9:\n",
    "            if i < 7:\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "            else:\n",
    "                fig, axs = plt.subplots(2, 1, figsize=(12, 8))\n",
    "                \n",
    "            ## RMSSE plot\n",
    "            scores.plot.bar(width=.8, ax=axs[0], color='g')\n",
    "            axs[0].set_title(f\"RMSSE\", size=14)\n",
    "            axs[0].set(xlabel='', ylabel='RMSSE')\n",
    "            if i >= 4:\n",
    "                axs[0].tick_params(labelsize=8)\n",
    "            for index, val in enumerate(scores):\n",
    "                axs[0].text(index*1, val+.01, round(val,4), color='black', \n",
    "                            ha=\"center\", fontsize=10 if i == 2 else 8)\n",
    "            \n",
    "            ## Weight plot\n",
    "            weights.plot.bar(width=.8, ax=axs[1])\n",
    "            axs[1].set_title(f\"Weight\", size=14)\n",
    "            axs[1].set(xlabel='', ylabel='Weight')\n",
    "            if i >= 4:\n",
    "                axs[1].tick_params(labelsize=8)\n",
    "            for index, val in enumerate(weights):\n",
    "                axs[1].text(index*1, val+.01, round(val,2), color='black', \n",
    "                            ha=\"center\", fontsize=10 if i == 2 else 8)\n",
    "                    \n",
    "            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 ,\n",
    "                         y=1.1, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        trn = create_viz_df(getattr(evaluator, f'lv{i}_train_df')\\\n",
    "                            .iloc[:, -28*3:], i)\n",
    "        val = create_viz_df(getattr(evaluator, f'lv{i}_valid_df'), i)\n",
    "        pred = create_viz_df(getattr(evaluator, f'lv{i}_valid_preds'), i)\n",
    "\n",
    "        n_cate = trn.shape[1] if i < 7 else 9\n",
    "\n",
    "        fig, axs = plt.subplots(n_rows[i-1], n_cols[i-1], \n",
    "                                figsize=(width[i-1],height[i-1]))\n",
    "        if i > 1:\n",
    "            axs = axs.flatten()\n",
    "\n",
    "        ## Time series plot\n",
    "        for k in range(0, n_cate):\n",
    "\n",
    "            ax = axs[k] if i > 1 else axs\n",
    "\n",
    "            trn.iloc[:, k].plot(ax=ax, label='train')\n",
    "            val.iloc[:, k].plot(ax=ax, label='valid')\n",
    "            pred.iloc[:, k].plot(ax=ax, label='pred')\n",
    "            ax.set_title(f\"{trn.columns[k]}  RMSSE:{scores[k]:.4f}\", size=14)\n",
    "            ax.set(xlabel='', ylabel='sales')\n",
    "            ax.tick_params(labelsize=8)\n",
    "            ax.legend(loc='upper left', prop={'size': 10})\n",
    "\n",
    "        if i == 1 or i >= 9:\n",
    "            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 , \n",
    "                         y=1.1, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "train_df = pd.read_csv('sales_train_validation.csv')\n",
    "calendar_df = pd.read_csv('calendar.csv')\n",
    "sell_prices_df = pd.read_csv('sell_prices.csv')\n",
    "train_df = train_df.loc[:, :'d_' + str(END_TEST)]\n",
    "\n",
    "train_fold_df = train_df.iloc[:, :-28]\n",
    "valid_fold_df = train_fold_df.iloc[:, -28:].copy()\n",
    "# Instantiate an evaluator for scoring validation periodstarting day 1886\n",
    "e = WRMSSEEvaluator_dashboard(train_fold_df, valid_fold_df, calendar_df, sell_prices_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del calendar, sell_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Sales train validation has 30490 rows and 1919 columns\n"
     ]
    }
   ],
   "source": [
    "del sales_train_validation, submission\n",
    "gc.collect()\n",
    "\n",
    "calendar, sell_prices, sales_train_validation, submission = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sale</th>\n",
       "      <th>d</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sale_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id store_id        item_id  sale       d  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     CA_1  HOBBIES_1_001     1  d_1886   \n",
       "1  HOBBIES_1_002_CA_1_validation     CA_1  HOBBIES_1_002     1  d_1886   \n",
       "2  HOBBIES_1_003_CA_1_validation     CA_1  HOBBIES_1_003     0  d_1886   \n",
       "3  HOBBIES_1_004_CA_1_validation     CA_1  HOBBIES_1_004     0  d_1886   \n",
       "4  HOBBIES_1_005_CA_1_validation     CA_1  HOBBIES_1_005     1  d_1886   \n",
       "\n",
       "   sell_price  sale_usd  \n",
       "0    8.257812  8.257812  \n",
       "1    3.970703  3.970703  \n",
       "2    2.970703  0.000000  \n",
       "3    4.640625  0.000000  \n",
       "4    2.880859  2.880859  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"d_{}\".format(i) for i in range(1914-28, 1914)]\n",
    "lastdata = sales_train_validation[[\"id\", 'store_id', 'item_id'] + cols]\n",
    "\n",
    "# To long form:\n",
    "lastdata = lastdata.melt(id_vars=[\"id\", 'store_id', 'item_id'], \n",
    "                 var_name=\"d\", value_name=\"sale\")\n",
    "\n",
    "# Add week of year column from 'calendar':\n",
    "lastdata = pd.merge(lastdata, calendar, how = 'left', \n",
    "                left_on = ['d'], right_on = ['d'])\n",
    "\n",
    "lastdata = lastdata[[\"id\", 'store_id', 'item_id', \"sale\", \"d\", \"wm_yr_wk\"]]\n",
    "\n",
    "# Add weekly price from 'sell_prices':\n",
    "lastdata = lastdata.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "lastdata.drop(columns = ['wm_yr_wk'], inplace=True)\n",
    "\n",
    "# Calculate daily sales in USD:\n",
    "lastdata['sale_usd'] = lastdata['sale'] * lastdata['sell_price']\n",
    "lastdata.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840, 30490)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_list = [sales.state_id, sales.store_id, \n",
    "                sales.cat_id, sales.dept_id, \n",
    "                sales.state_id +'_'+ sales.cat_id, sales.state_id +'_'+ sales.dept_id,\n",
    "                sales.store_id +'_'+ sales.cat_id, sales.store_id +'_'+ sales.dept_id, \n",
    "                sales.item_id, sales.state_id +'_'+ sales.item_id, sales.id]\n",
    "\n",
    "\n",
    "## First element Level_0 aggregation 'all_sales':\n",
    "dummies_df_list =[pd.DataFrame(np.ones(sales.shape[0]).astype(np.int8), \n",
    "                               index=sales.index, columns=['all']).T]\n",
    "\n",
    "# List of dummy dataframes:\n",
    "for i, cats in enumerate(dummies_list):\n",
    "    dummies_df_list +=[pd.get_dummies(cats, drop_first=False, dtype=np.int8).T]\n",
    "    \n",
    "# Concat dummy dataframes in one go:\n",
    "## Level is constructed for free.\n",
    "roll_mat_df = pd.concat(dummies_df_list, keys=list(range(12)), \n",
    "                        names=['level','id'])#.astype(np.int8, copy=False)\n",
    "\n",
    "# Save values as sparse matrix & save index for future reference:\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "roll_mat_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll_mat_df.to_pickle('roll_mat_df.pkl')\n",
    "del dummies_df_list, roll_mat_df, sales_train_validation, calendar, sell_prices\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(drop_days=0):\n",
    "    # Rollup sales:\n",
    "    d_name = ['d_' + str(i+1) for i in range(1913-drop_days)]\n",
    "    sales_train_val = roll_mat_csr * sales[d_name].values\n",
    "\n",
    "    no_sales = np.cumsum(sales_train_val, axis=1) == 0\n",
    "    sales_train_val = np.where(no_sales, np.nan, sales_train_val)\n",
    "\n",
    "    # Denominator of RMSSE / RMSSE\n",
    "    weight1 = np.nanmean(np.diff(sales_train_val,axis=1)**2,axis=1)\n",
    "    \n",
    "    return weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = get_s(drop_days=0)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w(sale_usd):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Calculate the total sales in USD for each item id:\n",
    "    total_sales_usd = sale_usd.groupby(\n",
    "        ['id'], sort=False)['sale_usd'].apply(np.sum).values\n",
    "    \n",
    "    # Roll up total sales by ids to higher levels:\n",
    "    weight2 = roll_mat_csr * total_sales_usd\n",
    "    \n",
    "    return 12*weight2/np.sum(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_w(lastdata[['id','sale_usd']])\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>CA</th>\n",
       "      <td>Level2</td>\n",
       "      <td>CA</td>\n",
       "      <td>X</td>\n",
       "      <td>0.442371</td>\n",
       "      <td>0.442370</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>HOBBIES</th>\n",
       "      <td>Level4</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>X</td>\n",
       "      <td>0.128079</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD</th>\n",
       "      <td>Level4</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>X</td>\n",
       "      <td>0.303335</td>\n",
       "      <td>0.303330</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>FOODS_1</th>\n",
       "      <td>Level5</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>0.062623</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_2</th>\n",
       "      <td>Level5</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>X</td>\n",
       "      <td>0.154642</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1</th>\n",
       "      <td>Level5</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.122088</td>\n",
       "      <td>0.122084</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_1</th>\n",
       "      <td>Level5</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.229594</td>\n",
       "      <td>0.229592</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2</th>\n",
       "      <td>Level5</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>X</td>\n",
       "      <td>0.073741</td>\n",
       "      <td>0.073738</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th>CA_HOBBIES</th>\n",
       "      <td>Level6</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0.058855</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOUSEHOLD</th>\n",
       "      <td>Level6</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.142772</td>\n",
       "      <td>0.142769</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_HOUSEHOLD</th>\n",
       "      <td>Level6</td>\n",
       "      <td>TX</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.086419</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_HOBBIES</th>\n",
       "      <td>Level6</td>\n",
       "      <td>WI</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">6</th>\n",
       "      <th>CA_FOODS_2</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.057655</td>\n",
       "      <td>0.057654</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOBBIES_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>0.056463</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOUSEHOLD_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOUSEHOLD_2</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>0.037909</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_FOODS_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>TX</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_FOODS_2</th>\n",
       "      <td>Level7</td>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.062561</td>\n",
       "      <td>0.062560</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_HOBBIES_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>WI</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>0.026375</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>CA_2_HOUSEHOLD</th>\n",
       "      <td>Level8</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>0.037629</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3_HOUSEHOLD</th>\n",
       "      <td>Level8</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.055869</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>WI_2_FOODS_2</th>\n",
       "      <td>Level9</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>FOODS_2_029</th>\n",
       "      <td>Level10</td>\n",
       "      <td>FOODS_2_029</td>\n",
       "      <td>X</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_2_183</th>\n",
       "      <td>Level10</td>\n",
       "      <td>FOODS_2_183</td>\n",
       "      <td>X</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_586</th>\n",
       "      <td>Level10</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>X</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Level_id  Agg_Level_1  Agg_Level_2    Weight  Predicted  \\\n",
       "level id                                                                       \n",
       "1     CA               Level2           CA            X  0.442371   0.442370   \n",
       "3     HOBBIES          Level4      HOBBIES            X  0.128079   0.128075   \n",
       "      HOUSEHOLD        Level4    HOUSEHOLD            X  0.303335   0.303330   \n",
       "4     FOODS_1          Level5      FOODS_1            X  0.062625   0.062623   \n",
       "      FOODS_2          Level5      FOODS_2            X  0.154642   0.154639   \n",
       "      HOBBIES_1        Level5    HOBBIES_1            X  0.122088   0.122084   \n",
       "      HOUSEHOLD_1      Level5  HOUSEHOLD_1            X  0.229594   0.229592   \n",
       "      HOUSEHOLD_2      Level5  HOUSEHOLD_2            X  0.073741   0.073738   \n",
       "5     CA_HOBBIES       Level6           CA      HOBBIES  0.058855   0.058852   \n",
       "      CA_HOUSEHOLD     Level6           CA    HOUSEHOLD  0.142772   0.142769   \n",
       "      TX_HOUSEHOLD     Level6           TX    HOUSEHOLD  0.086420   0.086419   \n",
       "      WI_HOBBIES       Level6           WI      HOBBIES  0.027931   0.027930   \n",
       "6     CA_FOODS_2       Level7           CA      FOODS_2  0.057655   0.057654   \n",
       "      CA_HOBBIES_1     Level7           CA    HOBBIES_1  0.056463   0.056460   \n",
       "      CA_HOUSEHOLD_1   Level7           CA  HOUSEHOLD_1  0.104863   0.104862   \n",
       "      CA_HOUSEHOLD_2   Level7           CA  HOUSEHOLD_2  0.037909   0.037907   \n",
       "      TX_FOODS_1       Level7           TX      FOODS_1  0.016016   0.016015   \n",
       "      WI_FOODS_2       Level7           WI      FOODS_2  0.062561   0.062560   \n",
       "      WI_HOBBIES_1     Level7           WI    HOBBIES_1  0.026375   0.026374   \n",
       "7     CA_2_HOUSEHOLD   Level8         CA_2    HOUSEHOLD  0.037630   0.037629   \n",
       "      CA_3_HOUSEHOLD   Level8         CA_3    HOUSEHOLD  0.055870   0.055869   \n",
       "8     WI_2_FOODS_2     Level9         WI_2      FOODS_2  0.030535   0.030534   \n",
       "9     FOODS_2_029     Level10  FOODS_2_029            X  0.002862   0.002861   \n",
       "      FOODS_2_183     Level10  FOODS_2_183            X  0.002679   0.002677   \n",
       "      FOODS_3_586     Level10  FOODS_3_586            X  0.005074   0.005073   \n",
       "\n",
       "                          diff  \n",
       "level id                        \n",
       "1     CA              0.000002  \n",
       "3     HOBBIES         0.000004  \n",
       "      HOUSEHOLD       0.000005  \n",
       "4     FOODS_1         0.000002  \n",
       "      FOODS_2         0.000004  \n",
       "      HOBBIES_1       0.000004  \n",
       "      HOUSEHOLD_1     0.000002  \n",
       "      HOUSEHOLD_2     0.000003  \n",
       "5     CA_HOBBIES      0.000003  \n",
       "      CA_HOUSEHOLD    0.000004  \n",
       "      TX_HOUSEHOLD    0.000001  \n",
       "      WI_HOBBIES      0.000001  \n",
       "6     CA_FOODS_2      0.000001  \n",
       "      CA_HOBBIES_1    0.000003  \n",
       "      CA_HOUSEHOLD_1  0.000002  \n",
       "      CA_HOUSEHOLD_2  0.000002  \n",
       "      TX_FOODS_1      0.000001  \n",
       "      WI_FOODS_2      0.000002  \n",
       "      WI_HOBBIES_1    0.000001  \n",
       "7     CA_2_HOUSEHOLD  0.000001  \n",
       "      CA_3_HOUSEHOLD  0.000001  \n",
       "8     WI_2_FOODS_2    0.000001  \n",
       "9     FOODS_2_029     0.000001  \n",
       "      FOODS_2_183     0.000001  \n",
       "      FOODS_3_586     0.000001  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_df = pd.DataFrame(W,index = roll_index,columns=['w'])\n",
    "\n",
    "W_original_df = pd.read_csv('weights_validation.csv')\n",
    "\n",
    "# Set new index, calculate difference between original and predicted:\n",
    "W_original_df = W_original_df.set_index(W_df.index)\n",
    "W_original_df['Predicted'] = W_df.w\n",
    "W_original_df['diff'] = W_original_df.Weight - W_original_df.Predicted\n",
    "\n",
    "# See where we are off by more than e-6\n",
    "m = W_original_df.Weight.values - W_df.w.values > 0.000001\n",
    "W_original_df[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SW = W/np.sqrt(S)\n",
    "sw_df = pd.DataFrame(np.stack((S, W, SW), axis=-1),index = roll_index,columns=['s','w','sw'])\n",
    "sw_df.to_pickle('sw_df.pkl')\n",
    "\n",
    "del W_original_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollup(v):\n",
    "    return roll_mat_csr*v #(v.T*roll_mat_csr.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_df = pd.read_pickle('sw_df.pkl')\n",
    "S = sw_df.s.values\n",
    "W = sw_df.w.values\n",
    "SW = sw_df.sw.values\n",
    "\n",
    "# Load roll up matrix to calcualte aggreagates:\n",
    "roll_mat_df = pd.read_pickle('roll_mat_df.pkl')\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "del roll_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del lastdata, sw_df, W_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrmsse_eval(preds, y_true, s = S, w = W, sw=SW):\n",
    "    score = np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds.values-y_true.values))\n",
    "                            ,axis=1)) * sw)/12 \n",
    "\n",
    "    return \"WRMSSE\", score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def transform(data):\n",
    "    \n",
    "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for feature in nan_features:\n",
    "        data[feature].fillna('unknown', inplace = True)\n",
    "        \n",
    "    cat = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for feature in cat:\n",
    "        encoder = LabelEncoder()\n",
    "        data[feature] = encoder.fit_transform(data[feature])\n",
    "        \n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    time_features = ['year', 'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear']\n",
    "    dtype = np.int16\n",
    "    for time_feature in time_features:\n",
    "        data[time_feature] = getattr(data['date'].dt, time_feature).astype(dtype)\n",
    "        \n",
    "    data = reduce_mem_usage(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in event proximity at some point, see if it gives good results in conjunction with other features\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "def new_features(data):\n",
    "    \n",
    "    data_fe = data[['id', 'demand']]\n",
    "    \n",
    "    window = 28\n",
    "    periods = [1, 2, 3, 4, 5, 6, 7]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    # most recent lag data\n",
    "    for period in periods:\n",
    "        data_fe['demand_rolling_mean_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).mean())\n",
    "        data_fe['demand_rolling_std_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).std())\n",
    "        data_fe['sales_lag_t' + str(period)] = group.transform(lambda x: x.shift(window + period))\n",
    "    \n",
    "    \n",
    "    def get_season(date):\n",
    "        year = str(date.year)\n",
    "        seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "                   'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "                   'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "        if date in seasons['spring']:\n",
    "            return 0\n",
    "        if date in seasons['summer']:\n",
    "            return 1\n",
    "        if date in seasons['autumn']:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    date_fe['season'] = data['date'].map(get_season)\n",
    "    \n",
    "    data_fe['price_max'] = data.groupby('id')['sell_price'].transform('max')\n",
    "    data_fe['price_min'] = data.groupby('id')['sell_price'].transform('min')\n",
    "    data_fe['price_std'] = data.groupby('id')['sell_price'].transform('std')\n",
    "    data_fe['price_mean'] = data.groupby('id')['sell_price'].transform('mean')  \n",
    "    \n",
    "    data_fe['price_norm'] = data_fe['sell_price']/data_fe['price_max']\n",
    "    data_fe['price_nunique'] = data.groupby('id')['sell_price'].transform('nunique')\n",
    "    \n",
    "    data_fe['price_momentum'] = data['sell_price']/data.groupby('id')['sell_price'].transform(lambda x: x.shift(1))\n",
    "    data_fe['price_momentum_m'] = data['sell_price']/data.groupby('id', 'month')['sell_price'].transform('mean')\n",
    "    data_fe['price_momentum_y'] = data['sell_price']/data.groupby('id', 'year')['sell_price'].transform('mean')\n",
    "    \n",
    "    data_fe['sale_momentum_m'] = data['demand']/data.groupby('id','month')['demand'].transform('mean')\n",
    "    data_fe['sale_momentum_y'] = data['demand']/data.groupby('id','year')['demand'].transform('mean')\n",
    "    \n",
    "    temp = data_fe\n",
    "\n",
    "    temp.index = pd.to_datetime(data('date'))\n",
    "    weighted_periods = [1, 2, 3, 4, 5, 6, 7]\n",
    "    weighted_group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    for weight in weight_periods:\n",
    "        data_fe['weighted_sales_t' + str(weight)] = weighted_group.ewm(span = weight + window).mean()\n",
    "    \n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe, temp\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29181085</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181086</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181087</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181088</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181089</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id      item_id  dept_id cat_id store_id  \\\n",
       "29181085  FOODS_3_823_WI_3_validation  FOODS_3_823  FOODS_3  FOODS     WI_3   \n",
       "29181086  FOODS_3_824_WI_3_validation  FOODS_3_824  FOODS_3  FOODS     WI_3   \n",
       "29181087  FOODS_3_825_WI_3_validation  FOODS_3_825  FOODS_3  FOODS     WI_3   \n",
       "29181088  FOODS_3_826_WI_3_validation  FOODS_3_826  FOODS_3  FOODS     WI_3   \n",
       "29181089  FOODS_3_827_WI_3_validation  FOODS_3_827  FOODS_3  FOODS     WI_3   \n",
       "\n",
       "         state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "29181085       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181086       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181087       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181088       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181089       WI       0  test1 2016-05-22     11617          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "29181085          NaN          NaN          NaN        0        0        0   \n",
       "29181086          NaN          NaN          NaN        0        0        0   \n",
       "29181087          NaN          NaN          NaN        0        0        0   \n",
       "29181088          NaN          NaN          NaN        0        0        0   \n",
       "29181089          NaN          NaN          NaN        0        0        0   \n",
       "\n",
       "          sell_price  \n",
       "29181085    2.980469  \n",
       "29181086    2.480469  \n",
       "29181087    3.980469  \n",
       "29181088    1.280273  \n",
       "29181089    1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#wdf = pd.read_csv(\"weight_scale_1886.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_VAL = '05-22-2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr_w = tr_x[ID_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wdf['scaled_weight'] = wdf.weight/np.sqrt(wdf.scale)\n",
    "wdf = wdf[[ 'Level_id', 'Agg_Level_1', 'Agg_Level_2','scaled_weight']]\n",
    "\n",
    "\n",
    "######################### level 1 #######################################\n",
    "tr_w['level_1_sw'] = wdf.loc[wdf['Level_id'] == 'Level1', 'scaled_weight'][0]\n",
    "\n",
    "######################### level 2 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level2']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id']], level[['state_id', 'scaled_weight']],\n",
    "                               on='state_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_2_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 3 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level3']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'store_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['store_id']], level[['store_id', 'scaled_weight']],\n",
    "                               on='store_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_3_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 4 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level4']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'cat_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['cat_id']], level[['cat_id', 'scaled_weight']],\n",
    "                               on='cat_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_4_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 5 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level5']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'dept_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['dept_id']], level[['dept_id', 'scaled_weight']],\n",
    "                               on='dept_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_5_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 6 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level6']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'cat_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id', 'cat_id']], level[['state_id', 'cat_id', 'scaled_weight']],\n",
    "                               on=['state_id', 'cat_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_6_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 7 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level7']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'dept_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id', 'dept_id']], level[['state_id', 'dept_id', 'scaled_weight']],\n",
    "                               on=['state_id', 'dept_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_7_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 8 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level8']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'store_id', 'cat_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['store_id', 'cat_id']], level[['store_id', 'cat_id', 'scaled_weight']],\n",
    "                               on=['store_id', 'cat_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_8_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 9 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level9']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'store_id', 'dept_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['store_id', 'dept_id']], level[['store_id', 'dept_id', 'scaled_weight']],\n",
    "                               on=['store_id', 'dept_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_9_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 10 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level10']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'item_id', 'dept_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['item_id']], level[['item_id', 'scaled_weight']],\n",
    "                               on=['item_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_10_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 11 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level11']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'item_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id', 'item_id']], level[['state_id', 'item_id', 'scaled_weight']],\n",
    "                               on=['state_id', 'item_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_11_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 12 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level12']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'item_id', 'store_id', 'scaled_weight']\n",
    "level_scaled_weight = pd.merge(tr_w[['item_id', 'store_id']], level[['item_id', 'store_id', 'scaled_weight']],\n",
    "                               on=['item_id', 'store_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_12_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight, wdf\n",
    "gc.collect()\n",
    "\n",
    "cols = [col for col in tr_w.columns if 'level' in col]\n",
    "tr_w = tr_w[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18021750</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021751</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021752</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021753</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021754</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021755</th>\n",
       "      <td>HOBBIES_1_006_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_006</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021756</th>\n",
       "      <td>HOBBIES_1_007_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_007</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.878906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021757</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021758</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021759</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>11517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "18021750  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "18021751  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "18021752  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "18021753  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "18021754  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "18021755  HOBBIES_1_006_CA_1_validation  HOBBIES_1_006  HOBBIES_1  HOBBIES   \n",
       "18021756  HOBBIES_1_007_CA_1_validation  HOBBIES_1_007  HOBBIES_1  HOBBIES   \n",
       "18021757  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "18021758  HOBBIES_1_009_CA_1_validation  HOBBIES_1_009  HOBBIES_1  HOBBIES   \n",
       "18021759  HOBBIES_1_010_CA_1_validation  HOBBIES_1_010  HOBBIES_1  HOBBIES   \n",
       "\n",
       "         store_id state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "18021750     CA_1       CA       0  train 2015-05-23     11517          NaN   \n",
       "18021751     CA_1       CA       0  train 2015-05-23     11517          NaN   \n",
       "18021752     CA_1       CA       1  train 2015-05-23     11517          NaN   \n",
       "18021753     CA_1       CA       4  train 2015-05-23     11517          NaN   \n",
       "18021754     CA_1       CA       0  train 2015-05-23     11517          NaN   \n",
       "18021755     CA_1       CA       1  train 2015-05-23     11517          NaN   \n",
       "18021756     CA_1       CA       1  train 2015-05-23     11517          NaN   \n",
       "18021757     CA_1       CA       5  train 2015-05-23     11517          NaN   \n",
       "18021758     CA_1       CA       0  train 2015-05-23     11517          NaN   \n",
       "18021759     CA_1       CA       0  train 2015-05-23     11517          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "18021750          NaN          NaN          NaN        0        0        0   \n",
       "18021751          NaN          NaN          NaN        0        0        0   \n",
       "18021752          NaN          NaN          NaN        0        0        0   \n",
       "18021753          NaN          NaN          NaN        0        0        0   \n",
       "18021754          NaN          NaN          NaN        0        0        0   \n",
       "18021755          NaN          NaN          NaN        0        0        0   \n",
       "18021756          NaN          NaN          NaN        0        0        0   \n",
       "18021757          NaN          NaN          NaN        0        0        0   \n",
       "18021758          NaN          NaN          NaN        0        0        0   \n",
       "18021759          NaN          NaN          NaN        0        0        0   \n",
       "\n",
       "          sell_price  \n",
       "18021750    8.257812  \n",
       "18021751    3.970703  \n",
       "18021752    2.970703  \n",
       "18021753    4.640625  \n",
       "18021754    2.880859  \n",
       "18021755    1.000000  \n",
       "18021756    7.878906  \n",
       "18021757    0.479980  \n",
       "18021758    1.769531  \n",
       "18021759    2.970703  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this cell, it will crash the kernel \n",
    "\n",
    "roll_1 = csr_matrix(pd.get_dummies(tr_x.d, drop_first=False).values)\n",
    "\n",
    "roll_2 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.state_id.astype('str'),\n",
    "                                  drop_first=False).values)\n",
    "\n",
    "roll_3 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_4 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_5 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_6 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.state_id.astype('str') + tr_x.cat_id.astype('str') ,\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_7 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.state_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_8 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.store_id.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_9 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.store_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_10 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.item_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_11 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.state_id.astype('str') + tr_x.item_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_12 = csr_matrix(pd.get_dummies(tr_x.d.astype('str') + tr_x.item_id.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                    drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_1 = csr_matrix(pd.get_dummies(tr_x.date, drop_first=False).values)\n",
    "\n",
    "roll_2 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str'),\n",
    "                                  drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_3 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_4 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_5 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_6 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str') + tr_x.cat_id.astype('str') ,\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_7 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_8 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.store_id.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_9 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.store_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_10 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.item_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_11 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str') + tr_x.item_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_12 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.item_id.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                    drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(roll, level_sw, actuals, preds, n, s):\n",
    "    diff = actuals - preds\n",
    "    diffsquared = np.square(diff)\n",
    "    \n",
    "    diff = np.reshape(diff,(roll.T.shape[1], -1))\n",
    "    diffsquared = np.reshape(diffsqaured,(roll.T.shape[1], -1))\n",
    "    \n",
    "    diff_sum = roll.T * diff\n",
    "    diffsquared_sum = roll.T * diffsquared\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return level_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29181085</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181086</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181087</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181088</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181089</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id      item_id  dept_id cat_id store_id  \\\n",
       "29181085  FOODS_3_823_WI_3_validation  FOODS_3_823  FOODS_3  FOODS     WI_3   \n",
       "29181086  FOODS_3_824_WI_3_validation  FOODS_3_824  FOODS_3  FOODS     WI_3   \n",
       "29181087  FOODS_3_825_WI_3_validation  FOODS_3_825  FOODS_3  FOODS     WI_3   \n",
       "29181088  FOODS_3_826_WI_3_validation  FOODS_3_826  FOODS_3  FOODS     WI_3   \n",
       "29181089  FOODS_3_827_WI_3_validation  FOODS_3_827  FOODS_3  FOODS     WI_3   \n",
       "\n",
       "         state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "29181085       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181086       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181087       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181088       WI       0  test1 2016-05-22     11617          NaN   \n",
       "29181089       WI       0  test1 2016-05-22     11617          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "29181085          NaN          NaN          NaN        0        0        0   \n",
       "29181086          NaN          NaN          NaN        0        0        0   \n",
       "29181087          NaN          NaN          NaN        0        0        0   \n",
       "29181088          NaN          NaN          NaN        0        0        0   \n",
       "29181089          NaN          NaN          NaN        0        0        0   \n",
       "\n",
       "          sell_price  \n",
       "29181085    2.980469  \n",
       "29181086    2.480469  \n",
       "29181087    3.980469  \n",
       "29181088    1.280273  \n",
       "29181089    1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "def run_lgb(data, features, cat_features):\n",
    "    \n",
    "    # reset_index\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    # going to evaluate with the last 28 days\n",
    "    x_train = data[data['date'] <= '2016-04-24']\n",
    "    y_train = x_train['demand']\n",
    "    test = data[data['date'] >= '2016-04-25']\n",
    "\n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.09,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 200,\n",
    "        'lambda_l1': 0.4,\n",
    "        'lambda_l2': 0.4,\n",
    "        'objective': 'tweedie'}\n",
    "    \n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    train_set = lgb.Dataset(x_train.iloc[trn_idx][features], y_train.iloc[trn_idx], \n",
    "                            categorical_feature = cat_features)\n",
    "    val_set = lgb.Dataset(x_train.iloc[val_idx][features], y_train.iloc[val_idx], \n",
    "                          categorical_feature = cat_features)\n",
    "        \n",
    "    model = lgb.train(params, train_set, num_boost_round = 10000, early_stopping_rounds = 100, \n",
    "                          valid_sets = [train_set, val_set], verbose_eval = 20, \n",
    "                          feval = wrmsse_eval)\n",
    "    model.save_model(\"LightGBM_TSS.lgb\")\n",
    "    preds += model.predict(test[features])\n",
    "\n",
    "    #print('-'*50)\n",
    "    #print('\\n')\n",
    "        \n",
    "    test = test[['id', 'date', 'demand']]\n",
    "    test['demand'] = preds\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(test, submission):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.to_csv('May25thsub.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17381460</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381461</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381462</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381463</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381464</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>11514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "17381460  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "17381461  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "17381462  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "17381463  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "17381464  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "\n",
       "         store_id state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "17381460     CA_1       CA       1  train 2015-05-02     11514          NaN   \n",
       "17381461     CA_1       CA       0  train 2015-05-02     11514          NaN   \n",
       "17381462     CA_1       CA       1  train 2015-05-02     11514          NaN   \n",
       "17381463     CA_1       CA       6  train 2015-05-02     11514          NaN   \n",
       "17381464     CA_1       CA       3  train 2015-05-02     11514          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "17381460          NaN          NaN          NaN        1        0        1   \n",
       "17381461          NaN          NaN          NaN        1        0        1   \n",
       "17381462          NaN          NaN          NaN        1        0        1   \n",
       "17381463          NaN          NaN          NaN        1        0        1   \n",
       "17381464          NaN          NaN          NaN        1        0        1   \n",
       "\n",
       "          sell_price  \n",
       "17381460    8.257812  \n",
       "17381461    3.970703  \n",
       "17381462    2.970703  \n",
       "17381463    4.640625  \n",
       "17381464    2.880859  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 675.18 Mb (54.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t7', \n",
    "            'demand_rolling_mean_t14', 'demand_rolling_mean_t28', 'demand_rolling_mean_t84',\n",
    "                'demand_rolling_std_t7', 'demand_rolling_std_t14', 'demand_rolling_std_t28', 'demand_rolling_std_t84']\n",
    "    \n",
    "cat_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', \n",
    "                    'event_name_2', 'event_type_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_test = run_lgb(data, features, cat_features)\n",
    "submit(next_test, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
