{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,BayesianRidge, Lasso\n",
    "from statistics import mean\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "import gc\n",
    "import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First three functions are used to read the data into the Jupyter notebook. Simply use cell 6 in order to read the data in. Use the nrows argument in order to control how much of the data you read into memory (note that the higher the value of nrows, the less data you are reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    calendar = pd.read_csv('calendar.csv')\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar.shape[0], calendar.shape[1]))\n",
    "    sell_prices = pd.read_csv('sell_prices.csv')\n",
    "    sell_prices = reduce_mem_usage(sell_prices)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices.shape[0], sell_prices.shape[1]))\n",
    "    sales_train_validation = pd.read_csv('sales_train_validation.csv')\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    return calendar, sell_prices, sales_train_validation, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_and_merge(calendar, sell_prices, sales_train_validation, submission, nrows = 55000000, merge = False):\n",
    "    \n",
    "    # melt sales data, get it ready for training\n",
    "    sales_train_validation = pd.melt(sales_train_validation, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    print('Melted sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
    "    sales_train_validation = reduce_mem_usage(sales_train_validation)\n",
    "    \n",
    "    # seperate test dataframes\n",
    "    test1_rows = [row for row in submission['id'] if 'validation' in row]\n",
    "    test2_rows = [row for row in submission['id'] if 'evaluation' in row]\n",
    "    test1 = submission[submission['id'].isin(test1_rows)]\n",
    "    test2 = submission[submission['id'].isin(test2_rows)]\n",
    "    \n",
    "    # change column names\n",
    "    test1.columns = ['id', 'd_1914', 'd_1915', 'd_1916', 'd_1917', 'd_1918', 'd_1919', 'd_1920', 'd_1921', 'd_1922', 'd_1923', 'd_1924', 'd_1925', 'd_1926', 'd_1927', 'd_1928', 'd_1929', 'd_1930', 'd_1931', \n",
    "                      'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937', 'd_1938', 'd_1939', 'd_1940', 'd_1941']\n",
    "    test2.columns = ['id', 'd_1942', 'd_1943', 'd_1944', 'd_1945', 'd_1946', 'd_1947', 'd_1948', 'd_1949', 'd_1950', 'd_1951', 'd_1952', 'd_1953', 'd_1954', 'd_1955', 'd_1956', 'd_1957', 'd_1958', 'd_1959', \n",
    "                      'd_1960', 'd_1961', 'd_1962', 'd_1963', 'd_1964', 'd_1965', 'd_1966', 'd_1967', 'd_1968', 'd_1969']\n",
    "    \n",
    "    # get product table\n",
    "    product = sales_train_validation[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()\n",
    "    \n",
    "    # merge with product table\n",
    "    test2['id'] = test2['id'].str.replace('_evaluation','_validation')\n",
    "    test1 = test1.merge(product, how = 'left', on = 'id')\n",
    "    test2 = test2.merge(product, how = 'left', on = 'id')\n",
    "    test2['id'] = test2['id'].str.replace('_validation','_evaluation')\n",
    "    \n",
    "    test1 = pd.melt(test1, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    test2 = pd.melt(test2, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n",
    "    \n",
    "    sales_train_validation['part'] = 'train'\n",
    "    test1['part'] = 'test1'\n",
    "    test2['part'] = 'test2'\n",
    "    \n",
    "    data = pd.concat([sales_train_validation, test1, test2], axis = 0)\n",
    "    \n",
    "    del sales_train_validation, test1, test2\n",
    "    \n",
    "    data = data.loc[nrows:]\n",
    "    \n",
    "    calendar.drop(['weekday', 'wday', 'month', 'year'], inplace = True, axis = 1)\n",
    "    \n",
    "    # delete test2 for now, don't delete when we do next stage of testing in June \n",
    "    data = data[data['part'] != 'test2']\n",
    "    \n",
    "    if merge:\n",
    "        data = pd.merge(data, calendar, how = 'left', left_on = ['day'], right_on = ['d'])\n",
    "        data.drop(['d', 'day'], inplace = True, axis = 1)\n",
    "        data = data.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "        print('Our final dataset to train has {} rows and {} columns'.format(data.shape[0], data.shape[1]))\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Sales train validation has 30490 rows and 1919 columns\n",
      "Melted sales train validation has 58327370 rows and 8 columns\n",
      "Mem. usage decreased to 3226.27 Mb (9.4% reduction)\n",
      "Our final dataset to train has 24181090 rows and 18 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "calendar, sell_prices, sales_train_validation, submission = read_data()\n",
    "\n",
    "data = melt_and_merge(calendar, sell_prices, sales_train_validation, submission, nrows = 35000000, merge = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the function below to control what the start date of the data is (format the start_date argument as a string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def truncate(data, start_date):\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "    mask = (data['date'] > start_date)\n",
    "    data = data.loc[mask]\n",
    "    data.head()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_114_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_114</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.969727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_115_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_115</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.470703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_116_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_116</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_117_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_117</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_118_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_118</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_114_WI_3_validation  HOBBIES_2_114  HOBBIES_2  HOBBIES     WI_3   \n",
       "1  HOBBIES_2_115_WI_3_validation  HOBBIES_2_115  HOBBIES_2  HOBBIES     WI_3   \n",
       "2  HOBBIES_2_116_WI_3_validation  HOBBIES_2_116  HOBBIES_2  HOBBIES     WI_3   \n",
       "3  HOBBIES_2_117_WI_3_validation  HOBBIES_2_117  HOBBIES_2  HOBBIES     WI_3   \n",
       "4  HOBBIES_2_118_WI_3_validation  HOBBIES_2_118  HOBBIES_2  HOBBIES     WI_3   \n",
       "\n",
       "  state_id  demand   part        date  wm_yr_wk event_name_1 event_type_1  \\\n",
       "0       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "1       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "2       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "3       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "4       WI       1  train  2014-03-21     11407          NaN          NaN   \n",
       "\n",
       "  event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0          NaN          NaN        0        0        0    1.969727  \n",
       "1          NaN          NaN        0        0        0    2.470703  \n",
       "2          NaN          NaN        0        0        0    2.970703  \n",
       "3          NaN          NaN        0        0        0    2.769531  \n",
       "4          NaN          NaN        0        0        0    3.970703  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del calendar, sell_prices, sales_train_validation, submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can use the cell below to get an EDA of a WRMSSE breakdown of a submission (haven't used this before though and we probably don't need it since you already made one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d5d02fab0241718b56eb6bae4fc4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import gc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "class WRMSSEEvaluator_dashboard(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 'all'  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')]\\\n",
    "                     .columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')]\\\n",
    "                               .columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], \n",
    "                                 axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)\\\n",
    "                    [valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns]\\\n",
    "                    .set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index()\\\n",
    "                   .rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left',\n",
    "                                    on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd'])\\\n",
    "                    .unstack(level=2)['value']\\\n",
    "                    .loc[zip(self.train_df.item_id, self.train_df.store_id), :]\\\n",
    "                    .reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns],\n",
    "                               weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt) \n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, \n",
    "                                       np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape \\\n",
    "               == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, \n",
    "                                       columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], \n",
    "                                 valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "\n",
    "            valid_preds_grp = valid_preds.groupby(group_id)[self.valid_target_columns].sum()\n",
    "            setattr(self, f'lv{i + 1}_valid_preds', valid_preds_grp)\n",
    "            \n",
    "            lv_scores = self.rmsse(valid_preds_grp, i + 1)\n",
    "            setattr(self, f'lv{i + 1}_scores', lv_scores)\n",
    "            \n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, \n",
    "                                  sort=False).prod(axis=1)\n",
    "            \n",
    "            all_scores.append(lv_scores.sum())\n",
    "            \n",
    "        self.all_scores = all_scores\n",
    "\n",
    "        return np.mean(all_scores)\n",
    "    \n",
    "\n",
    "    \n",
    "def create_viz_df(df,lv):\n",
    "    \n",
    "    df = df.T.reset_index()\n",
    "    if lv in [6,7,8,9,11,12]:\n",
    "        df.columns = [i[0] + '_' + i[1] if i != ('index','') \\\n",
    "                      else i[0] for i in df.columns]\n",
    "    df = df.merge(calendar.loc[:, ['d','date']], how='left', \n",
    "                  left_on='index', right_on='d')\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    df = df.set_index('date')\n",
    "    df = df.drop(['index', 'd'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_dashboard(evaluator, by_level_only=False, model_name=None):\n",
    "    \n",
    "    wrmsses = [np.mean(evaluator.all_scores)] + evaluator.all_scores\n",
    "    labels = ['Overall'] + [f'Level {i}' for i in range(1, 13)]\n",
    "\n",
    "    ## WRMSSE by Level\n",
    "    plt.figure(figsize=(12,5))\n",
    "    ax = sns.barplot(x=labels, y=wrmsses)\n",
    "    ax.set(xlabel='', ylabel='WRMSSE')\n",
    "    \n",
    "    #######################ALTERATION##########################\n",
    "    title = 'WRMSSE by Level'\n",
    "    if model_name: \n",
    "        title = f'WRMSSE by Level for {model_name}'\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    #######################ALTERATION-COMPLETE##########################\n",
    "\n",
    "  \n",
    "    for index, val in enumerate(wrmsses):\n",
    "        ax.text(index*1, val+.01, round(val,4), color='black', \n",
    "                ha=\"center\")\n",
    "        \n",
    "    #######################ALTERATION##########################\n",
    "    if by_level_only:       # stops function early for quick plotting of \n",
    "        plt.show()          # for quick plotting of levels\n",
    "        return\n",
    "    #######################ALTERATION-COMPLETE##########################\n",
    "\n",
    "    # configuration array for the charts\n",
    "    n_rows = [1, 1, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    n_cols = [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    width = [7, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
    "    height = [4, 3, 12, 3, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "    \n",
    "    for i in range(1,13):\n",
    "        \n",
    "        scores = getattr(evaluator, f'lv{i}_scores')\n",
    "        weights = getattr(evaluator, f'lv{i}_weight')\n",
    "        \n",
    "        if i > 1 and i < 9:\n",
    "            if i < 7:\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "            else:\n",
    "                fig, axs = plt.subplots(2, 1, figsize=(12, 8))\n",
    "                \n",
    "            ## RMSSE plot\n",
    "            scores.plot.bar(width=.8, ax=axs[0], color='g')\n",
    "            axs[0].set_title(f\"RMSSE\", size=14)\n",
    "            axs[0].set(xlabel='', ylabel='RMSSE')\n",
    "            if i >= 4:\n",
    "                axs[0].tick_params(labelsize=8)\n",
    "            for index, val in enumerate(scores):\n",
    "                axs[0].text(index*1, val+.01, round(val,4), color='black', \n",
    "                            ha=\"center\", fontsize=10 if i == 2 else 8)\n",
    "            \n",
    "            ## Weight plot\n",
    "            weights.plot.bar(width=.8, ax=axs[1])\n",
    "            axs[1].set_title(f\"Weight\", size=14)\n",
    "            axs[1].set(xlabel='', ylabel='Weight')\n",
    "            if i >= 4:\n",
    "                axs[1].tick_params(labelsize=8)\n",
    "            for index, val in enumerate(weights):\n",
    "                axs[1].text(index*1, val+.01, round(val,2), color='black', \n",
    "                            ha=\"center\", fontsize=10 if i == 2 else 8)\n",
    "                    \n",
    "            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 ,\n",
    "                         y=1.1, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        trn = create_viz_df(getattr(evaluator, f'lv{i}_train_df')\\\n",
    "                            .iloc[:, -28*3:], i)\n",
    "        val = create_viz_df(getattr(evaluator, f'lv{i}_valid_df'), i)\n",
    "        pred = create_viz_df(getattr(evaluator, f'lv{i}_valid_preds'), i)\n",
    "\n",
    "        n_cate = trn.shape[1] if i < 7 else 9\n",
    "\n",
    "        fig, axs = plt.subplots(n_rows[i-1], n_cols[i-1], \n",
    "                                figsize=(width[i-1],height[i-1]))\n",
    "        if i > 1:\n",
    "            axs = axs.flatten()\n",
    "\n",
    "        ## Time series plot\n",
    "        for k in range(0, n_cate):\n",
    "\n",
    "            ax = axs[k] if i > 1 else axs\n",
    "\n",
    "            trn.iloc[:, k].plot(ax=ax, label='train')\n",
    "            val.iloc[:, k].plot(ax=ax, label='valid')\n",
    "            pred.iloc[:, k].plot(ax=ax, label='pred')\n",
    "            ax.set_title(f\"{trn.columns[k]}  RMSSE:{scores[k]:.4f}\", size=14)\n",
    "            ax.set(xlabel='', ylabel='sales')\n",
    "            ax.tick_params(labelsize=8)\n",
    "            ax.legend(loc='upper left', prop={'size': 10})\n",
    "\n",
    "        if i == 1 or i >= 9:\n",
    "            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 , \n",
    "                         y=1.1, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "train_df = pd.read_csv('sales_train_evaluation.csv')\n",
    "calendar_df = pd.read_csv('calendar.csv')\n",
    "sell_prices_df = pd.read_csv('sell_prices.csv')\n",
    "\n",
    "train_fold_df = train_df.iloc[:, :-28]\n",
    "valid_fold_df = train_fold_df.iloc[:, -28:].copy()\n",
    "# Instantiate an evaluator for scoring validation periodstarting day 1886\n",
    "e = WRMSSEEvaluator_dashboard(train_fold_df, valid_fold_df, calendar_df, sell_prices_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore all stuff until the next markdown cell (was just trying to make a WRMSSE metric before I found the evaluator class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sale</th>\n",
       "      <th>d</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sale_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id store_id        item_id  sale       d  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     CA_1  HOBBIES_1_001     1  d_1886   \n",
       "1  HOBBIES_1_002_CA_1_validation     CA_1  HOBBIES_1_002     1  d_1886   \n",
       "2  HOBBIES_1_003_CA_1_validation     CA_1  HOBBIES_1_003     0  d_1886   \n",
       "3  HOBBIES_1_004_CA_1_validation     CA_1  HOBBIES_1_004     0  d_1886   \n",
       "4  HOBBIES_1_005_CA_1_validation     CA_1  HOBBIES_1_005     1  d_1886   \n",
       "\n",
       "   sell_price  sale_usd  \n",
       "0    8.257812  8.257812  \n",
       "1    3.970703  3.970703  \n",
       "2    2.970703  0.000000  \n",
       "3    4.640625  0.000000  \n",
       "4    2.880859  2.880859  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"d_{}\".format(i) for i in range(1914-28, 1914)]\n",
    "lastdata = sales_train_validation[[\"id\", 'store_id', 'item_id'] + cols]\n",
    "\n",
    "lastdata = lastdata.melt(id_vars=[\"id\", 'store_id', 'item_id'], \n",
    "                 var_name=\"d\", value_name=\"sale\")\n",
    "\n",
    "lastdata = pd.merge(lastdata, calendar, how = 'left', \n",
    "                left_on = ['d'], right_on = ['d'])\n",
    "\n",
    "lastdata = lastdata[[\"id\", 'store_id', 'item_id', \"sale\", \"d\", \"wm_yr_wk\"]]\n",
    "\n",
    "lastdata = lastdata.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "lastdata.drop(columns = ['wm_yr_wk'], inplace=True)\n",
    "\n",
    "lastdata['sale_usd'] = lastdata['sale'] * lastdata['sell_price']\n",
    "lastdata.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840, 30490)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_list = [sales.state_id, sales.store_id, \n",
    "                sales.cat_id, sales.dept_id, \n",
    "                sales.state_id +'_'+ sales.cat_id, sales.state_id +'_'+ sales.dept_id,\n",
    "                sales.store_id +'_'+ sales.cat_id, sales.store_id +'_'+ sales.dept_id, \n",
    "                sales.item_id, sales.state_id +'_'+ sales.item_id, sales.id]\n",
    "\n",
    "\n",
    "dummies_df_list =[pd.DataFrame(np.ones(sales.shape[0]).astype(np.int8), \n",
    "                               index=sales.index, columns=['all']).T]\n",
    "\n",
    "for i, cats in enumerate(dummies_list):\n",
    "    dummies_df_list +=[pd.get_dummies(cats, drop_first=False, dtype=np.int8).T]\n",
    "    \n",
    "roll_mat_df = pd.concat(dummies_df_list, keys=list(range(12)), \n",
    "                        names=['level','id'])#.astype(np.int8, copy=False)\n",
    "\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "roll_mat_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll_mat_df.to_pickle('roll_mat_df.pkl')\n",
    "del dummies_df_list, roll_mat_df, sales_train_validation, calendar, sell_prices\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(drop_days=0):\n",
    "    d_name = ['d_' + str(i+1) for i in range(1913-drop_days)]\n",
    "    sales_train_val = roll_mat_csr * sales[d_name].values\n",
    "\n",
    "    no_sales = np.cumsum(sales_train_val, axis=1) == 0\n",
    "    sales_train_val = np.where(no_sales, np.nan, sales_train_val)\n",
    "\n",
    "    weight1 = np.nanmean(np.diff(sales_train_val,axis=1)**2,axis=1)\n",
    "    \n",
    "    return weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = get_s(drop_days=0)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w(sale_usd):\n",
    "\n",
    "    total_sales_usd = sale_usd.groupby(\n",
    "        ['id'], sort=False)['sale_usd'].apply(np.sum).values\n",
    "    weight2 = roll_mat_csr * total_sales_usd\n",
    "\n",
    "    return 12*weight2/np.sum(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_w(lastdata[['id','sale_usd']])\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SW = W/np.sqrt(S)\n",
    "sw_df = pd.DataFrame(np.stack((S, W, SW), axis=-1),index = roll_index,columns=['s','w','sw'])\n",
    "sw_df.to_pickle('sw_df.pkl')\n",
    "\n",
    "del W_original_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollup(v):\n",
    "    return roll_mat_csr*v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_df = pd.read_pickle('sw_df.pkl')\n",
    "S = sw_df.s.values\n",
    "W = sw_df.w.values\n",
    "SW = sw_df.sw.values\n",
    "\n",
    "roll_mat_df = pd.read_pickle('roll_mat_df.pkl')\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "del roll_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del lastdata, sw_df, W_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrmsse_eval(preds, y_true, s = S, w = W, sw = SW):\n",
    "    score = np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds.values-y_true.values))\n",
    "                            ,axis=1)) * sw)/12 \n",
    "\n",
    "    return \"WRMSSE\", score, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The transform function simply label encodes the categorical features and add in some additional data features by breaking it down into month, day, year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def transform(data):\n",
    "    \n",
    "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for feature in nan_features:\n",
    "        data[feature].fillna('unknown', inplace = True)\n",
    "        \n",
    "    cat = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for feature in cat:\n",
    "        encoder = LabelEncoder()\n",
    "        data[feature] = encoder.fit_transform(data[feature])\n",
    "        \n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    time_features = ['year', 'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear']\n",
    "    dtype = np.int16\n",
    "    for time_feature in time_features:\n",
    "        data[time_feature] = getattr(data['date'].dt, time_feature).astype(dtype)\n",
    "        \n",
    "    data = reduce_mem_usage(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1383.65 Mb (54.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "item_id               0\n",
       "dept_id               0\n",
       "cat_id                0\n",
       "store_id              0\n",
       "state_id              0\n",
       "demand                0\n",
       "part                  0\n",
       "date                  0\n",
       "wm_yr_wk              0\n",
       "event_name_1          0\n",
       "event_type_1          0\n",
       "event_name_2          0\n",
       "event_type_2          0\n",
       "snap_CA               0\n",
       "snap_TX               0\n",
       "snap_WI               0\n",
       "sell_price       591425\n",
       "year                  0\n",
       "month                 0\n",
       "quarter               0\n",
       "week                  0\n",
       "day                   0\n",
       "dayofweek             0\n",
       "dayofyear             0\n",
       "imputed_price    591425\n",
       "combined              0\n",
       "scaled_weight         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the function that generates the features. All of the comemnted stuff are things I think we should try. The features I commented out were just bad features but I think the weighted average will be good once implemented correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in event proximity at some point, see if it gives good results in conjunction with other features\n",
    "#add in feature to capture state-specific SNAP dates - namely SNAP occurs in first half of month \n",
    "#maybe add in a low vs high price feature - notice that FOOD3 is particularly low priced\n",
    "#there is a state by state variation in how different event types affect sales \n",
    "#price lag? we already have price momentum \n",
    "#add in weather data, that definitely influnces sales \n",
    "#add in features that captures ARIMA stuff - like auto-correlation, integration, moving average -\n",
    "#or just run ARIMA model in emsembles \n",
    "#capture population change in each state \n",
    "#math transformations \n",
    "#how are we addressing out of stock values\n",
    "#weekend vs not weekend\n",
    "#week momentum instead of daily\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "def new_features(data):\n",
    "    \n",
    "    data_fe = data[['id', 'demand']]\n",
    "    \n",
    "    window = 28\n",
    "    periods = [1, 2, 3, 4, 5, 6, 7]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    # most recent lag data\n",
    "    for period in periods:\n",
    "        data_fe['demand_rolling_mean_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).mean())\n",
    "        data_fe['demand_rolling_std_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).std())\n",
    "        data_fe['sales_lag_t' + str(period)] = group.transform(lambda x: x.shift(window + period))\n",
    "    \n",
    "    \n",
    "    def get_season(date):\n",
    "        year = str(date.year)\n",
    "        seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "                   'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "                   'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "        if date in seasons['spring']:\n",
    "            return 0\n",
    "        if date in seasons['summer']:\n",
    "            return 1\n",
    "        if date in seasons['autumn']:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    data_fe['season'] = data['date'].map(get_season)\n",
    "    \n",
    "    #data_fe['price_max'] = data.groupby('id')['sell_price'].transform('max')\n",
    "    #data_fe['price_min'] = data.groupby('id')['sell_price'].transform('min')\n",
    "    #data_fe['price_std'] = data.groupby('id')['sell_price'].transform('std')\n",
    "    #data_fe['price_mean'] = data.groupby('id')['sell_price'].transform('mean')  \n",
    "    \n",
    "    #data_fe['price_norm'] = data['sell_price']/data_fe['price_max']\n",
    "    #data_fe['price_nunique'] = data.groupby('id')['sell_price'].transform('nunique')\n",
    "    \n",
    "    #data_fe['price_momentum'] = data['sell_price']/data.groupby('id')['sell_price'].transform(lambda x: x.shift(1))\n",
    "    #data_fe['price_momentum_m'] = data['sell_price']/data.groupby(['id', 'month'])['sell_price'].transform('mean')\n",
    "    #data_fe['price_momentum_y'] = data['sell_price']/data.groupby(['id', 'year'])['sell_price'].transform('mean')\n",
    "    \n",
    "    #data_fe['sale_momentum_m'] = data['demand']/data.groupby(['id','month'])['demand'].transform('mean')\n",
    "    #data_fe['sale_momentum_y'] = data['demand']/data.groupby(['id','year'])['demand'].transform('mean')\n",
    "    \n",
    "    temp = data_fe\n",
    "\n",
    "    temp.set_index(data['date'])\n",
    "    weighted_periods = [1, 2, 3, 4, 5, 6, 7]\n",
    "    weighted_group = temp.groupby('id')['demand']\n",
    "    \n",
    "    #for weight in weighted_periods:\n",
    "        #data_fe['weighted_sales_t' + str(weight)] = weighted_group.transform(lambda x: x.ewm(span = weight + 28).mean())\n",
    "    \n",
    "    \n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe, temp\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_price(data):\n",
    "    data['imputed_price'] = data['sell_price'].fillna(method = 'ffill')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sell_price'] = data['sell_price'].astype('float32')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = impute_price(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.imputed_price.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   34408,    34409,    34410,    34411,    34412,    34413,\n",
      "               34414,    34415,    34416,    34417,\n",
      "            ...\n",
      "            23831513, 23831514, 23831515, 23831516, 23831517, 23831518,\n",
      "            23831519, 23831520, 23831521, 23831522],\n",
      "           dtype='int64', length=591425)\n"
     ]
    }
   ],
   "source": [
    "data['imputed_price'] = data['sell_price']\n",
    "\n",
    "rows = data[data.sell_price.isnull()].index\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591425"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['imputed_price'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "def new_features_daily(data):\n",
    "    \n",
    "    data_fe = data[['id', 'demand']]\n",
    "    \n",
    "    days = [1, 2, 3, 4, 5, 6, 7]\n",
    "    periods = [7, 28]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    # most recent lag data\n",
    "    for period in periods:\n",
    "        for day in days:\n",
    "            data_fe['demand_rolling_mean_t' + str(day) + \"_\" + str(period)] = group.transform(lambda x: x.shift(day).rolling(period).mean())\n",
    "            data_fe['demand_rolling_std_t' + str(day) + \"_\" + str(period)] = group.transform(lambda x: x.shift(day).rolling(period).std())\n",
    "            data_fe['sales_lag_t' + str(day)] = group.transform(lambda x: x.shift(day))\n",
    "\n",
    "    \n",
    "    def get_season(date):\n",
    "        year = str(date.year)\n",
    "        seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "                   'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "                   'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "        if date in seasons['spring']:\n",
    "            return 0\n",
    "        if date in seasons['summer']:\n",
    "            return 1\n",
    "        if date in seasons['autumn']:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    data_fe['season'] = data['date'].map(get_season)\n",
    "    \n",
    "    #data_fe['price_max'] = data.groupby('id')['sell_price'].transform('max')\n",
    "    #data_fe['price_min'] = data.groupby('id')['sell_price'].transform('min')\n",
    "    #data_fe['price_std'] = data.groupby('id')['sell_price'].transform('std')\n",
    "    #data_fe['price_mean'] = data.groupby('id')['sell_price'].transform('mean')  \n",
    "    \n",
    "    #data_fe['price_norm'] = data['sell_price']/data_fe['price_max']\n",
    "    #data_fe['price_nunique'] = data.groupby('id')['sell_price'].transform('nunique')\n",
    "    \n",
    "    #data_fe['price_momentum'] = data['sell_price']/data.groupby('id')['sell_price'].transform(lambda x: x.shift(1))\n",
    "    #data_fe['price_momentum_m'] = data['sell_price']/data.groupby(['id', 'month'])['sell_price'].transform('mean')\n",
    "    #data_fe['price_momentum_y'] = data['sell_price']/data.groupby(['id', 'year'])['sell_price'].transform('mean')\n",
    "    \n",
    "    #data_fe['sale_momentum_m'] = data['demand']/data.groupby(['id','month'])['demand'].transform('mean')\n",
    "    #data_fe['sale_momentum_y'] = data['demand']/data.groupby(['id','year'])['demand'].transform('mean')\n",
    "    \n",
    "    #temp = data_fe\n",
    "\n",
    "    #temp.set_index(data['date'])\n",
    "    #weighted_periods = [1, 2, 3, 4, 5, 6, 7]\n",
    "    #weighted_group = temp.groupby('id')['demand']\n",
    "    \n",
    "    #for weight in weighted_periods:\n",
    "        #data_fe['weighted_sales_t' + str(weight)] = weighted_group.transform(lambda x: x.ewm(span = weight + 28).mean())\n",
    "    \n",
    "    \n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe\n",
    "    gc.collect()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "def new_features_weekly(data):\n",
    "    \n",
    "    data_fe = data[['id', 'demand']]\n",
    "    \n",
    "    days = [1, 2, 3, 4, 5, 6, 7]\n",
    "    periods = [7, 28]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    # most recent lag data\n",
    "    for period in periods:\n",
    "        for day in days:\n",
    "            data_fe['demand_rolling_mean_t' + str(day) + \"_\" + str(period)] = group.transform(lambda x: x.shift(day).rolling(period).mean())\n",
    "            data_fe['demand_rolling_std_t' + str(day) + \"_\" + str(period)] = group.transform(lambda x: x.shift(day).rolling(period).std())\n",
    "            data_fe['sales_lag_t' + str(day)] = group.transform(lambda x: x.shift(day))\n",
    "\n",
    "    \n",
    "    def get_season(date):\n",
    "        year = str(date.year)\n",
    "        seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "                   'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "                   'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "        if date in seasons['spring']:\n",
    "            return 0\n",
    "        if date in seasons['summer']:\n",
    "            return 1\n",
    "        if date in seasons['autumn']:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    data_fe['season'] = data['date'].map(get_season)\n",
    "    \n",
    "    #data_fe['price_max'] = data.groupby('id')['sell_price'].transform('max')\n",
    "    #data_fe['price_min'] = data.groupby('id')['sell_price'].transform('min')\n",
    "    #data_fe['price_std'] = data.groupby('id')['sell_price'].transform('std')\n",
    "    #data_fe['price_mean'] = data.groupby('id')['sell_price'].transform('mean')  \n",
    "    \n",
    "    #data_fe['price_norm'] = data['sell_price']/data_fe['price_max']\n",
    "    #data_fe['price_nunique'] = data.groupby('id')['sell_price'].transform('nunique')\n",
    "    \n",
    "    #data_fe['price_momentum'] = data['sell_price']/data.groupby('id')['sell_price'].transform(lambda x: x.shift(1))\n",
    "    #data_fe['price_momentum_m'] = data['sell_price']/data.groupby(['id', 'month'])['sell_price'].transform('mean')\n",
    "    #data_fe['price_momentum_y'] = data['sell_price']/data.groupby(['id', 'year'])['sell_price'].transform('mean')\n",
    "    \n",
    "    #data_fe['sale_momentum_m'] = data['demand']/data.groupby(['id','month'])['demand'].transform('mean')\n",
    "    #data_fe['sale_momentum_y'] = data['demand']/data.groupby(['id','year'])['demand'].transform('mean')\n",
    "    \n",
    "    #temp = data_fe\n",
    "\n",
    "    #temp.set_index(data['date'])\n",
    "    #weighted_periods = [1, 2, 3, 4, 5, 6, 7]\n",
    "    #weighted_group = temp.groupby('id')['demand']\n",
    "    \n",
    "    #for weight in weighted_periods:\n",
    "        #data_fe['weighted_sales_t' + str(weight)] = weighted_group.transform(lambda x: x.ewm(span = weight + 28).mean())\n",
    "    \n",
    "    \n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe\n",
    "    gc.collect()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore the stuff until the next markdown cell. Just my attempts from earlier to create custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweedie_eval(y_pred, y_true, p=1.5):\n",
    "    y_true = y_true.get_label()\n",
    "    a = y_true*np.exp(y_pred, (1-p)) / (1-p)\n",
    "    b = np.exp(y_pred, (2-p))/(2-p)\n",
    "    loss = -a + b\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del rect, rec\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr_w = tr_x[ID_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "id\n",
      "item_id\n",
      "dept_id\n",
      "cat_id\n",
      "store_id\n",
      "state_id\n",
      "demand\n",
      "part\n",
      "date\n",
      "wm_yr_wk\n",
      "event_name_1\n",
      "event_type_1\n",
      "event_name_2\n",
      "event_type_2\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "sell_price\n",
      "gaps\n",
      "gap_confirm\n",
      "out_of_stock\n",
      "true\n",
      "imputed_demand\n",
      "year\n",
      "month\n",
      "quarter\n",
      "week\n",
      "day\n",
      "dayofweek\n",
      "dayofyear\n",
      "lag_28\n",
      "lag_29\n",
      "lag_35\n",
      "lag_42\n",
      "lag_56\n",
      "shift_1_rolling_mean_7\n",
      "shift_1_rolling_std_7\n",
      "shift_1_rolling_mean_14\n",
      "shift_1_rolling_std_14\n",
      "shift_1_rolling_mean_28\n",
      "shift_1_rolling_std_28\n",
      "shift_28_rolling_mean_7\n",
      "shift_28_rolling_mean_14\n",
      "shift_28_rolling_mean_28\n",
      "combined\n",
      "scaled_weight\n",
      "shift_28_rolling_std_7\n",
      "shift_28_rolling_std_14\n",
      "shift_28_rolling_std_28\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "\n",
    "tr_x = data[data['date']<='2016-03-27']\n",
    "tr_w = tr_x[ID_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level2</td>\n",
       "      <td>CA</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level2</td>\n",
       "      <td>TX</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level2</td>\n",
       "      <td>WI</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Level_id Agg_Level_1 Agg_Level_2  scaled_weight\n",
       "1   Level2          CA           X       0.000163\n",
       "2   Level2          TX           X       0.000147\n",
       "3   Level2          WI           X       0.000149"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level = wdf[wdf.Level_id == 'Level2']\n",
    "encoder = LabelEncoder()\n",
    "level['state_id'] = encoder.fit_transform(level['state_id'])\n",
    "level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level2</td>\n",
       "      <td>CA</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level2</td>\n",
       "      <td>TX</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level2</td>\n",
       "      <td>WI</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level3</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Level_id Agg_Level_1 Agg_Level_2  scaled_weight\n",
       "0   Level1       Total           X       0.000169\n",
       "1   Level2          CA           X       0.000163\n",
       "2   Level2          TX           X       0.000147\n",
       "3   Level2          WI           X       0.000149\n",
       "4   Level3        CA_1           X       0.000128"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "wdf = pd.read_csv('weight_scale_1914.csv')\n",
    "wdf['scaled_weight'] = wdf.weight/np.sqrt(wdf.scale)\n",
    "wdf = wdf[[ 'Level_id', 'Agg_Level_1', 'Agg_Level_2','scaled_weight']]\n",
    "\n",
    "\n",
    "######################### level 1 #######################################\n",
    "tr_w['level_1_sw'] = wdf.loc[wdf['Level_id'] == 'Level1', 'scaled_weight'][0]\n",
    "\n",
    "######################### level 2 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level2']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level['state_id'] = encoder.fit_transform(level['state_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id']], level[['state_id', 'scaled_weight']],\n",
    "                               on='state_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_2_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 3 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level3']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'store_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level['store_id'] = encoder.fit_transform(level['store_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['store_id']], level[['store_id', 'scaled_weight']],\n",
    "                               on='store_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_3_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 4 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level4']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'cat_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level['cat_id'] = encoder.fit_transform(level['cat_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['cat_id']], level[['cat_id', 'scaled_weight']],\n",
    "                               on='cat_id', how='left')[['scaled_weight']]\n",
    "tr_w['level_4_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 5 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level5']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'dept_id', 'Agg_Level_2', 'scaled_weight']\n",
    "level['dept_id'] = encoder.fit_transform(level['dept_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['dept_id']], level[['dept_id', 'scaled_weight']],\n",
    "                               on='dept_id', how='left')[['scaled_weight']]\n",
    "                                        \n",
    "tr_w['level_5_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 6 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level6']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'cat_id', 'scaled_weight']\n",
    "level['state_id'] = encoder.fit_transform(level['state_id'])\n",
    "level['cat_id'] = encoder.fit_transform(level['cat_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id', 'cat_id']], level[['state_id', 'cat_id', 'scaled_weight']],\n",
    "                               on=['state_id', 'cat_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_6_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 7 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level7']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'dept_id', 'scaled_weight']\n",
    "level['state_id'] = encoder.fit_transform(level['state_id'])\n",
    "level['dept_id'] = encoder.fit_transform(level['dept_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id', 'dept_id']], level[['state_id', 'dept_id', 'scaled_weight']],\n",
    "                               on=['state_id', 'dept_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_7_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 8 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level8']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'store_id', 'cat_id', 'scaled_weight']\n",
    "level['store_id'] = encoder.fit_transform(level['store_id'])\n",
    "level['cat_id'] = encoder.fit_transform(level['cat_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['store_id', 'cat_id']], level[['store_id', 'cat_id', 'scaled_weight']],\n",
    "                               on=['store_id', 'cat_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_8_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 9 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level9']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'store_id', 'dept_id', 'scaled_weight']\n",
    "level['store_id'] = encoder.fit_transform(level['store_id'])\n",
    "level['dept_id'] = encoder.fit_transform(level['dept_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['store_id', 'dept_id']], level[['store_id', 'dept_id', 'scaled_weight']],\n",
    "                               on=['store_id', 'dept_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_9_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 10 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level10']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'item_id', 'dept_id', 'scaled_weight']\n",
    "level['item_id'] = encoder.fit_transform(level['item_id'])\n",
    "level['dept_id'] = encoder.fit_transform(level['dept_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['item_id']], level[['item_id', 'scaled_weight']],\n",
    "                               on=['item_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_10_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 11 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level11']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'state_id', 'item_id', 'scaled_weight']\n",
    "level['state_id'] = encoder.fit_transform(level['state_id'])\n",
    "level['item_id'] = encoder.fit_transform(level['item_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['state_id', 'item_id']], level[['state_id', 'item_id', 'scaled_weight']],\n",
    "                               on=['state_id', 'item_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_11_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight\n",
    "\n",
    "######################### level 12 #######################################\n",
    "level = wdf[wdf.Level_id == 'Level12']\n",
    "# Set the name of the aggregation column to match \n",
    "# the column in our id columns\n",
    "level.columns = ['Level_id', 'item_id', 'store_id', 'scaled_weight']\n",
    "level['store_id'] = encoder.fit_transform(level['store_id'])\n",
    "level['item_id'] = encoder.fit_transform(level['item_id'])\n",
    "level_scaled_weight = pd.merge(tr_w[['item_id', 'store_id']], level[['item_id', 'store_id', 'scaled_weight']],\n",
    "                               on=['item_id', 'store_id'], how='left')[['scaled_weight']]\n",
    "tr_w['level_12_sw'] = level_scaled_weight['scaled_weight'].values\n",
    "\n",
    "del level, level_scaled_weight, wdf\n",
    "gc.collect()\n",
    "\n",
    "cols = [col for col in tr_w.columns if 'level' in col]\n",
    "tr_w = tr_w[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_1_rolling_mean_28</th>\n",
       "      <th>shift_1_rolling_std_28</th>\n",
       "      <th>shift_28_rolling_mean_7</th>\n",
       "      <th>shift_28_rolling_mean_14</th>\n",
       "      <th>shift_28_rolling_mean_28</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "      <th>shift_28_rolling_std_7</th>\n",
       "      <th>shift_28_rolling_std_14</th>\n",
       "      <th>shift_28_rolling_std_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19361140</th>\n",
       "      <td>22473640</td>\n",
       "      <td>FOODS_3_818_WI_3_validation</td>\n",
       "      <td>1427</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178589</td>\n",
       "      <td>0.383057</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>FOODS_3_818_WI_3_validation</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.451660</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.508789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361141</th>\n",
       "      <td>22473641</td>\n",
       "      <td>FOODS_3_819_WI_3_validation</td>\n",
       "      <td>1428</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.646973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>FOODS_3_819_WI_3_validation</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699707</td>\n",
       "      <td>0.646973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361142</th>\n",
       "      <td>22473642</td>\n",
       "      <td>FOODS_3_820_WI_3_validation</td>\n",
       "      <td>1429</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>FOODS_3_820_WI_3_validation</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361143</th>\n",
       "      <td>22473643</td>\n",
       "      <td>FOODS_3_821_WI_3_validation</td>\n",
       "      <td>1430</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>FOODS_3_821_WI_3_validation</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.349854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361144</th>\n",
       "      <td>22473644</td>\n",
       "      <td>FOODS_3_822_WI_3_validation</td>\n",
       "      <td>1431</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.309326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FOODS_3_822_WI_3_validation</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361145</th>\n",
       "      <td>22473645</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.600586</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.699707</td>\n",
       "      <td>0.622559</td>\n",
       "      <td>0.524902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361146</th>\n",
       "      <td>22473646</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178589</td>\n",
       "      <td>0.383057</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.309326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361147</th>\n",
       "      <td>22473647</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.257568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361148</th>\n",
       "      <td>22473648</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361149</th>\n",
       "      <td>22473649</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.309326</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.257568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index                           id  item_id  dept_id  cat_id  \\\n",
       "19361140  22473640  FOODS_3_818_WI_3_validation     1427        2       0   \n",
       "19361141  22473641  FOODS_3_819_WI_3_validation     1428        2       0   \n",
       "19361142  22473642  FOODS_3_820_WI_3_validation     1429        2       0   \n",
       "19361143  22473643  FOODS_3_821_WI_3_validation     1430        2       0   \n",
       "19361144  22473644  FOODS_3_822_WI_3_validation     1431        2       0   \n",
       "19361145  22473645  FOODS_3_823_WI_3_validation     1432        2       0   \n",
       "19361146  22473646  FOODS_3_824_WI_3_validation     1433        2       0   \n",
       "19361147  22473647  FOODS_3_825_WI_3_validation     1434        2       0   \n",
       "19361148  22473648  FOODS_3_826_WI_3_validation     1435        2       0   \n",
       "19361149  22473649  FOODS_3_827_WI_3_validation     1436        2       0   \n",
       "\n",
       "          store_id  state_id  demand   part       date  ...  \\\n",
       "19361140         9         2       0  train 2016-03-27  ...   \n",
       "19361141         9         2       1  train 2016-03-27  ...   \n",
       "19361142         9         2       2  train 2016-03-27  ...   \n",
       "19361143         9         2       1  train 2016-03-27  ...   \n",
       "19361144         9         2       5  train 2016-03-27  ...   \n",
       "19361145         9         2       0  train 2016-03-27  ...   \n",
       "19361146         9         2       0  train 2016-03-27  ...   \n",
       "19361147         9         2       1  train 2016-03-27  ...   \n",
       "19361148         9         2       4  train 2016-03-27  ...   \n",
       "19361149         9         2       5  train 2016-03-27  ...   \n",
       "\n",
       "          shift_1_rolling_mean_28  shift_1_rolling_std_28  \\\n",
       "19361140                 0.178589                0.383057   \n",
       "19361141                 0.285645                0.646973   \n",
       "19361142                 0.071411                0.257568   \n",
       "19361143                 0.035706                0.185547   \n",
       "19361144                 0.107117                0.309326   \n",
       "19361145                 0.321533                0.600586   \n",
       "19361146                 0.178589                0.383057   \n",
       "19361147                 0.071411                0.257568   \n",
       "19361148                 0.035706                0.185547   \n",
       "19361149                 0.107117                0.309326   \n",
       "\n",
       "          shift_28_rolling_mean_7  shift_28_rolling_mean_14  \\\n",
       "19361140                 0.285645                  0.214233   \n",
       "19361141                 0.000000                  0.285645   \n",
       "19361142                 0.142822                  0.071411   \n",
       "19361143                 0.142822                  0.071411   \n",
       "19361144                 0.000000                  0.000000   \n",
       "19361145                 0.714355                  0.428467   \n",
       "19361146                 0.142822                  0.214233   \n",
       "19361147                 0.142822                  0.071411   \n",
       "19361148                 0.142822                  0.071411   \n",
       "19361149                 0.142822                  0.071411   \n",
       "\n",
       "          shift_28_rolling_mean_28                     combined  \\\n",
       "19361140                  0.250000  FOODS_3_818_WI_3_validation   \n",
       "19361141                  0.285645  FOODS_3_819_WI_3_validation   \n",
       "19361142                  0.142822  FOODS_3_820_WI_3_validation   \n",
       "19361143                  0.142822  FOODS_3_821_WI_3_validation   \n",
       "19361144                  0.000000  FOODS_3_822_WI_3_validation   \n",
       "19361145                  0.285645  FOODS_3_823_WI_3_validation   \n",
       "19361146                  0.107117  FOODS_3_824_WI_3_validation   \n",
       "19361147                  0.071411  FOODS_3_825_WI_3_validation   \n",
       "19361148                  0.142822  FOODS_3_826_WI_3_validation   \n",
       "19361149                  0.071411  FOODS_3_827_WI_3_validation   \n",
       "\n",
       "          scaled_weight  shift_28_rolling_std_7  shift_28_rolling_std_14  \\\n",
       "19361140       0.000020                0.451660                 0.410400   \n",
       "19361141       0.000011                0.000000                 0.699707   \n",
       "19361142       0.000014                0.349854                 0.257568   \n",
       "19361143       0.000017                0.349854                 0.257568   \n",
       "19361144       0.000021                0.000000                 0.000000   \n",
       "19361145       0.000004                0.699707                 0.622559   \n",
       "19361146       0.000006                0.349854                 0.410400   \n",
       "19361147       0.000018                0.349854                 0.257568   \n",
       "19361148       0.000006                0.349854                 0.257568   \n",
       "19361149       0.000003                0.349854                 0.257568   \n",
       "\n",
       "          shift_28_rolling_std_28  \n",
       "19361140                 0.508789  \n",
       "19361141                 0.646973  \n",
       "19361142                 0.440430  \n",
       "19361143                 0.349854  \n",
       "19361144                 0.000000  \n",
       "19361145                 0.524902  \n",
       "19361146                 0.309326  \n",
       "19361147                 0.257568  \n",
       "19361148                 0.440430  \n",
       "19361149                 0.257568  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "\n",
    "roll_2 = csr_matrix(pd.get_dummies(tr_x.state_id.astype('str'),\n",
    "                                  drop_first=False).values)\n",
    "\n",
    "roll_3 = csr_matrix(pd.get_dummies(tr_x.store_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_4 = csr_matrix(pd.get_dummies(tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_5 = csr_matrix(pd.get_dummies(tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_6 = csr_matrix(pd.get_dummies(tr_x.state_id.astype('str') + tr_x.cat_id.astype('str') ,\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_7 = csr_matrix(pd.get_dummies(tr_x.state_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_8 = csr_matrix(pd.get_dummies(tr_x.store_id.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_9 = csr_matrix(pd.get_dummies(tr_x.store_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_10 = csr_matrix(pd.get_dummies(tr_x.item_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_11 = csr_matrix(pd.get_dummies(tr_x.state_id.astype('str') + tr_x.item_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_12 = csr_matrix(pd.get_dummies(tr_x.item_id.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                    drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_1 = csr_matrix(pd.get_dummies(tr_x.date, drop_first=False).values)\n",
    "\n",
    "roll_2 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str'),\n",
    "                                  drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_3 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_4 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_5 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_6 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str') + tr_x.cat_id.astype('str') ,\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_7 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_8 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.store_id.astype('str') + tr_x.cat_id.astype('str'),\n",
    "                                    drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_9 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.store_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_10 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.item_id.astype('str') + tr_x.dept_id.astype('str'),\n",
    "                                   drop_first=False).values)\n",
    "\n",
    "roll_11 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.state_id.astype('str') + tr_x.item_id.astype('str'),\n",
    "                                    drop_first=False).values)\n",
    "\n",
    "roll_12 = csr_matrix(pd.get_dummies(tr_x.date.astype('str') + tr_x.item_id.astype('str') + tr_x.store_id.astype('str'),\n",
    "                                    drop_first=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(roll, level_sw, actuals, preds, n, s):\n",
    "    diff = actuals - preds\n",
    "    diffsquared = np.square(diff)\n",
    "    \n",
    "    diff = np.reshape(diff,(roll.T.shape[1], -1))\n",
    "    diffsquared = np.reshape(diffsqaured,(roll.T.shape[1], -1))\n",
    "    \n",
    "    diff_sum = roll.T * diff\n",
    "    diffsquared_sum = roll.T * diffsquared\n",
    "\n",
    "    \n",
    "    return level_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(actuals, preds):\n",
    "    grad = gradient()\n",
    "    hess = hessian()\n",
    "    \n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function will prepare the weights and scales of level 12 and merge them to the data frame. The file contains weights and scales for all levels so if you wanted to access those you can just modify the function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(data):\n",
    "    weights = pd.read_csv(\"weight_scale_1914.csv\")\n",
    "    \n",
    "    weights = weights[[ 'Level_id', 'Agg_Level_1', 'Agg_Level_2','weight', 'scale']]\n",
    "    level_12 = weights[weights.Level_id == 'Level12']\n",
    "    \n",
    "    level_12['scaled_weight'] = level_12.weight/np.sqrt(level_12.scale)\n",
    "    level_12[\"combined\"] = level_12[\"Agg_Level_1\"] + '_' + level_12[\"Agg_Level_2\"] + \"_validation\"\n",
    "\n",
    "    temp_weights = level_12[['combined', 'scaled_weight']]\n",
    "    data = pd.merge(data, temp_weights, how = 'left', left_on = 'id', right_on = 'combined')\n",
    "    \n",
    "    del level_12, weights\n",
    "    gc.collect()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_weights(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['date', 'revenue', 'demand', 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'season', 'scaled_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>imputed_price</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-05</td>\n",
       "      <td>11410</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>11410</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  demand   part       date  wm_yr_wk  ...  year  month  quarter  \\\n",
       "0       CA       0  train 2014-04-02     11409  ...  2014      4        2   \n",
       "1       CA       0  train 2014-04-03     11409  ...  2014      4        2   \n",
       "2       CA       0  train 2014-04-04     11409  ...  2014      4        2   \n",
       "3       CA       0  train 2014-04-05     11410  ...  2014      4        2   \n",
       "4       CA       0  train 2014-04-06     11410  ...  2014      4        2   \n",
       "\n",
       "   week  day  dayofweek  dayofyear  imputed_price  \\\n",
       "0    14    2          2         92       8.257812   \n",
       "1    14    3          3         93       8.257812   \n",
       "2    14    4          4         94       8.257812   \n",
       "3    14    5          5         95       8.257812   \n",
       "4    14    6          6         96       8.257812   \n",
       "\n",
       "                        combined  scaled_weight  \n",
       "0  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "1  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "2  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "3  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "4  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1728.14 Mb (15.6% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>imputed_price</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337910</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337911</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337912</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337913</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337914</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>3.080078</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                             id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  337910  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  337911  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  337912  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  337913  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  337914  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id  demand   part       date  ...  year  month  quarter  week  day  \\\n",
       "0         0       0  train 2014-04-02  ...  2014      4        2    14    2   \n",
       "1         0       0  train 2014-04-02  ...  2014      4        2    14    2   \n",
       "2         0       0  train 2014-04-02  ...  2014      4        2    14    2   \n",
       "3         0       0  train 2014-04-02  ...  2014      4        2    14    2   \n",
       "4         0       2  train 2014-04-02  ...  2014      4        2    14    2   \n",
       "\n",
       "   dayofweek  dayofyear  imputed_price                       combined  \\\n",
       "0          2         92       8.257812  HOBBIES_1_001_CA_1_validation   \n",
       "1          2         92       3.970703  HOBBIES_1_002_CA_1_validation   \n",
       "2          2         92       2.970703  HOBBIES_1_003_CA_1_validation   \n",
       "3          2         92       4.640625  HOBBIES_1_004_CA_1_validation   \n",
       "4          2         92       3.080078  HOBBIES_1_005_CA_1_validation   \n",
       "\n",
       "   scaled_weight  \n",
       "0       0.000051  \n",
       "1       0.000003  \n",
       "2       0.000014  \n",
       "3       0.000024  \n",
       "4       0.000018  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.imputed_price.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['index']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neehaltumma/Library/Jupyter/runtime\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter --runtime-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       object\n",
      "revenue                   float64\n",
      "demand                      int64\n",
      "id                         object\n",
      "item_id                     int64\n",
      "dept_id                     int64\n",
      "cat_id                      int64\n",
      "store_id                    int64\n",
      "state_id                    int64\n",
      "event_name_1                int64\n",
      "event_type_1                int64\n",
      "event_name_2                int64\n",
      "event_type_2                int64\n",
      "snap_CA                     int64\n",
      "snap_TX                     int64\n",
      "snap_WI                     int64\n",
      "sell_price                float64\n",
      "year                        int64\n",
      "month                       int64\n",
      "quarter                     int64\n",
      "week                        int64\n",
      "day                         int64\n",
      "dayofweek                   int64\n",
      "dayofyear                   int64\n",
      "demand_rolling_mean_t1    float64\n",
      "demand_rolling_std_t1     float64\n",
      "sales_lag_t1              float64\n",
      "demand_rolling_mean_t2    float64\n",
      "demand_rolling_std_t2     float64\n",
      "sales_lag_t2              float64\n",
      "demand_rolling_mean_t3    float64\n",
      "demand_rolling_std_t3     float64\n",
      "sales_lag_t3              float64\n",
      "demand_rolling_mean_t4    float64\n",
      "demand_rolling_std_t4     float64\n",
      "sales_lag_t4              float64\n",
      "demand_rolling_mean_t5    float64\n",
      "demand_rolling_std_t5     float64\n",
      "sales_lag_t5              float64\n",
      "demand_rolling_mean_t6    float64\n",
      "demand_rolling_std_t6     float64\n",
      "sales_lag_t6              float64\n",
      "demand_rolling_mean_t7    float64\n",
      "demand_rolling_std_t7     float64\n",
      "sales_lag_t7              float64\n",
      "season                      int64\n",
      "gaps                        int64\n",
      "gap_days                  float64\n",
      "gap_confirm               float64\n",
      "out_of_stock              float64\n",
      "imputed_demand              int64\n",
      "combined                   object\n",
      "scaled_weight             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lightgbm 2.3.1\n",
      "Uninstalling lightgbm-2.3.1:\n",
      "  Successfully uninstalled lightgbm-2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip uninstall lightgbm --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>daily_scales</th>\n",
       "      <th>new_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3658800</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3658801</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.145767e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3658802</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3658803</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>1.5060</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5720</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.312132e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3658804</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.735425e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             id  item_id  dept_id  cat_id  \\\n",
       "0     3658800  HOBBIES_1_001_CA_1_validation     1437        3       1   \n",
       "1     3658801  HOBBIES_1_002_CA_1_validation     1438        3       1   \n",
       "2     3658802  HOBBIES_1_003_CA_1_validation     1439        3       1   \n",
       "3     3658803  HOBBIES_1_004_CA_1_validation     1440        3       1   \n",
       "4     3658804  HOBBIES_1_005_CA_1_validation     1441        3       1   \n",
       "\n",
       "   store_id  state_id  demand   part        date  ...  sales_lag_t5  \\\n",
       "0         0         0       0  train  2014-08-30  ...           1.0   \n",
       "1         0         0       1  train  2014-08-30  ...           1.0   \n",
       "2         0         0       0  train  2014-08-30  ...           0.0   \n",
       "3         0         0       3  train  2014-08-30  ...           2.0   \n",
       "4         0         0       3  train  2014-08-30  ...           1.0   \n",
       "\n",
       "   demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "0                  0.3333                 0.5166           1.0   \n",
       "1                  0.5000                 0.8364           0.0   \n",
       "2                  0.0000                 0.0000           0.0   \n",
       "3                  1.6670                 1.5060           8.0   \n",
       "4                  0.6665                 0.8164           2.0   \n",
       "\n",
       "   demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \\\n",
       "0                  0.4285                 0.5347           0.0       1   \n",
       "1                  0.4285                 0.7866           0.0       1   \n",
       "2                  0.0000                 0.0000           0.0       1   \n",
       "3                  2.5720                 2.7600           3.0       1   \n",
       "4                  0.8570                 0.9000           2.0       1   \n",
       "\n",
       "   daily_scales   new_weights  \n",
       "0           0.0  1.000000e-07  \n",
       "1           1.0  2.145767e-06  \n",
       "2           0.0  1.000000e-07  \n",
       "3           1.0  6.312132e-05  \n",
       "4           3.0  9.735425e-06  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '? (vectorized)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c20f3932f3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'notebook_env.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mload_session\u001b[0;34m(filename, main, **kwds)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#NOTE: if settings change, need to update attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m_ufunc_reconstruct\u001b[0;34m(module, name)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# scipy.special.expit for instance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ufunc_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute '? (vectorized)'"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore this stuff I was just testing something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = data[data['date'] <= '2016-04-24']\n",
    "TS = 30490\n",
    "val_filter = -((28 + 14)) * TS\n",
    "val_stopper = -((0 + 14)) * TS\n",
    "\n",
    "temp = x_train[\"demand\"].iloc[val_filter:val_stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>13.92</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>1.5060</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5720</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  revenue  demand                             id  item_id  \\\n",
       "0  2014-08-30     0.00       0  HOBBIES_1_001_CA_1_validation     1437   \n",
       "1  2014-08-30     3.97       1  HOBBIES_1_002_CA_1_validation     1438   \n",
       "2  2014-08-30     0.00       0  HOBBIES_1_003_CA_1_validation     1439   \n",
       "3  2014-08-30    13.92       3  HOBBIES_1_004_CA_1_validation     1440   \n",
       "4  2014-08-30     8.64       3  HOBBIES_1_005_CA_1_validation     1441   \n",
       "\n",
       "   dept_id  cat_id  store_id  state_id  event_name_1  ...  sales_lag_t5  \\\n",
       "0        3       1         0         0            30  ...           1.0   \n",
       "1        3       1         0         0            30  ...           1.0   \n",
       "2        3       1         0         0            30  ...           0.0   \n",
       "3        3       1         0         0            30  ...           2.0   \n",
       "4        3       1         0         0            30  ...           1.0   \n",
       "\n",
       "   demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "0                  0.3333                 0.5166           1.0   \n",
       "1                  0.5000                 0.8364           0.0   \n",
       "2                  0.0000                 0.0000           0.0   \n",
       "3                  1.6670                 1.5060           8.0   \n",
       "4                  0.6665                 0.8164           2.0   \n",
       "\n",
       "   demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \\\n",
       "0                  0.4285                 0.5347           0.0     1.0   \n",
       "1                  0.4285                 0.7866           0.0     1.0   \n",
       "2                  0.0000                 0.0000           0.0     1.0   \n",
       "3                  2.5720                 2.7600           3.0     1.0   \n",
       "4                  0.8570                 0.9000           2.0     1.0   \n",
       "\n",
       "                        combined  scaled_weight  \n",
       "0  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "1  HOBBIES_1_002_CA_1_validation       0.000003  \n",
       "2  HOBBIES_1_003_CA_1_validation       0.000014  \n",
       "3  HOBBIES_1_004_CA_1_validation       0.000024  \n",
       "4  HOBBIES_1_005_CA_1_validation       0.000018  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>...</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>gaps</th>\n",
       "      <th>gap_days</th>\n",
       "      <th>gap_confirm</th>\n",
       "      <th>out_of_stock</th>\n",
       "      <th>imputed_demand</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17562235</th>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.880371e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562236</th>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>352.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562237</th>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>1</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.866211e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562238</th>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>4</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562239</th>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>5</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.603516e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  demand                           id  item_id  dept_id  \\\n",
       "17562235  2016-03-27       0  FOODS_3_823_WI_3_validation     1432        2   \n",
       "17562236  2016-03-27       0  FOODS_3_824_WI_3_validation     1433        2   \n",
       "17562237  2016-03-27       1  FOODS_3_825_WI_3_validation     1434        2   \n",
       "17562238  2016-03-27       4  FOODS_3_826_WI_3_validation     1435        2   \n",
       "17562239  2016-03-27       5  FOODS_3_827_WI_3_validation     1436        2   \n",
       "\n",
       "          cat_id  store_id  state_id  event_name_1  event_type_1  ...  \\\n",
       "17562235       0         9         2             4             0  ...   \n",
       "17562236       0         9         2             4             0  ...   \n",
       "17562237       0         9         2             4             0  ...   \n",
       "17562238       0         9         2             4             0  ...   \n",
       "17562239       0         9         2             4             0  ...   \n",
       "\n",
       "          demand_rolling_std_t7  sales_lag_t7  season  gaps  gap_days  \\\n",
       "17562235           4.880371e-01           0.0       0     1      32.0   \n",
       "17562236           0.000000e+00           0.0       0     1     352.0   \n",
       "17562237           7.866211e-01           0.0       0     0       0.0   \n",
       "17562238           5.960464e-08           0.0       0     0       0.0   \n",
       "17562239           1.603516e+00           2.0       0     0       0.0   \n",
       "\n",
       "          gap_confirm  out_of_stock  imputed_demand  \\\n",
       "17562235         32.0           NaN               0   \n",
       "17562236        352.0           NaN               0   \n",
       "17562237          0.0           0.0               1   \n",
       "17562238          0.0           0.0               4   \n",
       "17562239          0.0           0.0               5   \n",
       "\n",
       "                             combined  scaled_weight  \n",
       "17562235  FOODS_3_823_WI_3_validation       0.000004  \n",
       "17562236  FOODS_3_824_WI_3_validation       0.000006  \n",
       "17562237  FOODS_3_825_WI_3_validation       0.000018  \n",
       "17562238  FOODS_3_826_WI_3_validation       0.000006  \n",
       "17562239  FOODS_3_827_WI_3_validation       0.000003  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function runs the 28 day at once model. The arguments are simply the data, and lists of the features and categorical features. Just uncomment the code if you want to add the weights in or use the holdout validation set instead of the time series split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "def run_lgb(data, features, cat_indices):\n",
    "    \n",
    "    # reset_index\n",
    "    #data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # going to evaluate with the last 28 days, try Kfold TSS at some point \n",
    "    \n",
    "    x_train = data[data['date'] <= '2016-04-24']\n",
    "    #y_train = x_train['demand']\n",
    "    #x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "    #y_val = x_val['demand']\n",
    "    #test = data[data['date'] >= '2016-04-25']\n",
    "\n",
    "    #train_weights = x_train['scaled_weight']\n",
    "    #val_weights = x_val['scaled_weight']\n",
    "    \n",
    "    lgb_params = {'boosting_type': 'gbdt',\n",
    "            'objective': 'tweedie',\n",
    "            'tweedie_variance_power': 1.1,\n",
    "            'seed': 42,\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.5,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.065,\n",
    "            'num_leaves': 2047,\n",
    "            'max_depth': 22,\n",
    "            'min_data_in_leaf': 2**12-1,\n",
    "            'feature_fraction': 0.7,\n",
    "            'max_bin': 3050,\n",
    "            'n_estimators': 2000,\n",
    "            'verbose': 20,\n",
    "            'bagging_fraction': 0.85,\n",
    "            'bagging_freq': 1, \n",
    "            'colsample_bytree': 0.85,\n",
    "            'colsample_bynode': 0.85,\n",
    "            'lambda_l1': 0.2,\n",
    "            'lambda_l2': 0.2}\n",
    "    \n",
    "    new_params = {'boosting_type': 'gbdt',\n",
    "            'objective': 'tweedie',\n",
    "            'tweedie_variance_power': 1.1,\n",
    "            'seed': 42,\n",
    "            'metric': 'rmse',\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': .6, \n",
    "            'num_leaves': 127,\n",
    "            'min_data_in_leaf': 255,\n",
    "            'max_bin': 3050,\n",
    "            'n_estimators': 2500,\n",
    "            'verbose': 20,\n",
    "            'bagging_fraction': 0.85,\n",
    "            'bagging_freq': 1, \n",
    "            'colsample_bytree': 0.85,\n",
    "            'colsample_bynode': 0.85,\n",
    "            'lambda_l1': 0.2,\n",
    "            'lambda_l2': 0.2}\n",
    "    \n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.05,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 500,\n",
    "        'lambda_l1': 0.2,\n",
    "        'lambda_l2': 0.2,\n",
    "        'max_bin': 100,\n",
    "        'n_estimators': 1400,\n",
    "        'objective': 'tweedie',\n",
    "        'metric': 'rmse',\n",
    "        \"tweedie_variance_power\":1.1}\n",
    "    \n",
    "    \n",
    "    \n",
    "    TS = 30490\n",
    "    #val_num = x_train['date'].nunique()\n",
    "    for i in range(1, 4):\n",
    "        print(f'Training fold {i}') \n",
    "        \n",
    "        test = data[data['date'] >= '2016-04-25']\n",
    "        preds = np.zeros(len(test))\n",
    "        \n",
    "        if(i != 5):\n",
    "            val_filter = (-49 + 7 * i) * TS\n",
    "            val_stopper = (-21 + 7 * i) * TS\n",
    "\n",
    "            #train_fold_df = training_df.iloc[:, :(-77 + 7 * i)]\n",
    "            #valid_fold_df = training_df.iloc[:, (-77 + 7 * i):(-49 + 7 * i)].copy()\n",
    "            #w = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "            print(\"Yes maam\")\n",
    "        else:\n",
    "            val_filter = (-309) * TS\n",
    "            val_stopper = (-281) * TS\n",
    "\n",
    "            #train_fold_df = training_df.iloc[:, :(-337)]\n",
    "            #valid_fold_df = training_df.iloc[:, (-337):(-309)].copy()\n",
    "            #w = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "            print(\"Yes maam\")\n",
    "        \n",
    "        #del train_fold_df, valid_fold_df\n",
    "        gc.collect()\n",
    "        \n",
    "        if(i == 3):\n",
    "            \n",
    "            temp_train = x_train[features].iloc[:val_filter]\n",
    "            X_train =  temp_train.values\n",
    "            \n",
    "            train_set = lgb.Dataset(X_train, label = x_train['imputed_demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices,\n",
    "                                    weight = x_train[\"scaled_weight\"].iloc[:val_filter], feature_name = features)\n",
    "\n",
    "            gc.collect()\n",
    "            \n",
    "            temp_val = x_train[features].iloc[val_filter:]\n",
    "            X_val =  temp_val.values\n",
    "            \n",
    "            val_set = lgb.Dataset(X_val, label = x_train['imputed_demand'].iloc[val_filter:], \n",
    "                                  categorical_feature = cat_indices,\n",
    "                                  weight = x_train[\"scaled_weight\"].iloc[val_filter:], feature_name = features)\n",
    "            gc.collect()\n",
    "            \n",
    "            del temp_train, temp_val\n",
    "            gc.collect()\n",
    "           \n",
    "        else:\n",
    "\n",
    "            temp_train = x_train[features].iloc[:val_filter]\n",
    "            X_train =  temp_train.values\n",
    "            train_set = lgb.Dataset(X_train, label = x_train['imputed_demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices,\n",
    "                                    weight = x_train[\"scaled_weight\"].iloc[:val_filter], feature_name = features)\n",
    "            gc.collect()\n",
    "            logging.debug(\"Debugging training dataset construction\")\n",
    "            temp_val = x_train[features].iloc[val_filter:val_stopper]\n",
    "            X_val =  temp_val.values\n",
    "            val_set = lgb.Dataset(X_val, label = x_train['imputed_demand'].iloc[val_filter:val_stopper], \n",
    "                                  categorical_feature = cat_indices,\n",
    "                   weight = x_train[\"scaled_weight\"].iloc[val_filter:val_stopper], feature_name = features)\n",
    "            gc.collect()\n",
    "            logging.debug(\"Debugging validation dataset construction\")\n",
    "            \n",
    "            \n",
    "            del temp_train, temp_val\n",
    "            gc.collect()\n",
    "            print(\"Yes maam\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        model = lgb.train(new_params, train_set, num_boost_round = 2500, \n",
    "                              valid_sets = [train_set, val_set], verbose_eval = 20, \n",
    "                          early_stopping_rounds = 75)\n",
    "        logging.debug(\"Debugging model training process\")\n",
    "        \n",
    "        preds += model.predict(test[features])\n",
    "        #model.save_model(\"model_17.lgb\")\n",
    "        print('-'*50)\n",
    "        print('\\n')\n",
    "        test = test[['id', 'date', 'imputed_demand']]\n",
    "        test['imputed_demand'] = preds\n",
    "        test.to_csv(f'test_{i}(9).csv')\n",
    "\n",
    "    test1 = pd.read_csv('test_1(9).csv')\n",
    "    test2 = pd.read_csv('test_2(9).csv')\n",
    "    test3 = pd.read_csv('test_3(9).csv')\n",
    "    \n",
    "    return test1, test2, test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "def run_lgb_holdout(data, features, cat_indices):\n",
    "    \n",
    "    # reset_index\n",
    "    #data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # going to evaluate with the last 28 days, try Kfold TSS at some point \n",
    "    \n",
    "    x_train = data[data['date'] <= '2016-04-24']\n",
    "    #y_train = x_train['demand']\n",
    "    #x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "    #y_val = x_val['demand']\n",
    "    #test = data[data['date'] >= '2016-04-25']\n",
    "\n",
    "    #train_weights = x_train['scaled_weight']\n",
    "    #val_weights = x_val['scaled_weight']\n",
    "    \n",
    "    lgb_params = {'boosting_type': 'gbdt',\n",
    "            'objective': 'tweedie',\n",
    "            'tweedie_variance_power': 1.1,\n",
    "            'seed': 42,\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.5,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.065,\n",
    "            'num_leaves': 2047,\n",
    "            'max_depth': 22,\n",
    "            'min_data_in_leaf': 2**12-1,\n",
    "            'feature_fraction': 0.7,\n",
    "            'max_bin': 3050,\n",
    "            'n_estimators': 2000,\n",
    "            'verbose': 20,\n",
    "            'bagging_fraction': 0.85,\n",
    "            'bagging_freq': 1, \n",
    "            'colsample_bytree': 0.85,\n",
    "            'colsample_bynode': 0.85,\n",
    "            'lambda_l1': 0.2,\n",
    "            'lambda_l2': 0.2}\n",
    "    \n",
    "    new_params = {'boosting_type': 'gbdt',\n",
    "            'objective': 'tweedie',\n",
    "            'tweedie_variance_power': 1.1,\n",
    "            'seed': 42,\n",
    "            'metric': 'rmse',\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': .6, \n",
    "            'num_leaves': 127,\n",
    "            'min_data_in_leaf': 255,\n",
    "            'max_bin': 3050,\n",
    "            'n_estimators': 2500,\n",
    "            'verbose': 20,\n",
    "            'bagging_fraction': 0.85,\n",
    "            'bagging_freq': 1, \n",
    "            'colsample_bytree': 0.85,\n",
    "            'colsample_bynode': 0.85,\n",
    "            'lambda_l1': 0.2,\n",
    "            'lambda_l2': 0.2}\n",
    "    \n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.05,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 500,\n",
    "        'lambda_l1': 0.2,\n",
    "        'lambda_l2': 0.2,\n",
    "        'max_bin': 100,\n",
    "        'n_estimators': 1400,\n",
    "        'objective': 'tweedie',\n",
    "        'metric': 'rmse',\n",
    "        \"tweedie_variance_power\":1.1}\n",
    "    \n",
    "    \n",
    "    \n",
    "    TS = 30490\n",
    "    #val_num = x_train['date'].nunique()\n",
    "    for i in range(3, 4):\n",
    "        print(f'Training fold {i}') \n",
    "        \n",
    "        test = data[data['date'] >= '2016-04-25']\n",
    "        preds = np.zeros(len(test))\n",
    "        \n",
    "        if(i != 5):\n",
    "            val_filter = (-49 + 7 * i) * TS\n",
    "            val_stopper = (-21 + 7 * i) * TS\n",
    "\n",
    "            #train_fold_df = training_df.iloc[:, :(-77 + 7 * i)]\n",
    "            #valid_fold_df = training_df.iloc[:, (-77 + 7 * i):(-49 + 7 * i)].copy()\n",
    "            #w = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "            print(\"Yes maam\")\n",
    "        else:\n",
    "            val_filter = (-309) * TS\n",
    "            val_stopper = (-281) * TS\n",
    "\n",
    "            #train_fold_df = training_df.iloc[:, :(-337)]\n",
    "            #valid_fold_df = training_df.iloc[:, (-337):(-309)].copy()\n",
    "            #w = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "            print(\"Yes maam\")\n",
    "        \n",
    "        #del train_fold_df, valid_fold_df\n",
    "        gc.collect()\n",
    "        \n",
    "        if(i == 3):\n",
    "            \n",
    "            temp_train = x_train[features].iloc[:val_filter]\n",
    "            X_train =  temp_train.values\n",
    "            \n",
    "            train_set = lgb.Dataset(X_train, label = x_train['demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices,\n",
    "                                    weight = x_train[\"scaled_weight\"].iloc[:val_filter], feature_name = features)\n",
    "\n",
    "            gc.collect()\n",
    "            \n",
    "            temp_val = x_train[features].iloc[val_filter:]\n",
    "            X_val =  temp_val.values\n",
    "            \n",
    "            val_set = lgb.Dataset(X_val, label = x_train['demand'].iloc[val_filter:], \n",
    "                                  categorical_feature = cat_indices,\n",
    "                                  weight = x_train[\"scaled_weight\"].iloc[val_filter:], feature_name = features)\n",
    "            gc.collect()\n",
    "            \n",
    "            del temp_train, temp_val\n",
    "            gc.collect()\n",
    "           \n",
    "        else:\n",
    "\n",
    "            temp_train = x_train[features].iloc[:val_filter]\n",
    "            X_train =  temp_train.values\n",
    "            train_set = lgb.Dataset(X_train, label = x_train['demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices,\n",
    "                                    weight = x_train[\"scaled_weight\"].iloc[:val_filter], feature_name = features)\n",
    "            gc.collect()\n",
    "            logging.debug(\"Debugging training dataset construction\")\n",
    "            temp_val = x_train[features].iloc[val_filter:val_stopper]\n",
    "            X_val =  temp_val.values\n",
    "            val_set = lgb.Dataset(X_val, label = x_train['imputed_demand'].iloc[val_filter:val_stopper], \n",
    "                                  categorical_feature = cat_indices,\n",
    "                   weight = x_train[\"scaled_weight\"].iloc[val_filter:val_stopper], feature_name = features)\n",
    "            gc.collect()\n",
    "            logging.debug(\"Debugging validation dataset construction\")\n",
    "            \n",
    "            \n",
    "            del temp_train, temp_val\n",
    "            gc.collect()\n",
    "            print(\"Yes maam\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        model = lgb.train(new_params, train_set, num_boost_round = 2500, \n",
    "                              valid_sets = [train_set, val_set], verbose_eval = 20, \n",
    "                          early_stopping_rounds = 75)\n",
    "        logging.debug(\"Debugging model training process\")\n",
    "        \n",
    "        preds += model.predict(test[features])\n",
    "        #model.save_model(\"model_17.lgb\")\n",
    "        print('-'*50)\n",
    "        print('\\n')\n",
    "        test = test[['id', 'date', 'demand']]\n",
    "        test['demand'] = preds\n",
    "        test.to_csv(f'test_{i}(9).csv')\n",
    "\n",
    "    test1 = pd.read_csv('test_1(9).csv')\n",
    "    test2 = pd.read_csv('test_2(9).csv')\n",
    "    test3 = pd.read_csv('test_3(9).csv')\n",
    "    \n",
    "    return test1, test2, test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The make_lag function is for making lag features for the day to day model. I have those so we can generate features on the fly as opposed to generating them all at once because the notebook will probably crash. Then, the function below that simply runs the day to day model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_lags(data, day):\n",
    "    data_fe = data[['id', 'demand']]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    periods = [7, 28]\n",
    "    for period in periods:\n",
    "        data_fe['demand_rolling_mean_t' + str(day + 7) + '_' + str(period)] = group.transform(lambda x: x.shift(day + 7).rolling(period).mean())\n",
    "        data_fe['demand_rolling_std_t' + str(day + 7) + '_' + str(period)] = group.transform(lambda x: x.shift(day + 7).rolling(period).std())\n",
    "        data_fe['sales_lag_t' + str(day + 7)] = group.transform(lambda x: x.shift(day + 7))\n",
    "\n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe, data['sales_lag_t' + str(day)], data['demand_rolling_std_t' + str(day) + '_' + str(7)],\n",
    "    data['demand_rolling_mean_t' + str(day) + '_' + str(7)], data['demand_rolling_std_t' + str(day) + '_' + str(28)],\n",
    "    data['demand_rolling_mean_t' + str(day) + '_' + str(28)]\n",
    "                                                                \n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_lags(data, day_num):\n",
    "    data_fe = data[['id', 'demand']]\n",
    "    group = data_fe.groupby('id')['demand']\n",
    "    \n",
    "    week = []\n",
    "    if(day_num == 1):\n",
    "        week = [8, 9, 10, 11, 12, 13, 14]\n",
    "    elif(day_num == 2):\n",
    "        week = [15, 16, 17, 18, 19, 20, 21]\n",
    "    elif(day_num == 3):\n",
    "        week = [22, 23, 24, 25, 26, 27, 28]\n",
    "    else:\n",
    "        week = [29, 30, 31, 32, 33, 34, 35]\n",
    "    \n",
    "    \n",
    "    periods = [28]\n",
    "    for day in week:\n",
    "        for period in periods:\n",
    "            data_fe['demand_rolling_mean_t' + str(day) + '_' + str(period)] = group.transform(lambda x: x.shift(day).rolling(period).mean())\n",
    "            data_fe['demand_rolling_std_t' + str(day) + '_' + str(period)] = group.transform(lambda x: x.shift(day).rolling(period).std())\n",
    "            data_fe['sales_lag_t' + str(day)] = group.transform(lambda x: x.shift(day))\n",
    "\n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "        \n",
    "    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n",
    "    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n",
    "    \n",
    "    del data_fe\n",
    "    if(i != 1):\n",
    "        for day in week:\n",
    "            del data['sales_lag_t' + str((day - 14))], data['demand_rolling_std_t' + str((day - 14)) + '_' + str(28)],\n",
    "            data['demand_rolling_mean_t' + str((day - 14)) + '_' + str(28)]\n",
    "                                                                \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT SURE IF THIS WORKS YET HAVENT TESTED IT\n",
    "\n",
    "import sklearn.metrics as metrics \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "def run_daily(data, features, cat_features):\n",
    "    \n",
    "    # reset_index\n",
    "    #data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # going to evaluate with the last 28 days, try Kfold TSS at some point \n",
    "    \n",
    "    #x_train = data[data['date'] <= '2016-04-24']\n",
    "    #y_train = x_train['demand']\n",
    "    #x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "    #y_val = x_val['demand']\n",
    "    #test = data[data['date'] >= '2016-04-25']\n",
    "\n",
    "    #train_weights = x_train['scaled_weight']\n",
    "    #val_weights = x_val['scaled_weight']\n",
    "    \n",
    "\n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.08,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 200,\n",
    "        'lambda_l1': 0.2,\n",
    "        'lambda_l2': 0.2,\n",
    "        'objective': 'tweedie',\n",
    "        'metric': 'rmse',\n",
    "        \"tweedie_variance_power\":1.1}\n",
    "    \n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    TS = 30490\n",
    "    #date_list = x_train['date'].unique()\n",
    "    \n",
    "    test = data[data['date'] >= '2016-04-25']\n",
    "    \n",
    "    \n",
    "    for j in range(1, 29):\n",
    "        data = daily_lags(data, j)\n",
    "        del data.iloc[30490:]\n",
    "        gc.collect()\n",
    "        \n",
    "        x_train = data[data['date'] <= '2016-04-24']\n",
    "                          \n",
    "        marker = datetime.date(2016, 4, 24) + timedelta(days=(j))\n",
    "        temp_test = data[data['date'] == marker]\n",
    "        \n",
    "        for i in range(1, 4):\n",
    "            print(f'Training fold {i} for day {j}')\n",
    "\n",
    "            val_filter = (-70 + 14 * i) * TS\n",
    "            val_stopper = (-42 + 14 * i) * TS\n",
    "\n",
    "            train_fold_df = training_df.iloc[:, :(-98 + 14 * i)]\n",
    "            valid_fold_df = training_df.iloc[:, (-98 + 14 * i):(-70 + 14 * i)].copy()\n",
    "            w = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "\n",
    "            if(i == 3):\n",
    "                train_set = lgb.Dataset(x_train[features].iloc[:val_filter], label = x_train['demand'].iloc[:val_filter], \n",
    "                                        categorical_feature = cat_features, \n",
    "                                        weight = x_train[\"scaled_weight\"].iloc[:val_filter])\n",
    "\n",
    "                val_set = lgb.Dataset(x_train[features].iloc[val_filter:], \n",
    "                                      label = x_train['demand'].iloc[val_filter:], \n",
    "                                      categorical_feature = cat_features,\n",
    "                                      weight = x_train[\"scaled_weight\"].iloc[val_filter:])\n",
    "            else:\n",
    "                train_set = lgb.Dataset(x_train[features].iloc[:val_filter], label = x_train['demand'].iloc[:val_filter], \n",
    "                                        categorical_feature = cat_features,\n",
    "                                        weight = x_train[\"scaled_weight\"].iloc[:val_filter])\n",
    "\n",
    "                val_set = lgb.Dataset(x_train[features].iloc[val_filter:val_stopper], \n",
    "                                  label = x_train['demand'].iloc[val_filter:val_stopper], \n",
    "                                  categorical_feature = cat_features,\n",
    "                weight = x_train[\"scaled_weight\"].iloc[val_filter:val_stopper])\n",
    "\n",
    "            model = lgb.train(params, train_set, num_boost_round = 2500, \n",
    "                                  valid_sets = [val_set], verbose_eval = 20, \n",
    "                              early_stopping_rounds = 75, feval = w.feval)\n",
    "\n",
    "            preds += model.predict(temp_test[features]) / 3\n",
    "            print('-'*50)\n",
    "            print('\\n')\n",
    "        \n",
    "        \n",
    "        test['demand'] = temp_test.append(preds)\n",
    "        del x_train, temp_test\n",
    "        gc.collect()\n",
    "        model.save_model(f\"model_1_day{j}.lgb\")\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "def run_lgb_weekly(data, features1, features2, features3, features4, cat_indices):\n",
    "    \n",
    "    # reset_index\n",
    "    #data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # going to evaluate with the last 28 days, try Kfold TSS at some point \n",
    "    \n",
    "    #x_train = data[data['date'] <= '2016-04-24']\n",
    "    #y_train = x_train['demand']\n",
    "    #x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "    #y_val = x_val['demand']\n",
    "    test = data[data['date'] >= '2016-04-25']\n",
    "\n",
    "    #train_weights = x_train['scaled_weight']\n",
    "    #val_weights = x_val['scaled_weight']\n",
    "\n",
    "\n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,   \n",
    "        'learning_rate': 0.07,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 200,\n",
    "        'lambda_l1': 0.2,\n",
    "        'lambda_l2': 0.2,\n",
    "        'objective': 'tweedie',\n",
    "        'metric': 'rmse',\n",
    "        \"tweedie_variance_power\":1.1}\n",
    "    \n",
    "    new_params = {'boosting_type': 'gbdt',\n",
    "            'seed': 42,\n",
    "            'metric': 'rmse',\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.075,\n",
    "            'feature_fraction': .6, \n",
    "            'num_leaves': 127,\n",
    "            'min_data_in_leaf': 255,\n",
    "            'max_bin': 3050,\n",
    "            'n_estimators': 2500,\n",
    "            'verbose': 20,\n",
    "            'bagging_fraction': 0.85,\n",
    "            'bagging_freq': 1, \n",
    "            'colsample_bytree': 0.85,\n",
    "            'colsample_bynode': 0.85,\n",
    "            'lambda_l1': 0.2,\n",
    "            'lambda_l2': 0.2, \n",
    "            'objective': 'tweedie',\n",
    "            \"tweedie_variance_power\":1.1}\n",
    "    \n",
    "    \n",
    "    \n",
    "    TS = 30490\n",
    "    #date_list = x_train['date'].unique()\n",
    "    \n",
    "    #test = data[data['date'] >= '2016-04-25']\n",
    "    \n",
    "    \n",
    "    for j in range(1, 5):\n",
    "        rect = unmelt(data)\n",
    "        rect = rect.values\n",
    "        \n",
    "        print(j)\n",
    "        if (j == 1):\n",
    "            data = make_lags_df_1(data, rect)\n",
    "            gc.collect()\n",
    "        elif (j == 2):\n",
    "            data = make_lags_df_2(data, rect)\n",
    "            gc.collect()\n",
    "        elif (j == 3):\n",
    "            data = make_lags_df_3(data, rect)\n",
    "            gc.collect()\n",
    "        else:\n",
    "            data = make_lags_df_4(data, rect)\n",
    "            gc.collect()\n",
    "        \n",
    "        del rect\n",
    "        \n",
    "        preds = []\n",
    "        dates = data['date'].unique()\n",
    "        starting_date = dates[0]\n",
    "        del dates\n",
    "        \n",
    "        print(j)\n",
    "        if(j == 1):\n",
    "            start_date = starting_date + pd.to_timedelta(35, unit=\"D\")\n",
    "            temp_test = data[(data['date'] >= '2016-04-25') & (data['date'] <= '2016-05-01')]\n",
    "            x_train = data[(data['date'] >= start_date) & (data['date'] <= '2016-04-24')] \n",
    "        elif(j == 2):\n",
    "            start_date = starting_date + pd.to_timedelta(42, unit=\"D\")\n",
    "            temp_test = data[(data['date'] >= '2016-05-02') & (data['date'] <= '2016-05-08')]\n",
    "            x_train = data[(data['date'] >= start_date) & (data['date'] <= '2016-04-24')]\n",
    "        elif(j == 3):\n",
    "            start_date = starting_date + pd.to_timedelta(49, unit=\"D\")\n",
    "            temp_test = data[(data['date'] >= '2016-05-09') & (data['date'] <= '2016-05-15')]\n",
    "            x_train = data[(data['date'] >= start_date) & (data['date'] <= '2016-04-24')]\n",
    "        else:\n",
    "            start_date = starting_date + pd.to_timedelta(56, unit=\"D\")\n",
    "            temp_test = data[(data['date'] >= '2016-05-16') & (data['date'] <= '2016-05-22')]\n",
    "            x_train = data[(data['date'] >= start_date) & (data['date'] <= '2016-04-24')]\n",
    "        print(j)\n",
    "        \n",
    "        num_days = x_train['date'].nunique()\n",
    "\n",
    "        index_list = []\n",
    "        for a in range(30490):\n",
    "                index = a\n",
    "                index_list.append(a)\n",
    "                for b in range(num_days - 1):\n",
    "                    index += (30490)\n",
    "                    index_list.append(index)\n",
    "                    \n",
    "        x_train = x_train.reindex(index_list)\n",
    "        x_train = x_train.reset_index()\n",
    "        del index_list\n",
    "        \n",
    "        \n",
    "        scaled_weight = x_train['scaled_weight'].to_numpy()\n",
    "        def level12Weighted(y_pred, y_true, scaled_weight = scaled_weight):\n",
    "            y_true = y_true.get_label()\n",
    "            num_days = int(len(y_pred) / 30490)\n",
    "            residual = (y_true - y_pred).astype(\"float\")\n",
    "            for i in range(30490): \n",
    "                residual[i * num_days:(i+1) * num_days] = scaled_weight[i * num_days:(i+1) * num_days] * residual[i * num_days:(i+1) * num_days]\n",
    "\n",
    "            grad = -2 * residual\n",
    "            hess = 2 * np.ones(residual.shape)\n",
    "            return grad, hess\n",
    "        \n",
    "        print(j)\n",
    "\n",
    "        print(f'Training fold for week {j}')\n",
    "        \n",
    "        print(j)\n",
    "        \n",
    "        i = 3\n",
    "        val_filter = (-70 + 14 * i) * TS\n",
    "        val_stopper = (-42 + 14 * i) * TS\n",
    "\n",
    "        train_fold_df = training_df.iloc[:, :(-98 + 14 * i)]\n",
    "        valid_fold_df = training_df.iloc[:, (-98 + 14 * i):(-70 + 14 * i)].copy()\n",
    "        w = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "\n",
    "        print(j)\n",
    "        if (j == 1):\n",
    "            train_set = lgb.Dataset(x_train[features1].iloc[:val_filter], label = x_train['demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices, feature_name = features1 \n",
    "                                   )\n",
    "\n",
    "            val_set = lgb.Dataset(x_train[features1].iloc[val_filter:], \n",
    "                                  label = x_train['demand'].iloc[val_filter:], \n",
    "                                  categorical_feature = cat_indices, feature_name = features1)\n",
    "        elif (j == 2):\n",
    "            train_set = lgb.Dataset(x_train[features2].iloc[:val_filter], label = x_train['demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices, feature_name = features2)\n",
    "\n",
    "            val_set = lgb.Dataset(x_train[features2].iloc[val_filter:], \n",
    "                                  label = x_train['demand'].iloc[val_filter:], \n",
    "                                  categorical_feature = cat_indices, feature_name = features2)\n",
    "        elif (j == 3):\n",
    "            train_set = lgb.Dataset(x_train[features3].iloc[:val_filter], label = x_train['demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices, feature_name = features3)\n",
    "\n",
    "            val_set = lgb.Dataset(x_train[features3].iloc[val_filter:], \n",
    "                                  label = x_train['demand'].iloc[val_filter:], \n",
    "                                  categorical_feature = cat_indices, feature_name = features3)\n",
    "        else:\n",
    "            train_set = lgb.Dataset(x_train[features4].iloc[:val_filter], label = x_train['demand'].iloc[:val_filter], \n",
    "                                    categorical_feature = cat_indices, feature_name = features4)\n",
    "\n",
    "            val_set = lgb.Dataset(x_train[features4].iloc[val_filter:], \n",
    "                                  label = x_train['demand'].iloc[val_filter:], \n",
    "                                  categorical_feature = cat_indices, feature_name = features4)\n",
    "        \n",
    "\n",
    "        model = lgb.train(new_params, train_set, num_boost_round = 2500, \n",
    "                              valid_sets = [val_set], verbose_eval = 20, \n",
    "                          early_stopping_rounds = 150, feval = w.L1_feval)\n",
    "\n",
    "        \n",
    "        if (j == 1):\n",
    "            preds.append(model.predict(temp_test[features1]))\n",
    "        elif (j == 2):\n",
    "            preds.append(model.predict(temp_test[features2]))\n",
    "        elif (j == 3):\n",
    "            preds.append(model.predict(temp_test[features3]))\n",
    "        else: \n",
    "            preds.append(model.predict(temp_test[features4]))\n",
    "            \n",
    "        print('-'*50)\n",
    "        print('\\n')\n",
    "        \n",
    "        test = temp_test[['id', 'date', 'demand']]\n",
    "        test['demand'] = preds\n",
    "        test.to_csv(f'test_{j}(10).csv')\n",
    "        del x_train, temp_test, test \n",
    "        if (j == 1):\n",
    "            del data['shift_7_rolling_mean_7'], data['shift_7_rolling_mean_14'], data['shift_7_rolling_mean_28'], data['shift_7_rolling_std_7'], data['shift_7_rolling_std_14'], data['shift_7_rolling_std_28'], data['shift_1_rolling_mean_7'], data['shift_1_rolling_mean_14'], data['shift_1_rolling_mean_28'], data['shift_1_rolling_std_7'], data['shift_1_rolling_std_14'], data['shift_1_rolling_std_28']\n",
    "        elif (j == 2): \n",
    "            del data['shift_14_rolling_mean_7'], data['shift_14_rolling_mean_14'], data['shift_14_rolling_mean_28'], data['shift_14_rolling_std_7'], data['shift_14_rolling_std_14'], data['shift_14_rolling_std_28'], data['shift_1_rolling_mean_7'], data['shift_1_rolling_mean_14'], data['shift_1_rolling_mean_28'], data['shift_1_rolling_std_7'], data['shift_1_rolling_std_14'], data['shift_1_rolling_std_28']\n",
    "        elif (j == 3):\n",
    "            del data['shift_21_rolling_mean_7'], data['shift_21_rolling_mean_14'], data['shift_21_rolling_mean_28'], data['shift_21_rolling_std_7'], data['shift_21_rolling_std_14'], data['shift_21_rolling_std_28'], data['shift_1_rolling_mean_7'], data['shift_1_rolling_mean_14'], data['shift_1_rolling_mean_28'], data['shift_1_rolling_std_7'], data['shift_1_rolling_std_14'], data['shift_1_rolling_std_28']\n",
    "        else:\n",
    "            del data['shift_28_rolling_mean_7'], data['shift_28_rolling_mean_14'], data['shift_28_rolling_mean_28'], data['shift_28_rolling_std_7'], data['shift_28_rolling_std_14'], data['shift_28_rolling_std_28'], data['shift_1_rolling_mean_7'], data['shift_1_rolling_mean_14'], data['shift_1_rolling_mean_28'], data['shift_1_rolling_std_7'], data['shift_1_rolling_std_14'], data['shift_1_rolling_std_28']\n",
    "            \n",
    "        gc.collect()\n",
    "        #model.save_model(f\"model_1_week{j}.lgb\")\n",
    "    \n",
    "    test1 = pd.read_csv('test_1(10).csv')\n",
    "    test2 = pd.read_csv('test_2(10).csv')\n",
    "    test3 = pd.read_csv('test_3(10).csv')\n",
    "    test4 = pd.read_csv('test_4(10).csv')\n",
    "\n",
    "    return test1, test2, test3, test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(test, submission):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.to_csv(f'model_35.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del data['shift_7_rolling_mean_7'], data['shift_7_rolling_mean_14'], data['shift_7_rolling_mean_28'], data['shift_7_rolling_std_7'], data['shift_7_rolling_std_14'], data['shift_7_rolling_std_28'], data['shift_1_rolling_mean_7'], data['shift_1_rolling_mean_14'], data['shift_1_rolling_mean_28'], data['shift_1_rolling_std_7'], data['shift_1_rolling_std_14'], data['shift_1_rolling_std_28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['lag_0'], data['lag_1'], data['lag_3'], data['lag_7'], data['lag_28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1335"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-3c4ecc6cd86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def get_scale(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        return getattr(self, f'lv{lv}_scale')\n",
    "        \n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')       \n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "        if VERBOSE:\n",
    "            print(np.round(all_scores,3))\n",
    "        return np.mean(all_scores)\n",
    "\n",
    "    def L1_score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "        #print(np.round(all_scores,3))\n",
    "        return all_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRMSSEForLightGBM(WRMSSEEvaluator):\n",
    "    def feval(self, preds, dtrain):\n",
    "        preds = preds.reshape(self.valid_df[self.valid_target_columns].shape, order='F') #.transpose()\n",
    "        score = self.score(preds)\n",
    "        return 'WRMSSE', score, False\n",
    "    def L1_feval(self, preds, dtrain):\n",
    "        preds = preds.reshape(self.valid_df[self.valid_target_columns].shape, order='F') #.transpose()\n",
    "        score = self.L1_score(preds)\n",
    "        return 'L1_WRMSSE', score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "training_df = pd.read_csv('sales_train_validation.csv')\n",
    "training_df = reduce_mem_usage(training_df)\n",
    "temp_calendar = pd.read_csv('calendar.csv')\n",
    "temp_calendar = reduce_mem_usage(temp_calendar)\n",
    "temp_prices = pd.read_csv('sell_prices.csv')\n",
    "temp_prices = reduce_mem_usage(temp_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df = training_df.iloc[:, :-28]\n",
    "valid_fold_df = training_df.iloc[:, -28:].copy()\n",
    "\n",
    "#wrmsse = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)\n",
    "e = WRMSSEEvaluator(train_fold_df, valid_fold_df, temp_calendar, temp_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(filename, e): \n",
    "    testing_df = pd.read_csv(filename)\n",
    "    testing_df = testing_df.iloc[0:30490, 1:]\n",
    "    array = testing_df.values\n",
    "    e.score(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluding the read_data function which i still have at the top of the notebook \n",
    "def run_everything(data):\n",
    "    data = transform(data)\n",
    "    data = new_features(data) #change function for day to day model \n",
    "    data = get_weights(data)\n",
    "    data = reduce_mem_usage(data)\n",
    "    \n",
    "    features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t1', \n",
    "            'demand_rolling_std_t1', 'sales_lag_t1', 'demand_rolling_mean_t2', 'demand_rolling_std_t2', 'sales_lag_t2'\n",
    "            , 'demand_rolling_mean_t3', 'demand_rolling_std_t3', 'sales_lag_t3', 'demand_rolling_mean_t4'\n",
    "            ,'demand_rolling_std_t4', 'sales_lag_t4', 'demand_rolling_mean_t5', 'demand_rolling_std_t5', \n",
    "            'sales_lag_t5', 'demand_rolling_mean_t6', 'demand_rolling_std_t6', 'sales_lag_t6', 'demand_rolling_mean_t7',\n",
    "            'demand_rolling_std_t7', 'sales_lag_t7', 'season'] \n",
    "\n",
    "#'price_max', 'price_min', 'price_std', 'price_mean','price_norm', 'price_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y'\n",
    "#'weighted_sales_t1', 'weighted_sales_t2', 'weighted_sales_t3', 'weighted_sales_t4', 'weighted_sales_t5', 'weighted_sales_t6', 'weighted_sales_t7', \"sale_momentum_y\", \"sale_momentum_m\"\n",
    "\n",
    "    #use this in case you want to filter your data if you saved it to csv \n",
    "    keep_columns = ['date', 'revenue', 'demand', 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t1', \n",
    "            'demand_rolling_std_t1', 'sales_lag_t1', 'demand_rolling_mean_t2', 'demand_rolling_std_t2', 'sales_lag_t2'\n",
    "            , 'demand_rolling_mean_t3', 'demand_rolling_std_t3', 'sales_lag_t3', 'demand_rolling_mean_t4'\n",
    "            ,'demand_rolling_std_t4', 'sales_lag_t4', 'demand_rolling_mean_t5', 'demand_rolling_std_t5', \n",
    "            'sales_lag_t5', 'demand_rolling_mean_t6', 'demand_rolling_std_t6', 'sales_lag_t6', 'demand_rolling_mean_t7',\n",
    "            'demand_rolling_std_t7', 'sales_lag_t7', 'season']\n",
    "\n",
    "    cat_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', \n",
    "                    'event_name_2', 'event_type_2']\n",
    "    \n",
    "    #submission = pd.read_csv('sample_submission.csv'), use this if you load in data from csv and dont call read_data\n",
    "    next_test = run_lgb(data, features, cat_features)\n",
    "    submit(next_test, submission)\n",
    "    \n",
    "    #declare an evaluator and run get_score function on the csv file you save the submission to or just use the class you wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from imp import reload\n",
    "\n",
    "# jupyter notebook already uses logging, thus we reload the module to make it work in notebooks\n",
    "# http://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook\n",
    "reload(logging)\n",
    "\n",
    "# In the following not only did we change the logging level, but\n",
    "# also specify a logging file to write the log to, and the format.\n",
    "# the format we specified here is simply the time, the level name\n",
    "# and the message that we'll later specify, for more information\n",
    "# about what format we can specify, refer to the following webpage\n",
    "# https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "logging.basicConfig(filename='test_3.log', level=logging.DEBUG,\n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisconsin = pd.read_csv('wisconsinw.csv')\n",
    "california = pd.read_csv('californiaw.csv')\n",
    "texas = pd.read_csv('texasw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = pd.date_range(start='2011-01-29', end='2016-07-20').tolist()\n",
    "wisconsin['date_time'] = pd.Series(date_list)\n",
    "texas['date_time'] = pd.Series(date_list)\n",
    "california['date_time'] = pd.Series(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisconsin['state_id'] = 2\n",
    "texas['state_id'] = 1\n",
    "california['state_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat([wisconsin, texas, california], ignore_index = True)\n",
    "del wisconsin, texas, california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis_start_pop = 5752000\n",
    "wis_end_pop = 5773000\n",
    "cal_start_pop = 38600000\n",
    "cal_end_pop = 39170000\n",
    "tex_start_pop = 26960000\n",
    "tex_end_pop = 27910000\n",
    "\n",
    "wis_diff = (wis_end_pop - wis_start_pop) / 2000\n",
    "cal_diff = (cal_end_pop - cal_start_pop) / 2000\n",
    "tex_diff = (tex_end_pop - tex_start_pop) / 2000\n",
    "\n",
    "wis_list = []\n",
    "cal_list = []\n",
    "tex_list = []\n",
    "for i in range(1, 2001):\n",
    "    wis_pop = wis_start_pop + i * wis_diff\n",
    "    cal_pop = cal_start_pop + i * cal_diff\n",
    "    tex_pop = tex_start_pop + i * tex_diff\n",
    "\n",
    "    wis_list.append(wis_pop)\n",
    "    cal_list.append(cal_pop)\n",
    "    tex_list.append(tex_pop)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['population'] = pd.Series(wis_list + cal_list + tex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del weather_df['maxtempC'], weather_df['mintempC'], weather_df['sunHour'], weather_df['DewPointC'], \n",
    "weather_df['WindGustKmph'], weather_df['pressure']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.15 Mb (75.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "weather_df = reduce_mem_usage(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data, weather_df, how = 'left', left_on = ['date', 'state_id'], right_on = ['date_time', 'state_id'])\n",
    "del weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>FeelsLikeC</th>\n",
       "      <th>HeatIndexC</th>\n",
       "      <th>WindChillC</th>\n",
       "      <th>WindGustKmph</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id  demand   part       date  wm_yr_wk  ...  uvIndex  FeelsLikeC  \\\n",
       "0         0       0  train 2014-04-02     11409  ...        1           4   \n",
       "1         0       0  train 2014-04-02     11409  ...        1           4   \n",
       "2         0       0  train 2014-04-02     11409  ...        1           4   \n",
       "3         0       0  train 2014-04-02     11409  ...        1           4   \n",
       "4         0       2  train 2014-04-02     11409  ...        1           4   \n",
       "\n",
       "   HeatIndexC  WindChillC  WindGustKmph  cloudcover  humidity  precipMM  \\\n",
       "0           8           4            29          10        49  0.199951   \n",
       "1           8           4            29          10        49  0.199951   \n",
       "2           8           4            29          10        49  0.199951   \n",
       "3           8           4            29          10        49  0.199951   \n",
       "4           8           4            29          10        49  0.199951   \n",
       "\n",
       "   pressure  population  \n",
       "0      1014  27511000.0  \n",
       "1      1014  27511000.0  \n",
       "2      1014  27511000.0  \n",
       "3      1014  27511000.0  \n",
       "4      1014  27511000.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2023.74 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  2.09 Mb (84.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission = reduce_mem_usage(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'imputed_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'totalSnow_cm', 'FeelsLikeC', 'HeatIndexC',\n",
    "           'WindChillC', 'humidity', 'precipMM', 'population', 'lag_0', 'lag_1', 'lag_3', 'lag_7', 'lag_28',\n",
    "'shift_7_rolling_mean_7',\n",
    "'shift_7_rolling_mean_14',\n",
    "'shift_7_rolling_mean_28','shift_7_rolling_std_7',\n",
    "'shift_7_rolling_std_14',\n",
    "'shift_7_rolling_std_28'] \n",
    "\n",
    "features2 = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'imputed_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'totalSnow_cm', 'FeelsLikeC', 'HeatIndexC',\n",
    "           'WindChillC', 'humidity', 'precipMM', 'population', 'lag_0', 'lag_1', 'lag_3', 'lag_7', 'lag_28',\n",
    "'shift_14_rolling_mean_7',\n",
    "'shift_14_rolling_mean_14',\n",
    "'shift_14_rolling_mean_28','shift_14_rolling_std_7',\n",
    "'shift_14_rolling_std_14',\n",
    "'shift_14_rolling_std_28'] \n",
    "\n",
    "features3 = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'imputed_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'totalSnow_cm', 'FeelsLikeC', 'HeatIndexC',\n",
    "           'WindChillC', 'humidity', 'precipMM', 'population', 'lag_0', 'lag_1', 'lag_3', 'lag_7', 'lag_28',\n",
    "'shift_21_rolling_mean_7',\n",
    "'shift_21_rolling_mean_14',\n",
    "'shift_21_rolling_mean_28','shift_14_rolling_std_7',\n",
    "'shift_21_rolling_std_14',\n",
    "'shift_21_rolling_std_28'] \n",
    "\n",
    "features4 = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'imputed_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'totalSnow_cm', 'FeelsLikeC', 'HeatIndexC',\n",
    "           'WindChillC', 'humidity', 'precipMM', 'population', 'lag_0', 'lag_1', 'lag_3', 'lag_7', 'lag_28',\n",
    "'shift_28_rolling_mean_7',\n",
    "'shift_28_rolling_mean_14',\n",
    "'shift_28_rolling_mean_28',\n",
    "'shift_28_rolling_std_7',\n",
    "'shift_28_rolling_std_14',\n",
    "'shift_28_rolling_std_28'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population</th>\n",
       "      <th>lag_0</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HOBBIES_1_006_CA_1_validation</td>\n",
       "      <td>1442</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HOBBIES_1_007_CA_1_validation</td>\n",
       "      <td>1443</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>1444</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>1445</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>1446</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "5  HOBBIES_1_006_CA_1_validation     1442        3       1         0   \n",
       "6  HOBBIES_1_007_CA_1_validation     1443        3       1         0   \n",
       "7  HOBBIES_1_008_CA_1_validation     1444        3       1         0   \n",
       "8  HOBBIES_1_009_CA_1_validation     1445        3       1         0   \n",
       "9  HOBBIES_1_010_CA_1_validation     1446        3       1         0   \n",
       "\n",
       "   state_id  demand   part       date  wm_yr_wk  ...  cloudcover  humidity  \\\n",
       "0         0       0  train 2014-04-02     11409  ...          10        49   \n",
       "1         0       0  train 2014-04-02     11409  ...          10        49   \n",
       "2         0       0  train 2014-04-02     11409  ...          10        49   \n",
       "3         0       0  train 2014-04-02     11409  ...          10        49   \n",
       "4         0       2  train 2014-04-02     11409  ...          10        49   \n",
       "5         0       1  train 2014-04-02     11409  ...          10        49   \n",
       "6         0       1  train 2014-04-02     11409  ...          10        49   \n",
       "7         0       9  train 2014-04-02     11409  ...          10        49   \n",
       "8         0       0  train 2014-04-02     11409  ...          10        49   \n",
       "9         0       1  train 2014-04-02     11409  ...          10        49   \n",
       "\n",
       "   precipMM  pressure  population  lag_0  lag_1  lag_3  lag_7  lag_28  \n",
       "0  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "1  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "2  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "3  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "4  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "5  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "6  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "7  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "8  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "9  0.199951      1014  27511000.0    NaN    NaN    NaN    NaN     NaN  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_1_rolling_mean_14</th>\n",
       "      <th>shift_1_rolling_std_14</th>\n",
       "      <th>shift_1_rolling_mean_28</th>\n",
       "      <th>shift_1_rolling_std_28</th>\n",
       "      <th>shift_7_rolling_std_7</th>\n",
       "      <th>shift_7_rolling_std_14</th>\n",
       "      <th>shift_7_rolling_std_28</th>\n",
       "      <th>shift_7_rolling_mean_7</th>\n",
       "      <th>shift_7_rolling_mean_14</th>\n",
       "      <th>shift_7_rolling_mean_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23843175</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843176</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843177</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843178</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843179</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  item_id  dept_id  cat_id  store_id  \\\n",
       "23843175  FOODS_3_823_WI_3_validation     1432        2       0         9   \n",
       "23843176  FOODS_3_824_WI_3_validation     1433        2       0         9   \n",
       "23843177  FOODS_3_825_WI_3_validation     1434        2       0         9   \n",
       "23843178  FOODS_3_826_WI_3_validation     1435        2       0         9   \n",
       "23843179  FOODS_3_827_WI_3_validation     1436        2       0         9   \n",
       "\n",
       "          state_id  demand   part       date  wm_yr_wk  ...  \\\n",
       "23843175         2       0  test1 2016-05-22     11617  ...   \n",
       "23843176         2       0  test1 2016-05-22     11617  ...   \n",
       "23843177         2       0  test1 2016-05-22     11617  ...   \n",
       "23843178         2       0  test1 2016-05-22     11617  ...   \n",
       "23843179         2       0  test1 2016-05-22     11617  ...   \n",
       "\n",
       "          shift_1_rolling_mean_14  shift_1_rolling_std_14  \\\n",
       "23843175                      0.0                     0.0   \n",
       "23843176                      0.0                     0.0   \n",
       "23843177                      0.0                     0.0   \n",
       "23843178                      0.0                     0.0   \n",
       "23843179                      0.0                     0.0   \n",
       "\n",
       "          shift_1_rolling_mean_28  shift_1_rolling_std_28  \\\n",
       "23843175                      0.0                     0.0   \n",
       "23843176                      0.0                     0.0   \n",
       "23843177                      0.0                     0.0   \n",
       "23843178                      0.0                     0.0   \n",
       "23843179                      0.0                     0.0   \n",
       "\n",
       "          shift_7_rolling_std_7  shift_7_rolling_std_14  \\\n",
       "23843175                    0.0                     0.0   \n",
       "23843176                    0.0                     0.0   \n",
       "23843177                    0.0                     0.0   \n",
       "23843178                    0.0                     0.0   \n",
       "23843179                    0.0                     0.0   \n",
       "\n",
       "          shift_7_rolling_std_28  shift_7_rolling_mean_7  \\\n",
       "23843175                0.185547                     0.0   \n",
       "23843176                0.000000                     0.0   \n",
       "23843177                0.000000                     0.0   \n",
       "23843178                0.185547                     0.0   \n",
       "23843179                0.000000                     0.0   \n",
       "\n",
       "          shift_7_rolling_mean_14  shift_7_rolling_mean_28  \n",
       "23843175                      0.0                 0.035706  \n",
       "23843176                      0.0                 0.000000  \n",
       "23843177                      0.0                 0.000000  \n",
       "23843178                      0.0                 0.035706  \n",
       "23843179                      0.0                 0.000000  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "######################################################################## \n",
      "Adding lag columns\n",
      "Time: 2.83 seconds\n",
      "######################################################################## \n",
      "Adding rolling columns\n",
      "\n",
      "mean with window 7 time: 2.17 seconds\n",
      "std with window 7 time: 3.73 seconds\n",
      "mean with window 14 time: 2.34 seconds\n",
      "std with window 14 time: 6.72 seconds\n",
      "mean with window 28 time: 2.41 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "test1, test2, test3, test4 = run_lgb_weekly(data, features1, features2, features3, features4, cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(test1, submission, 1)\n",
    "submit(test2, submission, 2)\n",
    "submit(test3, submission, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import inv_boxcox\n",
    "from typing import Tuple\n",
    "import lightgbm as lgb\n",
    "from datetime import timedelta\n",
    "\n",
    "def differencing(data):\n",
    "    data = data.sort_values(['id', 'date'])\n",
    "    data['differenced_transformation_demand'] = data.groupby('id')['demand'].diff().values\n",
    "    data['differenced_demand_filled'] = np.where(pd.isnull(data['differenced_transformation_demand']),\n",
    "                                                 data['demand'], data['differenced_transformation_demand'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = differencing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore everything below this point, its just stuff I have used for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features(data):    \n",
    "    data_fe = data[['id', 'demand']]\n",
    "    \n",
    "    temp = data_fe\n",
    "    temp.set_index(data['date'])\n",
    "    weighted_periods = [1]\n",
    "    weighted_group = temp.groupby('id')[\"demand\"]\n",
    "    \n",
    "    for weight in weighted_periods:\n",
    "        data_fe['weighted_sales_t' + str(weight)] = weighted_group.transform(lambda x: x.ewm(span = weight + 28).mean())\n",
    "    \n",
    "    data_fe = reduce_mem_usage(data_fe)\n",
    "    \n",
    "    return data_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test1, test2, test3, submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>new_weights</th>\n",
       "      <th>revenue</th>\n",
       "      <th>gaps</th>\n",
       "      <th>gap_days</th>\n",
       "      <th>gap_confirm</th>\n",
       "      <th>out_of_stock</th>\n",
       "      <th>combined_y</th>\n",
       "      <th>scaled_weight</th>\n",
       "      <th>differenced_transformation_demand</th>\n",
       "      <th>differenced_demand_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3658800</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3658801</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.145767e-06</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3658802</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3658803</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312132e-05</td>\n",
       "      <td>13.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3658804</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>9.735425e-06</td>\n",
       "      <td>8.64</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             id  item_id  dept_id  cat_id  \\\n",
       "0     3658800  HOBBIES_1_001_CA_1_validation     1437        3       1   \n",
       "1     3658801  HOBBIES_1_002_CA_1_validation     1438        3       1   \n",
       "2     3658802  HOBBIES_1_003_CA_1_validation     1439        3       1   \n",
       "3     3658803  HOBBIES_1_004_CA_1_validation     1440        3       1   \n",
       "4     3658804  HOBBIES_1_005_CA_1_validation     1441        3       1   \n",
       "\n",
       "   store_id  state_id  demand   part        date  ...   new_weights  revenue  \\\n",
       "0         0         0       0  train  2014-08-30  ...  1.000000e-07     0.00   \n",
       "1         0         0       1  train  2014-08-30  ...  2.145767e-06     3.97   \n",
       "2         0         0       0  train  2014-08-30  ...  1.000000e-07     0.00   \n",
       "3         0         0       3  train  2014-08-30  ...  6.312132e-05    13.92   \n",
       "4         0         0       3  train  2014-08-30  ...  9.735425e-06     8.64   \n",
       "\n",
       "   gaps  gap_days  gap_confirm  out_of_stock                     combined_y  \\\n",
       "0     1       2.0          2.0           2.0  HOBBIES_1_001_CA_1_validation   \n",
       "1     0       3.0          0.0           0.0  HOBBIES_1_002_CA_1_validation   \n",
       "2     1       6.0          6.0           6.0  HOBBIES_1_003_CA_1_validation   \n",
       "3     0       0.0          0.0           0.0  HOBBIES_1_004_CA_1_validation   \n",
       "4     0       5.0          0.0           0.0  HOBBIES_1_005_CA_1_validation   \n",
       "\n",
       "   scaled_weight  differenced_transformation_demand differenced_demand_filled  \n",
       "0       0.000051                                NaN                       0.0  \n",
       "1       0.000003                                NaN                       1.0  \n",
       "2       0.000014                                NaN                       0.0  \n",
       "3       0.000024                                NaN                       3.0  \n",
       "4       0.000018                                NaN                       3.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/NeehalTumma/Downloads/data_with_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"scaled_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>daily_scales</th>\n",
       "      <th>new_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3658800</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3658801</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.145767e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3658802</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3658803</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>1.5060</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5720</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.312132e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3658804</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.735425e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             id  item_id  dept_id  cat_id  \\\n",
       "0     3658800  HOBBIES_1_001_CA_1_validation     1437        3       1   \n",
       "1     3658801  HOBBIES_1_002_CA_1_validation     1438        3       1   \n",
       "2     3658802  HOBBIES_1_003_CA_1_validation     1439        3       1   \n",
       "3     3658803  HOBBIES_1_004_CA_1_validation     1440        3       1   \n",
       "4     3658804  HOBBIES_1_005_CA_1_validation     1441        3       1   \n",
       "\n",
       "   store_id  state_id  demand   part        date  ...  sales_lag_t5  \\\n",
       "0         0         0       0  train  2014-08-30  ...           1.0   \n",
       "1         0         0       1  train  2014-08-30  ...           1.0   \n",
       "2         0         0       0  train  2014-08-30  ...           0.0   \n",
       "3         0         0       3  train  2014-08-30  ...           2.0   \n",
       "4         0         0       3  train  2014-08-30  ...           1.0   \n",
       "\n",
       "   demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "0                  0.3333                 0.5166           1.0   \n",
       "1                  0.5000                 0.8364           0.0   \n",
       "2                  0.0000                 0.0000           0.0   \n",
       "3                  1.6670                 1.5060           8.0   \n",
       "4                  0.6665                 0.8164           2.0   \n",
       "\n",
       "   demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \\\n",
       "0                  0.4285                 0.5347           0.0       1   \n",
       "1                  0.4285                 0.7866           0.0       1   \n",
       "2                  0.0000                 0.0000           0.0       1   \n",
       "3                  2.5720                 2.7600           3.0       1   \n",
       "4                  0.8570                 0.9000           2.0       1   \n",
       "\n",
       "   daily_scales   new_weights  \n",
       "0           0.0  1.000000e-07  \n",
       "1           1.0  2.145767e-06  \n",
       "2           0.0  1.000000e-07  \n",
       "3           1.0  6.312132e-05  \n",
       "4           3.0  9.735425e-06  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t1_28', \n",
    "            'demand_rolling_std_t1_28', 'sales_lag_t1_28', 'demand_rolling_mean_t2_28', 'demand_rolling_std_t2_28', 'sales_lag_t2_28'\n",
    "            , 'demand_rolling_mean_t3_28', 'demand_rolling_std_t3_28', 'sales_lag_t3_28', 'demand_rolling_mean_t4_28'\n",
    "            ,'demand_rolling_std_t4_28', 'sales_lag_t4_28', 'demand_rolling_mean_t5_28', 'demand_rolling_std_t5_28', \n",
    "            'sales_lag_t5_28', 'demand_rolling_mean_t6_28', 'demand_rolling_std_t6_28', 'sales_lag_t6_28', 'demand_rolling_mean_t7_28',\n",
    "            'demand_rolling_std_t7_28', 'sales_lag_t7_28', 'season', 'totalSnow_cm', 'FeelsLikeC', 'HeatIndexC',\n",
    "                  'WindChillC', 'humidity', 'precipMM', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'imputed_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t1', \n",
    "            'demand_rolling_std_t1', 'sales_lag_t1', 'demand_rolling_mean_t2', 'demand_rolling_std_t2', 'sales_lag_t2'\n",
    "            , 'demand_rolling_mean_t3', 'demand_rolling_std_t3', 'sales_lag_t3', 'demand_rolling_mean_t4'\n",
    "            ,'demand_rolling_std_t4', 'sales_lag_t4', 'demand_rolling_mean_t5', 'demand_rolling_std_t5', \n",
    "            'sales_lag_t5', 'demand_rolling_mean_t6', 'demand_rolling_std_t6', 'sales_lag_t6', 'demand_rolling_mean_t7',\n",
    "            'demand_rolling_std_t7', 'sales_lag_t7', 'season', 'totalSnow_cm', 'FeelsLikeC', 'HeatIndexC',\n",
    "                  'WindChillC', 'humidity',\n",
    "                  'precipMM', 'population'] \n",
    "\n",
    "#'price_max', 'price_min', 'price_std', 'price_mean','price_norm', 'price_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y'\n",
    "#'weighted_sales_t1', 'weighted_sales_t2', 'weighted_sales_t3', 'weighted_sales_t4', 'weighted_sales_t5', 'weighted_sales_t6', 'weighted_sales_t7', \"sale_momentum_y\", \"sale_momentum_m\"\n",
    "\n",
    "keep_columns = ['date', 'demand', 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "            'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n",
    "                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t1', \n",
    "            'demand_rolling_std_t1', 'sales_lag_t1', 'demand_rolling_mean_t2', 'demand_rolling_std_t2', 'sales_lag_t2'\n",
    "            , 'demand_rolling_mean_t3', 'demand_rolling_std_t3', 'sales_lag_t3', 'demand_rolling_mean_t4'\n",
    "            ,'demand_rolling_std_t4', 'sales_lag_t4', 'demand_rolling_mean_t5', 'demand_rolling_std_t5', \n",
    "            'sales_lag_t5', 'demand_rolling_mean_t6', 'demand_rolling_std_t6', 'sales_lag_t6', 'demand_rolling_mean_t7',\n",
    "            'demand_rolling_std_t7', 'sales_lag_t7', 'season']\n",
    "\n",
    "cat_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', \n",
    "                    'event_name_2', 'event_type_2']\n",
    "\n",
    "\n",
    "cat_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1672.31 Mb (74.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>13.92</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>1.5060</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5720</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  revenue  demand                             id  item_id  \\\n",
       "0  2014-08-30     0.00       0  HOBBIES_1_001_CA_1_validation     1437   \n",
       "1  2014-08-30     3.97       1  HOBBIES_1_002_CA_1_validation     1438   \n",
       "2  2014-08-30     0.00       0  HOBBIES_1_003_CA_1_validation     1439   \n",
       "3  2014-08-30    13.92       3  HOBBIES_1_004_CA_1_validation     1440   \n",
       "4  2014-08-30     8.64       3  HOBBIES_1_005_CA_1_validation     1441   \n",
       "\n",
       "   dept_id  cat_id  store_id  state_id  event_name_1  ...  sales_lag_t5  \\\n",
       "0        3       1         0         0            30  ...           1.0   \n",
       "1        3       1         0         0            30  ...           1.0   \n",
       "2        3       1         0         0            30  ...           0.0   \n",
       "3        3       1         0         0            30  ...           2.0   \n",
       "4        3       1         0         0            30  ...           1.0   \n",
       "\n",
       "   demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "0                  0.3333                 0.5166           1.0   \n",
       "1                  0.5000                 0.8364           0.0   \n",
       "2                  0.0000                 0.0000           0.0   \n",
       "3                  1.6670                 1.5060           8.0   \n",
       "4                  0.6665                 0.8164           2.0   \n",
       "\n",
       "   demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \\\n",
       "0                  0.4285                 0.5347           0.0       1   \n",
       "1                  0.4285                 0.7866           0.0       1   \n",
       "2                  0.0000                 0.0000           0.0       1   \n",
       "3                  2.5720                 2.7600           3.0       1   \n",
       "4                  0.8570                 0.9000           2.0       1   \n",
       "\n",
       "                        combined  scaled_weight  \n",
       "0  HOBBIES_1_001_CA_1_validation       0.000051  \n",
       "1  HOBBIES_1_002_CA_1_validation       0.000003  \n",
       "2  HOBBIES_1_003_CA_1_validation       0.000014  \n",
       "3  HOBBIES_1_004_CA_1_validation       0.000024  \n",
       "4  HOBBIES_1_005_CA_1_validation       0.000018  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>weighted_sales_t5</th>\n",
       "      <th>weighted_sales_t6</th>\n",
       "      <th>weighted_sales_t7</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>weight</th>\n",
       "      <th>scale</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>11519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024826</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>26720</td>\n",
       "      <td>Level12</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.364985</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>11519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292725</td>\n",
       "      <td>0.294189</td>\n",
       "      <td>0.295410</td>\n",
       "      <td>26730</td>\n",
       "      <td>Level12</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.612210</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>11519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415527</td>\n",
       "      <td>0.415039</td>\n",
       "      <td>0.414307</td>\n",
       "      <td>26740</td>\n",
       "      <td>Level12</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.785626</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>11519</td>\n",
       "      <td>...</td>\n",
       "      <td>2.517578</td>\n",
       "      <td>2.519531</td>\n",
       "      <td>2.521484</td>\n",
       "      <td>26750</td>\n",
       "      <td>Level12</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>7.189765</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>11519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419189</td>\n",
       "      <td>0.421387</td>\n",
       "      <td>0.423584</td>\n",
       "      <td>26760</td>\n",
       "      <td>Level12</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id  demand   part       date  wm_yr_wk  ...  weighted_sales_t5  \\\n",
       "0         0       0  train 2015-06-06     11519  ...           0.024826   \n",
       "1         0       0  train 2015-06-06     11519  ...           0.292725   \n",
       "2         0       1  train 2015-06-06     11519  ...           0.415527   \n",
       "3         0       2  train 2015-06-06     11519  ...           2.517578   \n",
       "4         0       0  train 2015-06-06     11519  ...           0.419189   \n",
       "\n",
       "   weighted_sales_t6  weighted_sales_t7  Unnamed: 0  Level_id    Agg_Level_1  \\\n",
       "0           0.025848           0.026855       26720   Level12  HOBBIES_1_001   \n",
       "1           0.294189           0.295410       26730   Level12  HOBBIES_1_002   \n",
       "2           0.415039           0.414307       26740   Level12  HOBBIES_1_003   \n",
       "3           2.519531           2.521484       26750   Level12  HOBBIES_1_004   \n",
       "4           0.421387           0.423584       26760   Level12  HOBBIES_1_005   \n",
       "\n",
       "   Agg_Level_2    weight     scale                       combined  \n",
       "0         CA_1  0.000060  1.364985  HOBBIES_1_001_CA_1_validation  \n",
       "1         CA_1  0.000002  0.612210  HOBBIES_1_002_CA_1_validation  \n",
       "2         CA_1  0.000013  0.785626  HOBBIES_1_003_CA_1_validation  \n",
       "3         CA_1  0.000063  7.189765  HOBBIES_1_004_CA_1_validation  \n",
       "4         CA_1  0.000029  2.670000  HOBBIES_1_005_CA_1_validation  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "id\n",
      "item_id\n",
      "dept_id\n",
      "cat_id\n",
      "store_id\n",
      "state_id\n",
      "demand\n",
      "part\n",
      "date\n",
      "wm_yr_wk\n",
      "event_name_1\n",
      "event_type_1\n",
      "event_name_2\n",
      "event_type_2\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "sell_price\n",
      "Level_id\n",
      "Agg_Level_1\n",
      "Agg_Level_2\n",
      "weight\n",
      "scale\n",
      "combined_x\n",
      "year\n",
      "month\n",
      "quarter\n",
      "week\n",
      "day\n",
      "dayofweek\n",
      "dayofyear\n",
      "demand_rolling_mean_t1\n",
      "demand_rolling_std_t1\n",
      "sales_lag_t1\n",
      "demand_rolling_mean_t2\n",
      "demand_rolling_std_t2\n",
      "sales_lag_t2\n",
      "demand_rolling_mean_t3\n",
      "demand_rolling_std_t3\n",
      "sales_lag_t3\n",
      "demand_rolling_mean_t4\n",
      "demand_rolling_std_t4\n",
      "sales_lag_t4\n",
      "demand_rolling_mean_t5\n",
      "demand_rolling_std_t5\n",
      "sales_lag_t5\n",
      "demand_rolling_mean_t6\n",
      "demand_rolling_std_t6\n",
      "sales_lag_t6\n",
      "demand_rolling_mean_t7\n",
      "demand_rolling_std_t7\n",
      "sales_lag_t7\n",
      "season\n",
      "daily_scales\n",
      "new_weights\n",
      "revenue\n",
      "gaps\n",
      "gap_days\n",
      "gap_confirm\n",
      "out_of_stock\n",
      "combined_y\n",
      "scaled_weight\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['combined_y']\n",
    "\n",
    "#del data[['combined_y', 'revenue', 'new_weights', 'daily_scales', 'combined_x', 'weight', 'scale', 'Level_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_data = weighted_data[weighted_data['date'] >= '2014-06-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "10732480\n",
      "yuh\n",
      "10732480\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print(data[feature].size)\n",
    "\n",
    "print(\"yuh\")\n",
    "print(data['demand'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next_test = run_lgb(data, features, cat_features)\n",
    "submit(next_test, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>13.92</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>1.5060</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5720</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  revenue  demand                             id  item_id  \\\n",
       "0  2014-08-30     0.00       0  HOBBIES_1_001_CA_1_validation     1437   \n",
       "1  2014-08-30     3.97       1  HOBBIES_1_002_CA_1_validation     1438   \n",
       "2  2014-08-30     0.00       0  HOBBIES_1_003_CA_1_validation     1439   \n",
       "3  2014-08-30    13.92       3  HOBBIES_1_004_CA_1_validation     1440   \n",
       "4  2014-08-30     8.64       3  HOBBIES_1_005_CA_1_validation     1441   \n",
       "\n",
       "   dept_id  cat_id  store_id  state_id  event_name_1  ...  sales_lag_t5  \\\n",
       "0        3       1         0         0            30  ...           1.0   \n",
       "1        3       1         0         0            30  ...           1.0   \n",
       "2        3       1         0         0            30  ...           0.0   \n",
       "3        3       1         0         0            30  ...           2.0   \n",
       "4        3       1         0         0            30  ...           1.0   \n",
       "\n",
       "   demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "0                  0.3333                 0.5166           1.0   \n",
       "1                  0.5000                 0.8364           0.0   \n",
       "2                  0.0000                 0.0000           0.0   \n",
       "3                  1.6670                 1.5060           8.0   \n",
       "4                  0.6665                 0.8164           2.0   \n",
       "\n",
       "   demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \\\n",
       "0                  0.4285                 0.5347           0.0       1   \n",
       "1                  0.4285                 0.7866           0.0       1   \n",
       "2                  0.0000                 0.0000           0.0       1   \n",
       "3                  2.5720                 2.7600           3.0       1   \n",
       "4                  0.8570                 0.9000           2.0       1   \n",
       "\n",
       "                        combined  scaled_weight  \n",
       "0  HOBBIES_1_001_CA_1_validation       0.000272  \n",
       "1  HOBBIES_1_002_CA_1_validation       0.000014  \n",
       "2  HOBBIES_1_003_CA_1_validation       0.000076  \n",
       "3  HOBBIES_1_004_CA_1_validation       0.000125  \n",
       "4  HOBBIES_1_005_CA_1_validation       0.000095  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_data = weighted_data[weighted_data['date'] >= '2014-08-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    total = 0\n",
    "    total += weighted_data[feature].isnull().sum()\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>daily_scales</th>\n",
       "      <th>new_weights</th>\n",
       "      <th>revenue</th>\n",
       "      <th>gaps</th>\n",
       "      <th>gap_days</th>\n",
       "      <th>gap_confirm</th>\n",
       "      <th>out_of_stock</th>\n",
       "      <th>scaled_weight</th>\n",
       "      <th>differenced_transformation_demand</th>\n",
       "      <th>differenced_demand_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, id, item_id, dept_id, cat_id, store_id, state_id, demand, part, date, wm_yr_wk, event_name_1, event_type_1, event_name_2, event_type_2, snap_CA, snap_TX, snap_WI, sell_price, Level_id, Agg_Level_1, Agg_Level_2, weight, scale, combined_x, year, month, quarter, week, day, dayofweek, dayofyear, demand_rolling_mean_t1, demand_rolling_std_t1, sales_lag_t1, demand_rolling_mean_t2, demand_rolling_std_t2, sales_lag_t2, demand_rolling_mean_t3, demand_rolling_std_t3, sales_lag_t3, demand_rolling_mean_t4, demand_rolling_std_t4, sales_lag_t4, demand_rolling_mean_t5, demand_rolling_std_t5, sales_lag_t5, demand_rolling_mean_t6, demand_rolling_std_t6, sales_lag_t6, demand_rolling_mean_t7, demand_rolling_std_t7, sales_lag_t7, season, daily_scales, new_weights, revenue, gaps, gap_days, gap_confirm, out_of_stock, scaled_weight, differenced_transformation_demand, differenced_demand_filled]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 64 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['date'] > '2014-08-30']\n",
    "gc.collect()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc574795d7e04404a204f7a4e74f5037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42840.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "e.get_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "\n",
    "class WRMSSEEvaluator(object):\n",
    "    \n",
    "    group_ids = ( 'all_id', 'state_id', 'store_id', 'cat_id', 'dept_id', 'item_id',\n",
    "        ['state_id', 'cat_id'],  ['state_id', 'dept_id'], ['store_id', 'cat_id'],\n",
    "        ['store_id', 'dept_id'], ['item_id', 'state_id'], ['item_id', 'store_id'])\n",
    "\n",
    "    def __init__(self, \n",
    "                 train_df: pd.DataFrame, \n",
    "                 valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, \n",
    "                 prices: pd.DataFrame):\n",
    "        '''\n",
    "        intialize and calculate weights\n",
    "        '''\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.train_target_columns = [i for i in self.train_df.columns if i.startswith('d_')]\n",
    "        self.weight_columns = self.train_df.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        self.train_df['all_id'] = \"all\"\n",
    "\n",
    "        self.id_columns = [i for i in self.train_df.columns if not i.startswith('d_')]\n",
    "        self.valid_target_columns = [i for i in self.valid_df.columns if i.startswith('d_')]\n",
    "\n",
    "        if not all([c in self.valid_df.columns for c in self.id_columns]):\n",
    "            self.valid_df = pd.concat([self.train_df[self.id_columns], self.valid_df],\n",
    "                                      axis=1, \n",
    "                                      sort=False)\n",
    "        self.train_series = self.trans_30490_to_42840(self.train_df, \n",
    "                                                      self.train_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        self.valid_series = self.trans_30490_to_42840(self.valid_df, \n",
    "                                                      self.valid_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        self.weights = self.get_weight_df()\n",
    "        self.scale = self.get_scale()\n",
    "        self.train_series = None\n",
    "        self.train_df = None\n",
    "        self.prices = None\n",
    "        self.calendar = None\n",
    "\n",
    "    def get_scale(self):\n",
    "        '''\n",
    "        scaling factor for each series ignoring starting zeros\n",
    "        '''\n",
    "        scales = []\n",
    "        for i in tqdm(range(len(self.train_series))):\n",
    "            series = self.train_series.iloc[i].values\n",
    "            series = series[np.argmax(series!=0):]\n",
    "            scale = ((series[1:] - series[:-1]) ** 2).mean()\n",
    "            scales.append(scale)\n",
    "        return np.array(scales)\n",
    "    \n",
    "    def get_name(self, i):\n",
    "        '''\n",
    "        convert a str or list of strings to unique string \n",
    "        used for naming each of 42840 series\n",
    "        '''\n",
    "        if type(i) == str or type(i) == int:\n",
    "            return str(i)\n",
    "        else:\n",
    "            return \"--\".join(i)\n",
    "    \n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        returns weights for each of 42840 series in a dataFrame\n",
    "        \"\"\"\n",
    "        day_to_week = self.calendar.set_index(\"d\")[\"wm_yr_wk\"].to_dict()\n",
    "        weight_df = self.train_df[[\"item_id\", \"store_id\"] + self.weight_columns].set_index(\n",
    "            [\"item_id\", \"store_id\"]\n",
    "        )\n",
    "        weight_df = (\n",
    "            weight_df.stack().reset_index().rename(columns={\"level_2\": \"d\", 0: \"value\"})\n",
    "        )\n",
    "        weight_df[\"wm_yr_wk\"] = weight_df[\"d\"].map(day_to_week)\n",
    "        weight_df = weight_df.merge(\n",
    "            self.prices, how=\"left\", on=[\"item_id\", \"store_id\", \"wm_yr_wk\"]\n",
    "        )\n",
    "        weight_df[\"value\"] = weight_df[\"value\"] * weight_df[\"sell_price\"]\n",
    "        weight_df = weight_df.set_index([\"item_id\", \"store_id\", \"d\"]).unstack(level=2)[\n",
    "            \"value\"\n",
    "        ]\n",
    "        weight_df = weight_df.loc[\n",
    "            zip(self.train_df.item_id, self.train_df.store_id), :\n",
    "        ].reset_index(drop=True)\n",
    "        weight_df = pd.concat(\n",
    "            [self.train_df[self.id_columns], weight_df], axis=1, sort=False\n",
    "        )\n",
    "        weights_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False)):\n",
    "            lv_weight = weight_df.groupby(group_id)[self.weight_columns].sum().sum(axis=1)\n",
    "            lv_weight = lv_weight / lv_weight.sum()\n",
    "            for i in range(len(lv_weight)):\n",
    "                weights_map[self.get_name(lv_weight.index[i])] = np.array(\n",
    "                    [lv_weight.iloc[i]]\n",
    "                )\n",
    "        weights = pd.DataFrame(weights_map).T / len(self.group_ids)\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def trans_30490_to_42840(self, df, cols, group_ids, dis=False):\n",
    "        '''\n",
    "        transform 30490 sries to all 42840 series\n",
    "        '''\n",
    "        series_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False, disable=dis)):\n",
    "            tr = df.groupby(group_id)[cols].sum()\n",
    "            for i in range(len(tr)):\n",
    "                series_map[self.get_name(tr.index[i])] = tr.iloc[i].values\n",
    "        return pd.DataFrame(series_map).T\n",
    "    \n",
    "    def get_rmsse(self, valid_preds) -> pd.Series:\n",
    "        '''\n",
    "        returns rmsse scores for all 42840 series\n",
    "        '''\n",
    "        score = ((self.valid_series - valid_preds) ** 2).mean(axis=1)\n",
    "        rmsse = (score / self.scale).map(np.sqrt)\n",
    "        return rmsse\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds],\n",
    "                                axis=1, \n",
    "                                sort=False)\n",
    "        valid_preds = self.trans_30490_to_42840(valid_preds, \n",
    "                                                self.valid_target_columns, \n",
    "                                                self.group_ids, \n",
    "                                                True)\n",
    "        self.rmsse = self.get_rmsse(valid_preds)\n",
    "        self.contributors = pd.concat([self.weights, self.rmsse], \n",
    "                                      axis=1, \n",
    "                                      sort=False).prod(axis=1)\n",
    "        return np.sum(self.contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('sales_train_evaluation.csv')\n",
    "temp_calendar = pd.read_csv('calendar.csv')\n",
    "temp_prices = pd.read_csv('sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19269675</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269676</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269677</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269678</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3330</td>\n",
       "      <td>1.3660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1430</td>\n",
       "      <td>1.3450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269679</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  revenue  demand                           id  item_id  \\\n",
       "19269675  2016-05-22      0.0       0  FOODS_3_823_WI_3_validation     1432   \n",
       "19269676  2016-05-22      0.0       0  FOODS_3_824_WI_3_validation     1433   \n",
       "19269677  2016-05-22      0.0       0  FOODS_3_825_WI_3_validation     1434   \n",
       "19269678  2016-05-22      0.0       0  FOODS_3_826_WI_3_validation     1435   \n",
       "19269679  2016-05-22      0.0       0  FOODS_3_827_WI_3_validation     1436   \n",
       "\n",
       "          dept_id  cat_id  store_id  state_id  event_name_1  ...  \\\n",
       "19269675        2       0         9         2            30  ...   \n",
       "19269676        2       0         9         2            30  ...   \n",
       "19269677        2       0         9         2            30  ...   \n",
       "19269678        2       0         9         2            30  ...   \n",
       "19269679        2       0         9         2            30  ...   \n",
       "\n",
       "          sales_lag_t5  demand_rolling_mean_t6  demand_rolling_std_t6  \\\n",
       "19269675           0.0                  0.3333                 0.5166   \n",
       "19269676           0.0                  0.1666                 0.4082   \n",
       "19269677           0.0                  0.3333                 0.5166   \n",
       "19269678           0.0                  1.3330                 1.3660   \n",
       "19269679           0.0                  0.0000                 0.0000   \n",
       "\n",
       "          sales_lag_t6  demand_rolling_mean_t7  demand_rolling_std_t7  \\\n",
       "19269675           0.0                  0.2856                 0.4880   \n",
       "19269676           0.0                  0.1428                 0.3780   \n",
       "19269677           2.0                  0.5713                 0.7866   \n",
       "19269678           0.0                  1.1430                 1.3450   \n",
       "19269679           0.0                  0.0000                 0.0000   \n",
       "\n",
       "          sales_lag_t7  season                     combined  scaled_weight  \n",
       "19269675           0.0       0  FOODS_3_823_WI_3_validation       0.000004  \n",
       "19269676           0.0       0  FOODS_3_824_WI_3_validation       0.000006  \n",
       "19269677           0.0       0  FOODS_3_825_WI_3_validation       0.000018  \n",
       "19269678           1.0       0  FOODS_3_826_WI_3_validation       0.000006  \n",
       "19269679           0.0       0  FOODS_3_827_WI_3_validation       0.000003  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRMSSEForLightGBM(WRMSSEEvaluator):\n",
    "    def feval(self, preds, dtrain):\n",
    "        preds = preds.reshape(self.valid_df[self.valid_target_columns].shape, order='F') #.transpose()\n",
    "        score = self.score(preds)\n",
    "        return 'WRMSSE', score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('sales_train_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 96.13 Mb (78.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "temp_df = reduce_mem_usage(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df = training_df.iloc[:, :-28]\n",
    "valid_fold_df = training_df.iloc[:, -28:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_cython_func_and_vals\u001b[0;34m(self, kind, how, values, is_numeric)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_cython_function\u001b[0;34m(self, kind, how, values, is_numeric)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0;34mf\"function is not implemented for this dtype: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->add,dtype->int64]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-76187b2c414c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrmsse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWRMSSEForLightGBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fold_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_fold_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_calendar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_prices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-9aec74de50c7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_df, valid_df, calendar, prices)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                       \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                       sort=False)\n\u001b[0;32m---> 36\u001b[0;31m         self.train_series = self.trans_30490_to_42840(self.train_df, \n\u001b[0m\u001b[1;32m     37\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_target_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                                       self.group_ids)\n",
      "\u001b[0;32m<ipython-input-5-9aec74de50c7>\u001b[0m in \u001b[0;36mtrans_30490_to_42840\u001b[0;34m(self, df, cols, group_ids, dis)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mseries_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mseries_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 \u001b[0;31m# try a cython aggregation if we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     ) -> DataFrame:\n\u001b[0;32m--> 993\u001b[0;31m         agg_blocks, agg_items = self._cython_agg_blocks(\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_cython_agg_blocks\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                 result, _ = self.grouper.aggregate(\n\u001b[0m\u001b[1;32m   1023\u001b[0m                     \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, values, how, axis, min_count)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     ) -> Tuple[np.ndarray, Optional[List[str]]]:\n\u001b[0;32m--> 586\u001b[0;31m         return self._cython_operation(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mout_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_func_and_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_cython_func_and_vals\u001b[0;34m(self, kind, how, values, is_numeric)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_float64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"complex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wrmsse = WRMSSEForLightGBM(train_fold_df, valid_fold_df, temp_calendar, temp_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n"
     ]
    }
   ],
   "source": [
    "n = len(numbers)\n",
    "h = 28\n",
    "total = 0\n",
    "\n",
    "for i in range(n):\n",
    "    if(i != 0):\n",
    "        total += ((numbers[i] - numbers[i - 1])**2)\n",
    "        \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del testing_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del training_df, temp_calendar, temp_prices, train_fold_df, valid_fold_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1886</th>\n",
       "      <th>d_1887</th>\n",
       "      <th>d_1888</th>\n",
       "      <th>d_1889</th>\n",
       "      <th>d_1890</th>\n",
       "      <th>d_1891</th>\n",
       "      <th>d_1892</th>\n",
       "      <th>d_1893</th>\n",
       "      <th>d_1894</th>\n",
       "      <th>d_1895</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_1886  d_1887  d_1888  d_1889  d_1890  d_1891  d_1892  d_1893  d_1894  \\\n",
       "0       1       0       0       0       0       0       1       0       4   \n",
       "1       1       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       1       0       0   \n",
       "3       0       0       0       0       3       1       2       1       3   \n",
       "4       1       0       4       4       0       1       4       0       1   \n",
       "\n",
       "   d_1895  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  \\\n",
       "0       2  ...       1       3       0       1       1       1       3   \n",
       "1       0  ...       0       0       0       0       0       1       0   \n",
       "2       0  ...       2       1       2       1       1       1       0   \n",
       "3       1  ...       1       0       5       4       1       0       1   \n",
       "4       0  ...       2       1       1       0       1       1       2   \n",
       "\n",
       "   d_1911  d_1912  d_1913  \n",
       "0       0       1       1  \n",
       "1       0       0       0  \n",
       "2       1       1       1  \n",
       "3       3       7       2  \n",
       "4       2       2       4  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_fold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cc32abbc6a4743b1d094560efd6f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42840.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "e = WRMSSEEvaluator(train_fold_df, valid_fold_df, temp_calendar, temp_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del temp_df, train_fold_df, valid_fold_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df = training_df.iloc[:, :-28]\n",
    "valid_fold_df = training_df.iloc[:, -28:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined</th>\n",
       "      <th>scaled_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26720</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            combined  scaled_weight\n",
       "26720  HOBBIES_1_001_CA_1_validation       0.000051"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_weights[temp_weights['combined'] == 'HOBBIES_1_001_CA_1_validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b699fdfd0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAEWCAYAAACOk1WwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3hVVdaH3wWhGooUHZogHQJJnFAVIciAUgQLVkYIlrErzlBklOaMXxiK0uygIDioiBRFbEDAgiBgAEVQlCBtgCAt1JT1/bFPrjfhJiSQznqf5zz3nH12WXujWWe33xZVxTAMwzCMokmx/DbAMAzDMIzcwxy9YRiGYRRhzNEbhmEYRhHGHL1hGIZhFGHM0RuGYRhGEcYcvWEYhmEUYczRG4ZRpBGRl0VkWH7bYRj5hdg+esMwAiEiccClQLJfcENV3X0eeUYCs1S15vlZVzgRkenATlV9Or9tMS4crEdvGEZmXK+qwX7XOTv5nEBEgvKz/PNBRIrntw3GhYk5esMwso2ItBGRr0XkkIis93rqqe/6i8iPInJURH4Vkfu98IuAxUB1EUnwruoiMl1E/u2XPlJEdvo9x4nIEBHZABwTkSAv3VwR2S8i20TksUxs9eWfmreIDBaRfSKyR0RuEJFuIvKTiPwuIv/0SztSRN4TkXe8+qwTkTC/901EJMZrhx9EpGe6cl8SkY9E5BhwD9AHGOzV/QMv3pMi8ouX/yYRudEvjygR+VJExonIQa+uXf3eVxKRN0Rkt/d+vt+7HiIS69n2tYiEZvkf2ChSmKM3DCNbiEgNYBHwb6ASMBCYKyJVvSj7gB5AeaA/8LyI/FlVjwFdgd3nMEJwB9AdqAikAB8A64EaQCdggIhcm8W8/gSU9tIOB14D/gpEAFcDw0Wkrl/8XsAcr67/BeaLSAkRKeHZ8SlwCfAo8JaINPJLeyfwLFAOeBN4Cxjj1f16L84vXrkVgFHALBGp5pdHa2ALUAUYA0wTEfHezQTKAiGeDc8DiMifgdeB+4HKwCvAQhEplcU2MooQ5ugNw8iM+V6P8JBfb/GvwEeq+pGqpqjqZ8AaoBuAqi5S1V/UsRznCK8+TzsmqeoOVT0BtASqquozqnpaVX/FOevbs5hXIvCsqiYCb+Mc6ERVPaqqPwA/AP6937Wq+p4X/zncR0Ib7woGRnt2LAU+xH2UpLJAVb/y2ulkIGNUdY6q7vbivAP8DLTyi7JdVV9T1WRgBlANuNT7GOgKPKCqB1U10WtvgPuAV1R1laomq+oM4JRns3GBUWjnuwzDyBNuUNXP04XVBm4Rkev9wkoAywC8oeURQENcZ6IssPE87diRrvzqInLIL6w48EUW8zrgOU2AE97vXr/3J3AO/IyyVTXFm1aonvpOVVP84m7HjRQEsjsgItIX+DtQxwsKxn18pPI/v/KPe535YNwIw++qejBAtrWBfiLyqF9YST+7jQsIc/SGYWSXHcBMVb0v/QtvaHgu0BfXm030RgJSh5oDbfM5hvsYSOVPAeL4p9sBbFPVBudi/DlQK/VGRIoBNYHUKYdaIlLMz9lfBvzklzZ9fdM8i0ht3GhEJ2ClqiaLSCx/tFdm7AAqiUhFVT0U4N2zqvpsFvIxijg2dG8YRnaZBVwvIteKSHERKe0tcquJ6zWWAvYDSV7vvotf2r1AZRGp4BcWC3TzFpb9CRhwlvJXA0e8BXplPBuaiUjLHKthWiJE5CZvxf8A3BD4N8Aq3EfKYG/OPhK4HjcdkBF7Af/5/4twzn8/uIWMQLOsGKWqe3CLG18UkYs9G9p7r18DHhCR1uK4SES6i0i5LNbZKEKYozcMI1uo6g7cArV/4hzUDmAQUExVjwKPAe8CB3GL0Rb6pd0MzAZ+9eb9q+MWlK0H4nDz+e+cpfxknEMNB7YB8cBU3GK23GABcBuuPncBN3nz4aeBnrh58njgRaCvV8eMmAY0TV3zoKqbgPHAStxHQHPgq2zYdhduzcFm3CLIAQCqugY3Tz/Fs3srEJWNfI0ihAnmGIZhZICIjATqq+pf89sWwzhXrEdvGIZhGEUYc/SGYRiGUYSxoXvDMAzDKMJYj94wDMMwijC2j97IEypWrKj169fPbzPynWPHjnHRRRfltxn5jrWDw9rBYe3gCNQOa9eujVfVqhkkyRLm6I084dJLL2XNmjX5bUa+ExMTQ2RkZH6bke9YOzisHRzWDo5A7SAi2883Xxu6NwzDMIwijDl6wzAMwyjCmKM3DMMwjCKMOXrDMAzDKMKYozcMwzCMIow5esMwDMPIIsnJyVxxxRX06NEDAFXlqaeeomHDhjRp0oRJkyYBsHnzZtq2bUupUqUYN26cL/3Jkydp1aoVYWFhhISEMGLEiDPKePTRRwkODs4xm217XSFGRL5W1StFpA5wpar+NxfLegA4rqpvpguvA3yoqlk6WtMwDKMwM3HiRJo0acKRI0cAmD59Ojt27GDz5s0UK1aMffv2AVCpUiUmTZrE/Pnz06QvVaoUS5cuJTg4mMTERNq1a0fXrl1p06YNAGvWrOHQoUM5arP16Asxqnqld1sHdxxobpb1cnonbxiGcSGxc+dOFi1axL333usLe+mllxg+fDjFijl3eskll/h+W7ZsSYkSJdLkISK+3npiYiKJiYmICOBGCwYNGsSYMWNy1G7r0RdiRCRBVYOB0UATEYkFZgCTvLBIoBTwgqq+IiKRwCjcudfhwPvARuBxoAxwg6r+kkFZI4EEVR0nIhHA68Bx4Mus2HoiMZk6Ty46x5oWHf7RPIkoawdrBw9rB0dhaIe40d0ZMGAAY8aM4ejRo77wX375hXfeeYd58+ZRtWpVJk2aRIMGDTLNKzk5mYiICLZu3crDDz9M69atAZg3bx49e/akWrVqOWq7OfqiwZPAQFXtASAifwMOq2pLESkFfCUin3pxw4AmwO/Ar8BUVW0lIo8DjwIDslDeG8CjqrpcRMZmFMmz428AVapUZXjzpHOsXtHh0jLuj9qFjrWDw9rBURjaITo6msTERI4ePUpsbCwHDhwgJiaG48ePs2vXLsaNG8eKFSu4+eabffP0AHFxcZQpU4aYmJg0+U2YMIGEhASGDRtG48aNKVeuHEuXLuXGG28kJiaG5OTkM9KcK+boiyZdgFAR6e09VwAaAKeBb1V1D4CI/AKkfgBsBDqeLWMRqQBUVNXlXtBMoGuguKr6KvAqQKNGjfTRPr3OrTZFiJiYGG41qU9rBw9rB0dhaIehQ79h7dq1REVFcfLkSY4cOcLUqVOpXbs2gwcPpk6dOnTo0IHx48enkbGNiYkhODg4Q4nftWvXcuDAAS655BL+97//cc899wBw6tSpNFME54PN0RdNBNfjDveuy1U11aGf8ouX4vecQtY+/ASws40Nw7igiI6OZufOncTFxfH2229zzTXXMGvWLG644QaWLl0KwPLly2nYsGGm+ezfv9+32O7EiRN8/vnnNG7cmO7du/P+++8TFxdHXFwcZcuWZevWrTliu/XoiwZHgXJ+z58AD4rIUlVNFJGGwK6cKEhVD4nIYRFpp6pfAn1yIl/DMIzCyJNPPkmfPn14/vnnCQ4OZurUqQD873//o0WLFhw5coRixYoxYcIENm3axJ49e+jXrx/JycmkpKRw6623+rbq5Rbm6IsGG4AkEVkPTAcm4lbirxO3nHM/cEMOltcfeF1EjuM+KgzDMC4YIiMjfUPxFStWZNGiMxcS/ulPf2Lnzp1nhIeGhvLdd9+dtYyEhITztjMVc/SFGG/FPaqaCHRK9/qf3uVPjHelpo/0u0/zLkBZI/3u1+IW9aUyMn18wzAMo2Bgc/SGcYFz9913c8kll9Cs2R+aRyNHjqRGjRqEh4cTHh7ORx99BMDq1at9YWFhYcybN8+Xpk6dOjRv3pzw8HBatGjhC4+NjaVNmza+8NWrV+dd5QzDMEdvpEVEnhKR2HTXU/ltl5F7REVF8fHHH58R/sQTTxAbG0tsbCzdunUDoFmzZqxZs4bY2Fg+/vhj7r//fpKS/tgWtWzZMmJjY1mzZo0vbPDgwYwYMYLY2FieeeYZBg8enPuVMgzDhw3dF3JEZDpOgvY9EYnB7adfk3mqjFHVZ0XkAAHkbo2iSfv27YmLi8tS3LJly/ruT5486VP0ygwR8cmFHj58mOrVq5+TnYZhnBvm6I00iEiQqr6c0/maMp6joCmAxY3unuG7KVOm8Oabb9KiRQvGjx/PxRdfDMCqVau4++672b59OzNnziQoyP0ZERG6dOmCiHD//ffzt7/9DXDCINdeey0DBw4kJSWFr7/+mm3btuV+5QzDAEBUbUt0QUNELgLeBWoCxYF/AVuB54BgIB6IUtU92enRi0gC8ApOGOcgcLuq7vfSfQ1cBSzEbdVLlbutD7wMVAWSgVtU9RcRGQTcipPYnaeqZxzBlE4ZL2L4hNfOu20KO5eWgb0n8tuKP2heowLgtgINHTqUN954A4Dff/+dChUqICK8/vrrHDhwgCFDhqRJu337dkaPHs3EiRMpWbIk8fHxVKlShYMHDzJw4EAee+wxwsLCmDRpEmFhYXTo0IFly5bx4YcfMmrUqBw9nauwkpCQYO2AtUMqgdqhY8eOa1W1RQZJsoaq2lXALuBm4DW/5wo4R1zVe74NeN27nw709u5jgBaZ5KtAH+9+ODDFL92LfvFG4j4YAFYBN3r3pYGyOOW9V3HiOcWAD4H2mdWpYcOGaqguW7Ysv00IyLZt2zQkJCTb7yIjI/Xbb789I3zEiBE6duxYVVUtX768pqSkqKpqSkqKlitXrsC2Q15j7eCwdnAEagdgjZ6nT7HFeAWTjcBfROQ/InI1UAtoBnzmHVzzNK63n11SgHe8+1lAO79376SPLCLlgBqqOg9AVU+q6nGco+8CfAesAxrjJHaNIsKePXt89/PmzfOtyN+2bZtv8d327dvZsmULderU4dixY76DPo4dO8ann37qS1O9enWWL3eKyUuXLj3rgR+GYeQsNkdfAFHVn7wT4roB0cBnwA+q2jani/K7PxbgfUYrrQSIVtVXctgeIx+44447iImJIT4+npo1azJq1ChiYmKIjY1FRKhTpw6vvOL+qb/88ktGjx5NiRIlKFasGC+++CJVqlTh119/5cYbbwQgKSmJO++8k+uuuw6A1157jccff5ykpCRKly7Nq6++mub0L8Mwchdz9AUQEakO/K6qs7x59b8BVUWkraquFJESQENV/SGbWRcDegNv486vz/SIWVU9IiI7ReQGVZ3vnYRXHKeG9y8ReUtVE0SkBpCoqvuyaY9RAJg9e/YZYakHa6Tnrrvu4q677jojvG7duqxfvz5gmnbt2rF27do0YTl1KpdhGGfHHH3BpDkwVkRSgETgQSAJmOSdHhcETACy6+iPASEishY4jJvrPxt3Aa+IyDOeLbeo6qci0gRY6W2vSgD+CpijNwzDKGDYHH0BRFU/UdVQdSfPtVTVNaoaq6rtVTVMVUNU9TUvbpSqvufdR+pZ9tCr6jBVjVDVa1R1f6B0qjpSVcd59z97cUO9dL964RNVtbl3tVXVX3KrPYzcIzuqeJ999hkRERE0b96ciIgI34ldR48e9cUNDw+nSpUqDBgwAHBHbd52223Ur1+f1q1bZ3m/vmEYOYc5+gKIiIwUkYE5mF9jbxFfGRGpl1P5GoWf7KjiValShQ8++ICNGzcyY8YM3xB+uXLlfHFjY2OpXbs2N910EwDTpk3j4osvZuvWrTzxxBNnbNEzDCP3MUdfBBGRVf4StsBSYKWqFs+tnreIFM+NfI3cpX379lSqVClLca+44gqfql1ISAgnT57k1KlTaeL8/PPP7Nu3j6uvvhqABQsW0K9fPwB69+7NkiVLUrdwGoaRR9gcfQHB05PvC+zAHSu7VkTuwy3EK4kTzLkLtxhuA24xXqKIlPeeGwAhOHGbMsAvwN1AW+B1oKeINMYtwItX1Yleuc8Ce1V1UkYiOCIyH7fFrzQwUVVf9cITcCI+1wL/IJPFfaaM5yhIynjnooqXyty5c7niiisoVapUmvDZs2dz2223+aRxd+3aRa1atQAICgqiQoUKHDhwIIdrYhhGZpgyXgHA20o3HWiN+/hah3PYb6jqAS/Ov3EOebKIvAEs8FbC/w1opKr/EJENwKOqutxbPFdeVQeIyEj+ULqrA7yvqn8WkWLAz0ArIAK3Iv9+3Pa5hcAYVV0hIpVU9XcRKQN8C3RQ1QMiosBtqvpuBvUyZbx0FCRlvHNVxdu2bRtPP/00Y8aMoUaNGmnyjIqKYujQoTRq1Mj3PHbsWKpWrQpAnz59ePHFFylevLgpoWGKcKlYOzhMGa8IX8AA4Bm/5+eAgUAH4AucgM424GXv/VU4Rw+wEiemUwH4zS+PesA6734kntKd9/wZcAVwHfCeFzYOiANivWsrcI9f+vXedRho44UnAcWzUkdTxnMURAWw7Kji7dixQxs0aKBffvnlGXFjY2O1QYMGacK6dOmiX3/9taqqJiYmauXKlTUlJaVAtkN+YO3gsHZwmDJe0SfQ0Mp04BFVbQ6Mwg2do6pfAXVEpAPO0X6fzbKmAlFAf9ywPvwhghPuXfVVdZqIRAJ/AdqqahhODa+0l+akqiZns2yjgJORKt6hQ4fo3r070dHRXHXVVWekmz17NnfccUeasJ49ezJjxgwA3nvvPa655posnXhnGEbOYY6+YLACuFFEyniys9d74eWAPZ5ATp90ad4EZgNvAKjqYeCgJ5kLbj5/eQblzcP15lvixG/wfu8WkWAAEakhIpfgRgoOqupxb46/zflV1ShI3HHHHbRt25YtW7ZQs2ZNpk2bxuDBg2nevDmhoaEsW7aM559/HnDz9lu3buVf//qXbyvdvn1/SCe8++67Zzj6e+65hwMHDlC/fn2ee+45Ro8enaf1MwzDFuMVCFR1nYi8gxsy344brgcYhjtUZjtu+L6cX7K3gH/jnH0q/YCXRaQs8Cuuxx6ovNMisgw4lNoj14xFcD4GHvDm/7cA35x/jY2CQnZU8Z5++mmefvrpDPP69ddfzwgrXbo0c+bMOXcDDcM4b8zRFxBU9Vng2QCvXsogSTvc/PohvzxiCdDjVtWR/s/eIrw2wC3p4k0EJgYoq2sGNtvqGcMwjAKOOfpCiIhMxjnfbueQtinuWNl5qvpzTttmGIZhFCxsjr4QoqqPeovlfjqHtJtUta6q/iM3bCvqbNmyJY3ca/ny5ZkwYYLv/bhx4xAR4uPjAXjrrbcIDQ0lNDSUK6+8kq1bt6bJLzk5mSuuuIIePXrkaT0Mw7hwsB69kW1EJAa3XS9TXf2iSKNGjYiNjQWck65Ro4bveNYdO3bw2Wefcdlll/niX3755SxfvpyLL76YxYsX8/e//517773X937ixIk0adKEI0eO5G1FDMO4YLAevWGcI0uWLKFevXrUrl0bcPrwY8aMSbN97Morr/SpyrVp08bX0wfYuXMnixYtSuP4DcMwchrr0V8AiMhg3J73SSLyPBCmqteISCfcyvw3cfv0S+Gkc/urO2c+AifeEwzEA1Gquscv32K47X07VDXj5dgUDQnc9JKxb7/9tm872cKFC6lRowZhYWEZpp82bRqtWrXyPQ8YMIAxY8Zw9OjR3DHYMAwDc/QXCitwWvSTgBZAKW9vfjvctr2ngb+o6jERGQL8XUSigclAL1XdLyK34XYF3O3lGYTb4ve9t2PgDNJJ4DK8eVKuVTAviImJ8d0nJiYyd+5cevTowccff8yQIUMYO3YsMTExnDx5kq+++ooKFSr44n/33XdMnjyZ6OhoYmJiWLlyJYmJiRw9epTY2FgOHDiQJv+iTkJCwgVV34ywdnBYOzhyrR3OV1rProJ/ASVw++rLAZ/jttC19e4fw/XWU6VvNwHTcLK6R/zCNwKfevnF4ORwn8qqDUVNAnf+/PnauXNnVVXdsGGDVq1aVWvXrq21a9fW4sWLa61atXTPnj2qqrp+/XqtW7eubtmyxSdx+eSTT2qNGjW0du3aeumll2qZMmW0T58++VWdPMckTx3WDg5rB0duSeBaj/4CQN0pd3G4YfqvcafddcTp4W8DPlPVNJJmItIc+EFV22aQ7ddARxEZr6onc834Aoq/3Gvz5s3TKMTVqVOHNWvWUKVKFX777TduuukmZs6cScOGDdm9ezcA0dHRREdHA26kYNy4ccyaNSvvK2IYRpHHFuNdOKzAHZSzAqe89wCup/4NcJWI1AcQkbIi0hCngldVRNp64SVEJMQvv2nAR8AcEbmgPhiPHz/OZ599xk033XTWuM888wwHDhzgoYceIjw8nPvvvz8PLDQMw/iDC+oP9AXOF8BTwEp1c/EngS/Uzb9HAbNFJPVw8adV9ScR6Q1MEpEKuP9WJgA/pGaoqs9572aKSB9VTcnTGuUTZcuWzfRM9bi4ON/91KlTmTp1qu850PxbZGQkkZGROWihYRjGH5ijv0BQ1SW4ufrU54Z+90txB9ykTxMLtA8QHul3PyKnbTUMwzByDhu6Nww/Dh06RO/evWncuDFNmjRh5cqV/P7773Tu3JkGDRrQuXNnDh48CJyperd+/XpfPnXq1KF58+aEh4fTokWL/KqOYRiGOXrD8Ofxxx/nuuuuY/Pmzaxfv54mTZowevRoOnXqxM8//0ynTp18R62mqt5t2LCBYcOG8be//S1NXsuWLSM2NpY1ay44AUHDMAoQeeboRWSkiAzMq/IysSNORKrkZD4ikuD9VheR984374KGiISLSDe/50EiEutd34tIsohUyk8bc4IjR46wYsUK3zGtJUuWpGLFiixYsIB+/foB0K9fP+bPnw+cqXq3c+fO/DHcMAwjE2yOPgPE6ZhKdhaYqepuoHfuWZVvhOOEdj4CUNWxwFgAEbkeeEJVf88sg4KujBc3uju//vorVatWpX///qxfv56IiAgmTpzI3r17qVatGgDVqlVLs5UulWnTptG16x+n+YoIXbp0QUS4//77z+jtG4Zh5BW56uhF5CmgL7AD2A+sFZF6wAtAVeA4cJ+qbhaR6cAJoDFQG7fnux9O2GWVqkZ5eb6EWzhWBnce+wgvPA6YAVyPW3R2i5dvZWC2V95q4A8h8jPtrQMsBpZ55d4gIlcC//TSLVLVIWdJ/6GqNvNWsvcEyuL2q89T1cFevHuAIcBu4GfglKo+kkGeWW2XLgSWsR3utUkZ3N73+1VVvYNpVuH201cE7lHVLwKUXxJ4BigjIu2AaFV9xy/KHbj2DWR7oVHGi4mJYcuWLaxdu5aoqCiioqKYPHkyDz74IElJSWlWy6d/TlW9mzRpki987NixVKlShYMHDzJw4EBOnDhBWFiYKYB5WDs4rB0c1g6OQqeMB0Tg1NTKAuWBrbh93EuABl6c1sBS73468DbOofbCqbI1x00vrAXCvXiVvN/iOIW2UO85DnjUu38ImOrdTwKGe/fdAQWqZGBzHSAFaOM9Vwd+w30kBAFLgRv8yqvi3Sf4pf/eu4/CqdFVAEoD24FaXp5xQCXcB8kXwJRM2vGs7QJUwe2Pv8hLM8SvzpX88poJXK9/qNuN9+67AZ9nYkNUIBu9f9vf/cvI6CoMynh79uzR2rVr+55XrFih3bp104YNG+ru3btVVXX37t3qXxd/1buMGDFihI4dO1ZVTQEsFWsHh7WDw9rBkVvKeLk5R381rhd7XFWPAAtxDu9KnMhKLPAKUM0vzQdexTYCe1V1o7qh8x9wThTgVhFZB3wHhABN/dK/7/2u9YvfHpgFoKqLgINnsXu7qn7j3bcEYlR1v6om4bTdz9hulglLVPWwOuW4TbgeeStguar+rqqJwJws5HO2dmmDa4evvHbt55UFTr1ulYhsBK7BtVkqgdorO1wPfKVnGbYvLPzpT3+iVq1abNmyBXCn0zVt2pSePXsyY8YMAGbMmEGvXr0AzlC9S+XYsWO+g2qOHTvGp59+SrNmzfK4NoZhGI7cnqPXdM/FgEOqGp5B/FPeb4rffepzkIhcjhsVaKmqB71h7dIB0ieTtm7p7ciMY373GQ7zZxH/OqTadC55ZtouXt6BZGxLAy8CLVR1h4iMJGvtlVVuJ4Nh+8LK5MmT6dOnD6dPn6Zu3bq88cYbpKSkcOuttzJt2jQuu+wy5sxx32b+qncAQUFBrFmzhr179/rOqE9KSuLOO+/kuuuuy7c6GYZxYZObjn4FMF1ERnvlXI/rwW8TkVtUdY634C1UVddnlpEf5XGO+LCIXAp0xQ1Bn82OPsC/RaQrcHE26rAKmOitrj+Im4+enI30gVgNPC8iFwNHgZtxPfXz4RvgBRGpr6pbRaQsUBNIXTUWLyLBuIWC57Ir4CjuQBwfniJeB+Cv5252wSM8PDzgdrglS5acEZZe9S6VunXrptlTbxiGkZ/k2tC9qq4D3sHpqc/FzUWDc7r3iMh63NBzr2zkuR43ZP8D8DrwVRaSjQLae8P9XXBz7lktbw8wFLc4bz2wTlUXZDV9BnnuAv4P9xHxOW5I//B55rkfN48+W0Q24Bx/Y1U9BLyG+5CYD3x7jkUsA5p62+lu88JuxJ1mdyyTdIZhGEZ+c76T/HZl/wKCvd8g4APgxvy2Kbev/FyMl5SUpOHh4dq9e3dVVb3zzju1YcOGGhISov3799fTp0/74i5btkzDwsK0adOm2r59e1/44sWLtWHDhlqvXj2Njo4+Z1ts0ZHD2sFh7eCwdnAUxsV4RsaM9BbNfY87JnZ+PttTpJk4cSJNmjTxPffp04fNmzezceNGTpw44Rt+P3ToEA899BALFy7khx9+8M3FJycn8/DDD7N48WI2bdrE7Nmz2bRpU77UxTAMI7tckI5eRCr7Kbv5X5XzonxVHaiq4araWFUfU1UVkacC2PNUVvITkQHevPx5ISLXBrBhnvfuGRH5S4A0kSLy4fmWnVvs3LmTRYsWce+99/rCunXrhoggIrRq1cqnaPff//6Xm266icsuuwyASy65BIDVq1dTv3596tatS8mSJbn99ttZsOC8ZnAMwzDyjAtSGU9VD+D2nxcYVPVZ4NlzTD4At4XweFYTiEhxVU1OZ8MnwCcZ2Df8HG0D8l4ZL250dwAGDBjAmAXZ84EAACAASURBVDFjfNvd/ElMTGTmzJlMnDgRgJ9++onExEQiIyM5evQojz/+OH379mXXrl3UqlXLl65mzZqsWrUqbypiGIZxnlyQjr4wIyIXAe/iVtUXx+3Drw4sE5F4Ve0oIncQQM3P0+R/DrgW+IeInPCeg4F4IErdAsRA5U7Hqf69JyLX4c6mjwfWZWJrvinjxcTEsHLlShITEzl69CixsbEcOHAgjerUuHHjqFu3LsnJycTExLB9+3a2bNnC+PHjOX36NA8//DAiwi+//MKePXt8aX/88Ud27959TgpWpgDmsHZwWDs4rB0cudUO5ugLH9cBu1W1O/i2ufUHOqpqvIhUB/6DUyY8CHwqIjeo6nzgIpxy33ARKQEsB3qp6n5vNf2zwN2ZFe7tzX8NJ76zFbezIiCq+irwKsBldevr+I15959bXJ9IPvnkE5+k7cmTJzly5AhTp05l1qxZjBo1iqCgIN59912KFXMzWN988w1hYWE+zfqFCxdSunRprr32WlauXElkZCQAK1eupGXLlr7n7BATE3NO6Yoa1g4OaweHtYMjt9rBHH3hYyMwTkT+g+thf+HkCHz41PwARCRVzW8+ThhnrhevEdAM+MxLXxwI2JtPR2Ngm6r+7OU/C6/XnhllShRnizecnldER0cTHR0NuP+Bxo0bx6xZs5g6dSqffPIJS5Ys8Tl5gF69evHII4+QlJTE6dOnWbVqFU888QSNGzfm559/Ztu2bdSoUYO3336b//73v3laF8MwjHPFHH0hQ1V/EpEInD59tIh8mi5KZsp7J/3m5QX4QVXbnosZ55CmwPDAAw9Qu3Zt2rZ1Vb/pppsYPnw4TZo04brrriM0NJRixYpx7733+qRrp0yZwrXXXktycjJ33303ISEhmRVhGIZRYDBHX8jwhuZ/V9VZ3px7FH8o18WTdTW/LUBVEWmrqiu9ofyGqvrDWUzYDFwuIvVU9Rcv/wJPZGSkb0gsKSnjtQKDBg1i0KBBZ4R369aNbt265ZZ5hmEYuYY5+sJHc2CsiKQAicCDuCNrF4vIHm8xXqqanwAfaQA1P1U9LSK9gUnePH8QboFdpo5eVU96i+wWiUg88CVuCsAwDMMogJijL2RksAVuDX69dlX9L3DGJLKqBqd7jiWLp/Gpd+69d/8xbq7eMAzDKOBckII5RtHl5MmTtGrVirCwMEJCQhgxYgQAV199NeHh4YSHh1O9enVuuOEGAA4ePMiNN95IaGgorVq14vvvvwdgy5Ytvvjh4eGUL1+eCRMm5Fu9DMMwzhXr0RtpEJEXgKvSBU9U1Tfyw57sUqpUKZYuXUpwcDCJiYm0a9eOrl278sUXX/ji3Hzzzb4z5f/v//6P8PBw5s2bx+bNm3n44YdZsmQJjRo1IjY2FnASuDVq1PAdPWsYhlGYsB59AUFEpntz5jmRV5SITDmXtKr6sCfP67uAeSLykF/+HdPJ5J4UkRtywvbzRUQIDnYzFImJiSQmJuK//fDo0aMsXbrU16PftGkTnTp1AqBx48bExcWxd+/eNHkuWbKEevXqUbt27TyqhWEYRs5hPXojK1QEHgJeBFDVZXgSwiJSCSeck36bXxryQgI3VfY2OTmZiIgItm7dysMPP0zr1q19cebNm0enTp0oX748AGFhYbz//vu0a9eO1atXs337dnbu3Mmll17qS/P2229zxx2FYnOBYRjGGZijz0UCyNX+CydUcz1QBvgauN87itA/XQQBpGlF5DHgASAJ2KSqt2fBhuuBp4GSwAGgj6ruFZGquAV7lXHn1F8HRKhqfIBsRgP1vBP3PlNV//1nvYHFqnqGzn5eS+D6S0dOmDCBhIQEhg0bRuPGjbn88ssBeOGFF+jWrZsv7lVXXcWUKVN8h9bUr1+f7777zqeNn5iYyNy5c+nRo0eOSFOa1KfD2sFh7eCwdnDkWjuc7zm3dmV8ATcDr/k9VwAq+T3PBK737qfjnGYJ3AdAVS/8NuB17343UMq7r5hJuVHAFO/+YkC8+3uB8d79FGCod38dTgSnSgb51cFJ5wZ6txTocba2yK/z6EeOHKljx45VVdX4+HitVKmSnjhxImDclJQUrV27th4+fNgXNn/+fO3cuXOO2WPnbjusHRzWDg5rB4edR1842Qj8RUT+IyJXq+phoKOIrBKRjTi9+PQSa/7StLG43nhN790G4C0R+SuuV58VagKfeOUN8iuvHfA2+LbLHcxu5USkGm5ff8AT7/KD/fv3c+jQIQBOnDjB559/TuPGbifgnDlz6NGjB6VLl/bFP3ToEKdPnwZg6tSptG/f3jesDzB79mwbtjcMo1BjQ/e5iAaWq30YaKGqO0RkJFA6XbLMpGm74/a99wSGiUiIqp7N4U8GnlPVhSISCYz0K+d8uRWYp6qJOZBXjrBnzx769etHcnIyKSkp3HrrrfTo0QNwc+1PPvlkmvg//vgjffv2pXjx4jRt2pRp06b53h0/fpzPPvuMV155JU/rYBiGkZOYo89FMpCrBYgXkWDcUP176ZIFlKYFfgRqqeoyEfkSuBM3h3/oLGZUAHZ59/38wr/EOer/iEgX3BB/RqRK7KbnDmDoWcrPU0JDQ/nuu+8Cvgs099W2bVt+/vnngPHLli3LgQMHctI8wzCMPMccfe4SSK72BtyQfhxuEVwaNGNp2p+AWV6YAM+r6tmcPLge/BwR2QV8A1zuhY8CZnvH0y7HnVx3NFAGqnpARL4Ske9xC+8GiUgdoJaX1jAMwyigmKPPRTRjudqnA8SN8rvPSJq2XRbLnY5b3Ic6nfsztO6Bw8C1qpokIm1x59mfyiTPO9M9xwE1smJPXnDy5Enat2/PqVOnSEpKonfv3owaNYqoqCiWL19OhQoVAJg+fTrh4eEsWLCAYcOGUaxYMYKCgpgwYQLt2rnm/e2337j33nvZsWMHIsJHH31EnTp18rF2hmEY5445+guXy4B3RaQYcBq4L5/tOS8yUsQDGDt2LL17p9Ui6tSpEz179kRE2LBhA7feeiubN28GoG/fvjz11FN07tyZhISENGfWG4ZhFDYK7F8wERkpIgMLgB1x3pGvOZaPN1+PiFQXkfRz9NnJs386hbpYT8I2fbxwEUlzxqqq/qyqV6hqGFAV2CYilQPkt1FEBvnlVSBV8c6miJee4OBg3/tjx4757jdt2kRSUhKdO3f2xStbtmwuW28YhpF7WI8+hxDnKURVU7KaRlV34xbknRPq9OezokEfDrQAPjpLfge8uD68ufgPgbFenGyr4kHuK+PFje4eUBHvpZde4qmnnuKZZ56hU6dOjB49mlKlSgFOJW/o0KHs27ePRYucbT/99BMVK1bkpptuYtu2bfzlL39h9OjRFC9ePNdsNwzDyE1ShVQKBCLyFNAX2AHsB9YC84AXcL3O48B9qrpZRKYDJ3DHpdYG+uNWlbcFVqXOeYvIS0BLnBLde6o6wguPA2bgVOpKALd4+VYGZnvlrSYTxTjPCS7Gnf3eFrfQ7krgn7gFc4tUdYhfeS1UNV5EElQ1ONWJqmozEYnCbZsrC9TDbVsb7KW9BxiCE8z5GTilqo9k0Ia3ACOAZNw8/F9wzrgMbvV9NPB5Nur4NtALtxsgjSqep3zXQVX7ZGCLvzJexPAJrwWKliM0r1HBd5+qiPfYY49Rvnx5KlWqRGJiIuPHj6d69er069cvTdr169fz5ptvMn78eJYvX87YsWN59dVXufTSSxk1ahStW7eme/fuOWJnQkKCb+ThQsbawWHt4LB2cARqh44dO65V1RbnlfH5Ku7k1AVE4FajlwXK45zTQGAJ0MCL0xpYqn8oyb2Nc6i9gCO4Ve7FcB8I4V68St5vcSAGCPWe44BHvfuHgKne/SRguHffnbMrxqUAbbzn6sBvOAcahFONu8GvvCrefYJf+u/1DzW7X3Hb4UoD23Gr2qt7aSvhPki+wFO9y8CmjUAN9VPPw08p7xzreF6qeJoPynj+inipLFu2TLt37x4wfp06dXT//v26cuVK7dChgy/8zTff1IceeijH7DIFMIe1g8PawWHt4LgQlPGuxvVij6vqEWAhzuFdidseFgu8AlTzS/OB1xAbgb2qulHd0PkPOAcFcKuIrAO+w6nCNfVL/773u9YvfntgFoCqLuLsinHbVfUb774lEKOq+9UJ2bxF4NXzGbFEVQ+r6klgE26kohWwXFV/VydMM+cseXwFTBeR+3AfN4HIbh3PoKCp4mWkiLdnzx7AfdDOnz+fZs2aAbB169bUjxXWrVvH6dOnqVy5Mi1btuTgwYPs378fgKVLl9K0adMAJRqGYRQOCtocffp5hGLAIXVHpQYidTtYit996nOQiFyOGxVoqaoHveH+0gHSJ5O2LbIzn3HM7/581eb865BqU7byVNUHRKQ1rqceKyIZtd35ztkUKFW8jBTxrrnmGvbv34+qEh4ezssvvwzA3LlzefPNNylRogRlypThnXfeQUQoXrw448aNo1OnTqgqERER3Hdfod6QYBjGBU5BcvQrcD3R0Ti7rsf14LeJyC2qOsdb8BaqquuzmGd5nCM+LCKXAl1xw/dns6MP8G8R6UrminHpWQVM9FbXH8Qpx03ORvpArAaeF5GLcYI2N+NGMAIiIvVUdRWwyju5rhZnKttlp46FQhUvI0W8pUuXBow/ZMgQhgwZEvBd586d2bBhQ47aZxiGkV8UmKF7VV0HvAPEAnNxc9HgHNI9IrIeNyTfKxt5rscN2f8AvI4b1j4bo4D23nB/F9yce1bL24NzfsuA9cA6dYI154yq7gL+D/cR8TluSP9wJknGelvivsc59PWePU297XC3kY06qluJ/5WIfC8iY8G3CNFU8QzDMAoD5zvJb1fuX0Cw9xsEfADcmN82ZffK7cV4J06c0JYtW2poaKg2bdpUhw8fnub9I488ohdddJHvOS4uTq+55hpt3ry5dujQQXfs2OF7N3jwYA0JCdGQkBB9++23c9ROW3TksHZwWDs4rB0cBWYxnohcLCKhOfq1YZyNkd5ixO+BbcD8fLanwJGqjLd+/XpiY2P5+OOP+eYbt0ZyzZo1voV6qQwcOJC+ffuyYcMGhg8fztChbhZi0aJFrFu3jtjYWFatWsXYsWM5cuRIntfHMAwjp8iSoxeRGBEp7wmkrAfeEJHncte0gkMGinGx3p77XEdVB6pquKo2VtXHVFVF5Ck/O3aJyHpPhyCzegwQkYAyb2ero4hMFZEzlp+LSJSITMmZmp47GSnjJScnM2jQIMaMGZMm/qZNm+jUqRMAHTt2ZMGCBb7wDh06EBQUxEUXXURYWBgff/xx3lbGMAwjB8lqj76Cui1vNwFvqGoETojlgkBVD3iONv2Vb2eYquqzqXbgTsbrpKrPniXZAJxOQaD8Mq2jqt6rqptythY5S3JyMuHh4VxyySV07tyZ1q1bM2XKFHr27Em1atXSxA0LC2Pu3LmAU8g7evQoBw4cICwsjMWLF3P8+HHi4+NZtmwZO3bsyI/qGIZh5AhZXXUf5O2bvhXItNdo5C4ichHwLlATt09+Dk5UZ5mIxKtqx0BqgCLyWIB4XXAL80oBvwD9VTUhg3JjgIGqukZE+uMWHe7BHZ+b4al3qeSmBG7caKdaV7x4cWJjYzl06BA33ngjK1asYM6cOQHPoR83bhyPPPII06dPp3379tSoUYOgoCC6dOnCt99+y5VXXknVqlVp27YtQUEFaXOKYRhG9siSBK4nqzoM+EpVHxSRusBYVb05tw000iIiNwPXqep93nMF3HRKC/UkbEWkkqr+LiLFccqCj6nqhnQyvFVwgkFdVfWYiAwBSqnqMxmUG4PTJNiF2wEQgVv9vwz4TgNI8uaVBK6//G0qM2bMAGDBggWULFkSgH379lGtWjXeeuutNHFPnDhB3759mTPnTC2if/3rX3Tu3Jk2bdrkiK0m9emwdnBYOzisHRxFXgLXrqxdQEPcgrz/AFd7YXH4SdgCDwDrgA24MwNuTx8P6AHE47YzxuK27U3LpNwY3ME4NwBv+oU/RiaSvKlXbq+637dvnx48eFBVVY8fP67t2rXTDz74IE0c/1X3+/fv1+TkZFVV/ec//6nDhg1TVdWkpCSNj49XVdX169drSEiIJiYm5pidtrrYYe3gsHZwWDs4cmvVfZbGJEWkIfAScKm6A1hCgZ6q+u9z/sIwzglV/UlEIoBuQLSIpDk5LgtqgL6ouENq7jgXM84hTa6SkTJeRsTExDB06FBEhPbt2/PCC+5038TERK6++moAypcvz6xZs2zo3jCMQk1W/4K9BgzCKdWhbhj4v4A5+jxGRKoDv6vqLHHn2kfxh3pdPJmrAfrH+wZ4QUTqq+pWbzV+TVX96SwmpKr/VcYdJHQLbuogX8lIGc+fhIQ/lh/07t2b3r3PPCG4dOnSbNpUoNccGoZhZIusOvqyqrraKdD6SMoFe4yz0xynfpeCW23/IO6I3MUiskfdIrtUNcBfSasG+Gq6eFHAbBEp5b1/Gre4LkNUdY+IjARW4hbjrSPjw3MMwzCMfCarjj5eROrhDdmKSG/cH3kjj1HVTzjzxLg1+Gnqq2pUBmknp4u3FLc6PyvlRvrdvwG8kVWbDcMwjPwjq/voH8YN2zcWkV24/dgP5JpVhpFNTp48SatWrQgLCyMkJIQRI0akef/oo4+mWc26fft2OnXqRGhoKJGRkezcudMXHhERQXh4OCEhIb7T7gzDMAorZ+3Ri0gx3Jasv3h7uIup6tHcN83ID0RkHm4qIBm3Yh9giDeSUGBJlcANDg4mMTGRdu3a0bVrV9q0aZOpBG6/fv1YunQpQ4cOZebMmVSrVo2vv/6aUqVKkZCQQLNmzejZsyfVq1fPp5oZhmGcH2ft0atqCvCId3/MnHzRRlVvBF4Gntc/1PEKtJOHnJPALVmyJKVKuSULp06dIiUlJQ9rYRiGkfNkdY7+MxEZiDtG9lhqoKr+nitWGXmOp5PfF9iB68mvFZH7cII3JYGtwF24hXcbgIaqmigi5b3nBqqamFH+eaGMl5ycTEREBFu3buXhhx+mdevWTJw4MVMJ3McffzyNBG7lypXZsWMH3bt3Z+vWrYwdO9Z684ZhFGqyqoy3LUCwqmrdnDfJyGu8ffnTgda4j791uF79G+pp3YvIv4G9qjpZRN4AFqjqfE/9rpGq/iNAvvmijJeQkMCwYcOIiopi6tSpTJgwgeLFi9O1a1cWL14MQHx8PJMmTWLPnj2EhoayYsUK3njjjTTz+PHx8QwbNoxnn32WSpUq5YitpgDmsHZwWDs4rB0cuaWMlyVHbxRtRGQAUElVh3vPzwG7gW9xWgkVgWDgE1V9QESuAgarai8RWQncp6rfZ1ZGo0aNdMuWLblaD39GjRoFwEsvvUTp0k4v6LfffqNu3bps3bo1TdyEhAQaN27sW5DnT//+/enevXvAPffnQkxMDJGRkTmSV2HG2sFh7eCwdnAEagcROW9Hn1VlvL6BwlX1zfMp3ChQBPrimw7coKrrvT33kQCq+pWI1BGRDkDxszn5vGD//v2UKFGCihUrcuLECT7//HOGDBnC//73P1+c4OBgn5OPj4+nUqVKFCtWjOjoaO6++24Adu7cSeXKlSlTpgwHDx7kq6++4u9//3u+1MkwDCMnyOr2upZ+19XASKBnLtlk5D0rgBtFpIyIlAOu98LLAXtEpATQJ12aN4HZFJD99Hv27KFjx46EhobSsmVLOnfufFYJ3EaNGtGwYUP27t3LU0+5Qxl//PFHWrduTVhYGB06dGDgwIE0b948r6phGIaR42SpR6+qj/o/eyemzcwVi4w8R1XXicg7uMNttgNfeK+G4SRvtwMbcY4/lbdww/qz89DUDMkpCdzOnTuzYcOGHLfPMAwjvzjX0zqOAw1y0hAjf1HVZ4FnA7x6KYMk7XBn3R/K4L1hGIZRAMjS0L2IfCAiC73rQ2ALsDB3TTMKKiIyGRgN/Cs/7chIDW/btm20bt2aBg0acNttt3H69GkApk+fTtWqVQkPDyc8PJypU6emye/IkSPUqFGDRx55JM/rYhiGkVtktUc/zu8+CdiuqmcuUTYuCNJP5eQXGanhPffcczzxxBPcfvvtPPDAA0ybNo0HH3wQgNtuu40pU6YEzG/YsGF06NAhL6tgGIaR62R1MV43VV3uXV+p6k4R+U+uWmbkGSISKSJXniXOA4F2X3ir7/Nl1X1GanhLly71zb/369eP+fPnnzWvtWvXsnfvXrp06ZKrNhuGYeQ1We3RdwaGpAvrGiDMKJxEAgnA1xlFUNXzOt0lp5XxMlLDq1evHhUrViQoyP2nXbNmTXbt2uVLN3fuXFasWEHDhg15/vnnqVWrFikpKfzjH/9g5syZLFmyJMdsNAzDKAhk6uhF5EHgIaCuiPgvRS5H2nPOjQKI1wMfiNsjvwF4F3fmfEngAG7LXBncSYTJIvJX4FFV/SJAXiOBBFUd5ynpvY5blPllJuX7K+MxvHlSjtUtJibGdz9hwgSfGl6NGjU4ceKE7/2+ffs4fvw4MTExXHzxxcyYMYOSJUuycOFCevXqxXPPPce8efNo1KgRv/zyC5s3b2bXrl1p8s9JEhISci3vwoS1g8PawWHt4Mi1dlDVDC+gAlAHt4Wqtt9VKbN0duX/BYTgFk1W8Z4rARfzhxrivcB4734kMPAs+fni4D4aOnj3Y4Hvz2ZPw4YNNbcZOXKkjhkzRitXrqyJiYmqqvr1119rly5dzoiblJSk5cuXV1XVO++8U2vVqqW1a9fWypUra7ly5XTIkCG5YuOyZctyJd/ChrWDw9rBYe3gCNQOwBo9T3+Q6Ry9qh5W1ThVvUNVtwMncL3DYBG57Pw/M4xc5Brc9rd48B1AVBP4REQ2AoNwHwPZwtNQqKiqy72gfNNT2L9/v+/42VQ1vCZNmtCxY0fee+89AGbMmEGvXr0AJ6qTysKFC2nSpAkAb731Fr/99htxcXGMGzeOvn37Mnr06DyujWEYRu6QVQnc64HngOrAPlyv/kfOwVEYeYZwpqztZOA5VV0oIpG4XnpO5Jsv7Nmzh379+pGcnExKSgq33norPXr0oGnTptx+++08/fTTXHHFFdxzzz0ATJo0iYULFxIUFESlSpWYPn16/lbAMAwjD8jqYrx/A22Az1X1ChHpCNyRe2YZOcASYJ6IPK+qB0SkEm4qJnVlWj+/uEeB8lnJVFUPichhEWmnql9ypjRunpGRGl7dunVZvXr1GeHR0dFER0dnmmdUVBRRUVE5ZaJhGEa+k9XtdYnqjistJiLFVHUZEJ6Ldhnniar+gFO6Wy4i63EjMiOBOSLyBRDvF/0DnNZ9rIhcnYXs+wMveCfXnchZyw3DMIycJKuO/pCIBOM00N8SkYk44RyjAKOqM1S1maqGqWqUqi5Q1bqqerWqDlLVSC/eT6oaqqrhGmDFvRdnpKqO8+7Xenm29cKb5WG1ANixYwcdO3akSZMmhISEMHHiRABiY2Np06YN4eHhtGjR4oye/bfffkvx4sV9c/gAQ4YMoVmzZjRr1ox33nknT+thGIaR22R16L4Xruc2ADdUWwF4JreMMoyzERQUxPjx4/nzn//M0aNHiYiIoHPnzgwePJgRI0bQtWtXPvroIwYPHuzbrpKcnMyQIUO49tprffksWrSIdevWERsby6lTp+jQoQNdu3alfPkszWQYhmEUeLLUo1fVY0AtIFJVZwBTgdPZKUhERorIwOybmLOISJyIVMnJfEQkwfutLiLvZZ6yYCMiT3lD+P7XZBHpli5epPfuBxFZnlF+uUW1atX485//DEC5cuVo0qQJu3btQkQ4cuQIAIcPH6Z69eq+NJMnT+bmm2/mkksu8YVt2rSJDh06EBQUxEUXXURYWBgff/xx3lbGMAwjF8nqoTb3Ae8Br3hBNYCz64oWYsSR1akNAFR1t6qeefZpIUJVn/WG8H0XsBbwOXoRqQi8CPRU1RDglnwyF4C4uDi+++47WrduzYQJExg0aBC1atVi4MCBvsV3u3btYt68eTzwwANp0oaFhbF48WKOHz9OfHw8y5YtY8eOHflRDcMwjFwhq0P3DwOtcGeTo6o/i8glmSdxvUOgL7AD2A+sFZF6wAtAVZyy2n2qullEpuOmBxrjtu/1x60MbwusUtUoL8+XgJY4Rbf3VHWEFx4HzACuB0oAt3j5VsYJ/lQFVuO2h2Vkbx1gMbDMK/cGTwP+n166Raqaoeyvl/5DVW0mIlFAT6AsUA+Yp6qDvXj34OSDdwM/A6dUNeCRadloly7AKKAU8AvQX1UTRGS41yZlcBK396uqikgM7t+zI1ARuCfQ/LyIlMRN05QRkXZANFAZeF9VfwNQ1X0ZtUkqOSmBmyp/C05J6uabb2bChAmUL1+ep59+mueff56bb76Zd999l3vuuYfPP/+cAQMG8J///IfixYunyatLly58++23XHnllVStWpW2bdv65HMNwzCKAqkqaZlHElmlqq1F5Dtve10QsE5VQzNJEwFMB1rjPijWAS/jNPIf8D4WWgPRqnqN59BK47bt9cQJsVwF/AB8i3NEsSJSSVV/F5HiuC1kj6nqBs/Rj1fVySLyEPBnVb1XRCYB8ar6jIh0Bz4EqqYKyaSzuQ7wK3Clqn4jItWBb4AI4CDwKTBJVed75bVQ1XgRSVDV4ACOfjhwBXAKp1LXDkjGOdw/47a1LQXWn8XRZ9ouwE7gfaCrqh4TkSFAKa/OlTyxHERkJvCuqn7gOfq1qvoPb1j+/9s79zidy/z/P9+RERZp6IsJkfMMI2m1hA4O5Vw6WN8y1Jat9uv7K/oqil1tTvXtQFtbm1SKklqp/SrrELUR2mFQI2tIWFQGY8rx/fvjuu7bPeO+53zPjJn38/G4H/fnc30+1/V5X2/uuT7X6fW+X1WvjWBDkq/rff78adzLVGucHPIzqvpamHyhErjtAOPCQAAAIABJREFUH336pXDF55uE+jUAOHHiBA899BAdOnTg5ptvBqBPnz4sXLgQEUFV6dOnDx9++CGDBw8OKPxx8OBBKleuzAMPPEDnzp2zlD1x4kS6d+9Ox44di8TW7GRkZAQD8ZRnzA8O84PD/OAI54errrpqnapeVphy89p1+UREHsb16rrj9O8X5pLnSlwvNhNARN7HNVi/wm3xCtwXE5Jnoe9tpgB7VTXF592Ek+JNBm72DUhFoC7QCifJCq6xAzfUfIM/7hI4VtUPReRALnbvUNVV/rgDsFxV93s73vDl5XXaYomqHvR5N+N65LHAJyGN7zygWS7l5OaXOJwfPvN+rQR87vNeJSIP4kYWauFeEAL/dqH+apTHOoHzfXvgGtxIweciskpVt4TepKovAi8CNG/eXH83pH8+HpEzqsrQoUPp1KkTTz/9dDD9oosuQkTo1q0bS5YsoUWLFnTr1i2LKl5SUhJ9+vRh0KBBnDx5kvT0dC644AI2bNjA3r17GTVqVNR69cuXL6dbt25RKftswvzgMD84zA+OaPkhr3/NxuB6jinA3cDfcAvyciP7cME5QLqf9w3HUf99KuQ4cF5RRC7GBWnpoKoHQnq72fOfJGvd8qPkdiTkOOIwfx4JrUPApoKUmaNffNmLVTWLiJGIVMbNpV+mqjt9YJq8+Cs3vsONkhwBjojICqAtsCXnbEXHZ599xuuvv05CQgKJie6/0+OPP85LL73EyJEjOXHiBJUrV+bFF1/MsZzjx49z5ZVOOqB69erMnj3bhu4NwyhT5Ba9roGqfquqp4CX/CevrABmichk/5y+uMV8aSJyk6rOE9f9bKOq6/NYZnVcQ3xQRC7ETQMsz4MdQ4DHROQ6XGCXvLIaeMavrj+AGz6fno/84fgCeEpEzscN3d+Ie4EqDKtwAjaXqOpWEamC6+UH5s6/9zoIg3CLKvPLYdwQfYAFwAw/hVMJNz3zVIGtLwCdO3cODsVnZ926dTnmDZW+rVy5Mps3by5K0wzDMEoVua0qDw5Ri8j8/BSsql8Cb+GG2+fjxHbANbp3eLW2Tbg9+nktcz3wT59vJnkLlft7oIuIfAn0AL7Nx/P2AA/hFuetx61LWJDX/BHK3AU8jnuJ+DuwGThYyDL3A0nAHHHhhFcBLVQ1HfdyloL7t1xTwEcsA1r57XS3qOpXwCLclMkXwF9UdWNh6mAYhmFEhxwX4wUW32U/NgqHiFTzK+IrAu8BM1X1vZK2K5o0b95cU1NTS9qMEsfmIh3mB4f5wWF+cITzg4gUejFebj16jXBsFI4JIpIMbATSKOOaBEVJJOlbcII4zZs3p3Xr1jz44IMAfPHFFyQmJpKYmEjbtm15773T71PDhw+nTp06xMcXu4KvYRhGsZHbqqO2InIIt4DsPH+MP1dVPSt1Qv3e+iVhLl3jg/dEFVU9QyFQRJbg9srvD0mep6p/LMgzRKQFMBf3gjZIVf+Vhzw9gSnZktNUdWCYe5cDo1R1bUHsKyiRpG/37t3LggUL2LBhAzExMezb55YnxMfHs3btWipWrMiePXto27Ytffv2pWLFiiQlJXHfffdx++23F2cVDMMwipUcG3pVrZDT9bMV35iXtuh7K4H/CwSOKQIGAAsCgkJ5QVU/Aj4qoudHhbp161K3bl0gq/TtSy+9xJgxY4iJcbs1AzK3VapUCeb9+eefCdnWSZcuXdi+fXvxGW8YhlEC2D6iEiSCcuBvcCIzlYCtwG1ABdzCt2aqelxEqvvzpjjRmhdw++T/BQzHqeb9N3BSRLrg1P5+VtVnReQpoK0XKboGp6D3nzko67XHhbithgttm+QXKQbqcA7wCrBTVcdFqmtRKeOFquKFSt+OHj2alStXMnbsWCpXrswTTzxBhw4dAFi9ejXDhw9nx44dvP7667Z9zjCMcoX9xSshfAN6K045L6AcuA4nLfuSv+cxnCLgdD9U3hs3n38rMN83+q8Bv1PVT0TkD8B4Vf1vEXkByFDVJ0SkI/AA8CxwGRAjIufilPpW+u2D44BrQ5T17heRSbjthP1Vdb+I3IKLcT/cV6Mi8AawMdwUQzZlPB5NKHxk40Akup9++omRI0dy55138uWXX3Lw4EFSUlKYPHkyX3/9Nf369ePNN98M9uCfe+45duzYwcMPP0zVqlWpVKkSAP/+9785cuRIsNxok5GRUWzPKs2YHxzmB4f5wRE1P6iqfUrgg+tx/yHk/H9xYkBdccP4KbiFei/4651wQ/HgVO/iceGCvw0powluCyDABNwcOji52m24vfB/B57B9fr/jlPU64PrrSf7z2bgZf+MQyHpKcDHvszluC2HY/NS32bNmmlRcezYMe3Ro4c++eSTwbSePXvqsmXLgueNGzfWffv2nZG3W7duumbNmuB5Wlqatm7dushsy41QG8sz5geH+cFhfnCE8wOwVgvZ3uQrOptR5ITbyTALuE9VE3BD6ZUBVPUzoJGIdAUqaD72ravqcWA7LiDOP3AvElfhXgy+wi2uXKynI9a1UtU7fPqmkPQEVe0RUvQ/cBK7oWp7UUVVueOOO2jZsiX3339/MH3AgAEsXboUgC1btnDs2DFiY2NJS0vjxAk3krBjxw5SU1Np1KhRcZlrGIZR4lhDX3KsAAaKyHki8gucciC4XvceP7Q+JFue13CR+F4BUKejf0BErvTXbwMixYZfgRsxWIFr6EcAyf6NcRXQSUQuARCRKiLSDBeIp7aIXOHTzxWR1iFlvoyTQ57nNQGiTkD6dunSpcFtc3/7298YPnw427ZtIz4+nltvvZVXX30VEeHTTz+lbdu2JCYmMnDgQP70pz8RGxsLwODBg7niiitITU0lLi6Ol19+uTiqYBiGUazYHH0JoapfikhAOXAHp5UDH8Gp5u3ADZWHSs++ATyGa+wDDAVe8LK323C99nCsBMYCn6ubh/858Ex18+9JOGW9QJChcaq6RUQGAc+KSA3c/5enccqEgXr8r7/2uogMUSeXHDVykr6dPXv2GWm33XYbt912W9j758yZEzbdMAyjLGENfQmibgFbuH3yz0fI0hl4R520baCMZOCMmKqqOiHb+RLcXH3gvFm260tx0fqyl5OMi9iXPb1byHGet/AZhmEYxYsN3Z8liMh0YDIwsaRtKQkiKeKNHj2aFi1a0KZNGwYOHEh6unsHOn78OEOHDiUhIYGWLVsyadIkAFJTU4ND/omJiVSvXj1LmFvDMIyyhjX0Zwmq+jtVvUSzxXwvLwQU8b766itWrVrFc889x+bNm+nevTsbN25kw4YNNGvWLNigz5s3j6NHj5KSksK6dev485//zPbt22nevDnJyckkJyezbt06qlSpwsCBZwj/GYZhlBlKbUMvIhNE5Ayp2BKwY7vfZ15k5YhIhv+uJyIFCRub32cnisj1ebEtzLWaInJPtrQGIvKxiHwlIptFpFHRWnwmdevW5dJLLwWyKuL16NEjKIDTsWNHvvvuu4CNHDlyhBMnTvDTTz9RqVIlqlfPqti8ZMkSmjRpQsOGDaNtvmEYRolhc/RFhDhlFsnPYjRV3Y2LER9tEnFCOX8rQN6awD3An0LSXgP+qKqLfZz7XOtcGGW8UDU8yKqIF8rMmTO55ZZbABg0aBALFiygbt26ZGZm8tRTT1GrVq0s98+dO5fBgwcXyCbDMIyzhVLV0EeQhG0CPAfUBjKB36jq1yIyC/gJFwimIW61+VCcEMxqVU3yZT6PW2R2Hm4h23ifvh14Fbet7VzgJl/uBbhV7bVxsdZPi6OfaW8jnLzsMv/cASLyK+Bhn+9DVf2fXPJ/oKrxftV7P5yUbRPgPVV90N93B/A/wG7gG+Coqt4XocybgPHASVyc+2uBP+CCEnUGJuGEcvJUR9y6gCY+2t5i3Na+iqq6GEBVM3KoX5Eo44UqRWVXxAswe/Zs0tPTqV+/PsuXLyclJYXvv/+eOXPmcPjwYUaOHEm1atWoV68e4Obw58+fT58+fYpVkcsUwBzmB4f5wWF+cJR5ZTygPW47WRWgOk7nfRQuylxTf88vgaX+eBYuOpsA/XEKbgm46Yh1QKK/r5b/roBTc2vjz7fjpGPB9Vj/4o+fBR71x71xojaxEWxuhOvNdvTn9YBvcQ1oRWApMCDkebH+OCMk/0Z/nITbHlcDJ5KzA7jIl7kdqIV7IVkJzMjBjylAfX9cM6TsGSH35LeOG0POBwAfAO8C/wSm4QR8oq6MF04RT1V11qxZ2rFjRz1y5Egw7Z577tHXXnsteD5s2DB96623gud//etftXv37oW2Kb+YApjD/OAwPzjMD47yoIx3Ja4Xm6mqh4D3cQ3er3CCLMnAn4G6IXkWekekAHtVNUXd0PkmXAMFcLOIfIlrlFrjJF8DvOu/14Xc3wWYDaCqHwIHcrF7h6qu8scdgOWqul9VT+D2vZ+xNS0HlqjqQVX9GSdD2xC4HPhEVX9Up3A3L5cyPgNm+eA4kaIP5reOoVTE/VuNwtW3Me5FIqpoBEW8RYsWMWXKFN5///0skeoaNGjA0qVLUVWOHDnCqlWraNGiRfD6nDlzbNjeMIxyQWlq6OFMSdhzgHQ9LcGaqKotQ64f9d+nQo4D5xVF5GJcg3SNqrYBPsRLymbLf5Ks0xjhFVnCcyTkOKch8LwQWoeATfkqU1VH4ALUXAQk+6mIsLcWyEL4Dvinqm7zLzN/BS4tYFl5JpIi3n333cfhw4fp3r07iYmJjBgxAoB7772XjIwM4uPj6dChA8OGDaNNmzYAZGZmsnjxYm644YZom20YhlHilKY5+hW4nuhknF19cT34NBG5SVXn+QVvbVR1fR7LrI5riA+KyIXAdbjh+9zsGAI8JiLXAefnow6rgWf8CvYDwGBc9LfC8AXwlIicDxwGbsSNYIRFRJqo6mpgtYj0xTX4h8mqsJefOmbPuwY4X0Rqq+p+4Gpgbf6rlT8iKeJdf334zQTVqlVj3rzwgx9VqlThhx9+KFL7DMMwSiulpkevql8CAUnY+ZyWhB0C3CEi63FD8v3zUeZ63JD9JmAmblg7N34PdPHD/T1wc+55fd4e4CHc4rz1uEhyC/KaP0KZu4DHcS8Rf8cN6R/MIcs0EUkRkY24Bn29t6eViCT7ULN5rqOq/gB8JiIbRWSaqp7Er50QkRTciMNLhamjYRiGET0kXC/JKF2ISDVVzfCBY94DZqrqeyVtV35o3ry5pqamlrQZJc7y5cvp1q1bSZtR4pgfHOYHh/nBEc4PIrJOVS8rTLmlpkdv5MgEvxhxIy5G/V9L2J5iJZL87bx582jdujXnnHMOa9eenj1YvHgx7du3JyEhgfbt2wfD1wJ069aN5s2bB+f59+3bV+z1MQzDKE6KbY5eRCbgtpU9UVzPjGDHduAyVf0+H3kuwG3zC6UV0FpVvxGRDFWtJiL1gGdVtUhFcFT1DIVArzlwU7bkeeoC5eSbCHUEuAa/zU9V/+bvHYLb1w+QAfw2H+sm8k1A/vbSSy/l8OHDtG/fnu7duxMfH8+7777L3XffneX+2NhYFi5cSL169di4cSM9e/Zk165dwetvvPEGl11WqBdkwzCMs4bStBivVBGqdOfnqROzXd9Otm1pWnxKdzlFvitoeWfUMYBf1BeqrJcGdFXVA34x34s4jYOoULduXerWdbsqQ+Vvu3fvHvb+du3aBY9bt27Nzz//zNGjR4mJiQl7v2EYRlkmqg29Kd0VidJdXv3SA7fILgb4FzDMz+s/6n1yHvAP4G5VVRFZjlvgdxVO5vYOVV1JNkSkEtmU9VT1rZBbVgFxkXwSoKASuHmVv43E/PnzadeuXZZGftiwYVSoUIEbb7yRcePG4d7pDMMwyiZRa+hFpD1wK9DOP+dLnDDNi8AIP+T9S5yG+tU+2/n+uB+wEOgE3AmsEZFEdbHRx6rqjyJSAbfyu42qbvD5v1fVS30QllE+73jgU1X9g4j0xkuy5kBzXCN5jx+Kn4JT7TsAfCwiA1Q1r3Pkib7+R4FUH2r2JPAIbu/5YZx6Xm7D3jn6Bbe3fRxwraoeEZH/Ae7HNdAzVPUPACLyOtDHlwFOyvZyH/BmPE4uNwuqesy/LFwW4WXkDtzL0RkUhQRuXuRv09PTWbduHRkZWdV409LSGDduHFOnTg2Wc++991K7dm0yMzMZP348mZmZ9OzZM992FRST+nSYHxzmB4f5wREtP0SzRx9UugMQkexKd4H7QsdTF/reZlDpzucNKN0l45Tu7vK218XNlQca+lClu4AaSpfAsap+KCIFUrrzdgSU7vLa0C9R1YM+b0DpLhavdOfT5wHNciknN7/E4fzwmfdrJeBzn/cqEXkQN7JQC7fVMNDQh1MGzDMichWuoe8c7rqqvoh7saN58+b6uyF53hl5BsePH6dPnz6MGDEiizIeQM2aNWnfvn2WeffvvvuOu+66i7fffptOnTqFLXPfvn2sXbu2WFf72upih/nBYX5wmB8c0fJDtOfoIyrdRbg/r0p3Hfz88CzKuNJdtnLC+sWXvVhVs2i6ikhl3IjJZaq60y+IzIu/ckVE2gB/Aa7z8/tRI5L8bSTS09Pp3bs3kyZNytLInzhxgvT0dGJjYzl+/DgffPAB1157xiCGYRhGmSKa2+tWAANF5DwR+QVunjgTr3QHbsGbiLTNR5nhlO7yYscQ/7yCKN11FZFYP1UwGPgkH/nD8YUv83y/L/7GQpYHbp68k4hcAiAiVUSkGacb9e/FhZMt6ELBLOp4ItIANxpwm6puKbjZeSOS/O17771HXFwcn3/+Ob179w4Owc+YMYOtW7cyceLELNvojh49Ss+ePWnTpg2JiYnUr1+f3/zmN9E23zAMo0SJWo9eVb8UkYDS3Q6yKt09LyLjcIvm5pL7HHWgzPUiElC620bele7meBW4T8in0p2IBJTuBPhbUSjdiUhA6W43uSvd5aXM/X7x3xwRCUyFjFPVLSLyEk4ydztOvrYgLAPG+L38k4DuwAXAn/xUwYnCCjrkRCT5W4CBAweekTZu3DjGjRsX9v5169YVqW2GYRilHVPGKwHKgtJdfjFlPIfNRTrMDw7zg8P84DBlvLJFuVa6yy+RlPF+/PFHunfvTtOmTenevTsHDpxeZ7l8+XISExNp3bo1Xbt2Daanp6czaNAgWrRoQcuWLfn888/PeJ5hGEZZolwK5uSkAhfthWVQPEp3BUFEeuK2E4aSpqpnjo8XI5GU8WbNmsU111zDmDFjmDx5MpMnT2bKlCmkp6dzzz33sGjRIho0aJBF5nbkyJH06tWLd955h2PHjpGZmVmCNTMMw4g+pbqhj5Zsbk4qcBHs2E4+ZXNzKyeCbG7UGnW/3z4oY5uDbWf4RURqAr9W1T/584a4xXgVcOsspqvqC9GyPZIy3oIFC4J7TocOHUq3bt2YMmUKb775JjfccAMNGjQAoE6dOgAcOnSIFStWMGvWLAAqVapEpUqVomW2YRhGqaBUN/RnG6GyuXnNU4yyuYlklbHNDzWBe3Bb9QD2AL9S1aN+Nf9GEXnf1yUs0VDG27t3b/AFoG7dusGe+5YtWzh+/DjdunXj8OHDjBw5kttvv51t27ZRu3Zthg0bxvr162nfvj3PPPMMVatWzbddhmEYZwulrqE32dwikc29Cad0dxK3ov9assnY4mLb56mOwGSgiV9XsFhVR4dciyHCWo9oK+OdOHEiy/XA+Y4dO0hNTeXJJ5/k2LFj3HvvvYgImZmZrFu3jqSkJJKSkpg+fTq//e1vGT58eL7tKiimAOYwPzjMDw7zgyNqflDVUvPBSc2m4Bq66sBWnEDOEqCpv+eXwFJ/PAu3PU+A/sAhIAHX8KwDEv19tfx3BWA50Mafbwd+54/vAf7ij58FHvXHvXGCO7ERbG6EE67p6M/r4bbw1ca9SC0FBoQ8L9YfZ4Tk3+iPk3DbBmvg9sDvwEeO83lr4V5IVuKkbSP5MQWo749rhpQ9I+Se/NZxY7a0i3CKhJnAvbn92zZr1kwLw7Fjx7RHjx765JNPBtOaNWumu3fvVlXV3bt3a+AZkyZN0vHjxwfvGz58uL799tu6Z88ebdiwYTB9xYoVev311xfKrvyybNmyYn1eacX84DA/OMwPjnB+ANZqIdvW0rbqPiibq6qHgOyyucnAn3HStwEWemcE5WHVDZ0H5GHByeZ+CfwTaI2Tiw0QTga2CzAbnGwu2aLUhSGsbK6qngACsrl5ZYmqHlTVn3F77BsCl+Nlc1X1ODAvlzI+A2aJyG9wLzfhyG8ds6CqO1W1DXAJMNQLGEUFjaCM169fP1599VUAXn31Vfr3dxK7/fv3Z+XKlZw4cYLMzExWr15Ny5Yt+Y//+A8uuugiAtv8lixZQqtWrc58oGEYRhmi1A3dY7K5hZbNVdURPmBQbyDZL8QLe2vBTMzyrN1ec/9K4J3ClheOgDJeQkICiYmuKo8//jhjxozh5ptv5uWXX6ZBgwbMm+fef1q2bEmvXr1o06YN55xzDnfeeSfx8fEATJ8+nSFDhnDs2DEaN27MK6+8Eg2TDcMwSg2lraFfgeuJTsbZ1hfXg08TkZtUdZ5f8NZGVfOkpkd42dzlebBjCPBYAWVznxGRWFwveTAwPR/5w/EF8JSInI+To70RN4IRFhFpoqqrgdXiYslfRDYZW/JXx+wSuHHAD6r6k7epE/C/BapZHshJGW/JknC7JGH06NGMHj36jPTExETWrl1bpPYZhmGUZkpVQ68mmxupzPzK5k4Tkab++UtwvvqWrDK2ea6jqv4gIp+JyEbcwsOPgSdFRP0znlAfUc8wDMMoZRR2kt8+xfMBqvnvirgwswNL2qb8fAq6GG/YsGFau3Ztbd26dTAtOTlZO3bsqPHx8dqnTx89ePCgqqqmpaVp5cqVtW3bttq2bVu9++67g3nefPNNjY+P14SEBO3Zs6fu37+/QPYUFlt05DA/OMwPDvODo7wsxjMiUy5lc5OSkli0aFGWtDvvvJPJkyeTkpLCwIEDmTZtWvBakyZNSE5OJjk5mRdecBo+J06cYOTIkSxbtowNGzbQpk0bZsyYUaz1MAzDKClKbUMvIhNE5Ayp2BKwY7sPU3uBiCSH+VyQn3L8cYb/ricieVrApqqjVDVRVVuo6n+pqorI2DD2jA3z7EQRub6AdUwRkdHZ7j8Zcv39vNhfULp06UKtWrWypKWmptKli9vI0L17d+bPn59jGYG32iNHjqCqHDp0iHr16kXNZsMwjNJEqZqjL81oLrK5JaGKp04HPy+yuXlSxQtXx4CgDzAtJPknjbwLIiwFUcbLrooXID4+nvfff5/+/fszb948du7cGbyWlpZGu3btqF69Oo899hhXXnkl5557Ls8//zwJCQlUrVqVpk2b8txzz+XLFsMwjLOVUhWmNpwqHi6Ma0mq4vUC2msYnftwqni4Pf9nqOJF0LlvRPGo4m319d9FeFW8nOo4FydGlIpXxQvYH+752fKGKuO1f/Tpl3LLkoWE+jUA+Pe//81DDz0U3Ar37bffMn36dA4ePEinTp149913WbBgAceOHeOnn36iRo0apKam8sgjj/DKK68QExPDgw8+yAMPPEC9evV49tlnqVWrFrfddlu+7CkKMjIyqFYtV9eVecwPDvODw/zgCOeHq666qtBhakt8kVbgg6niJXH2qOKdANYCqwL1y+1TGGW8tLS0LIvxQklNTdUOHTqEvda1a1dds2aNfvHFF3r11VcH0z/55BO97rrrCmxPYbBFRw7zg8P84DA/OMrDYjxTxTtLVPGABureMH8NPO1jERQbgeA1p06d4rHHHmPEiBEA7N+/n5MnTwKwbds2vvnmGxo3bkz9+vXZvHkz+/fvB2Dx4sW0bNmyOE02DMMoMUrbHL2p4p2m1KriqY9Sp6rbRGQ50A74V0HLy4nBgwezfPlyvv/+e+Li4vj9739PRkZGcI79hhtuYNiwYQCsWLGCRx99lIoVK1KhQgVeeOGF4EK+8ePH06VLF84991waNmwYDFVrGIZR1ilNDb2p4oWntKninQ9kqgtRG4tTxZtaoJrlgTlz5oRNHzly5BlpN954IzfeeGPY+0eMGBHs+RuGYZQnSk1Dr6aKF6nM0qaK9x7wZxE5hRtxmayqmwtTR8MwDCN6lJqGHnLcLtYrzL1JIcfbgfgI15IIg6o2CjleC3Tzxz8APUJu/X852JvluT7tTeDNXJ5XLXt+VZ2FW2AYuKdPSPY3VfVFEamIa2g/zsGmG8Ik/4hbPxBKnuroy/x1tqSEnO43DMMwSg+laTGeEZlyqYoHMHz4cOrUqROMPgewfv16rrjiChISEujbty+HDh0C3CK79u3bk5CQQPv27Vm6dGkwz7Fjx7jrrrto1qwZLVq0yFVkxzAMo6xQqnr0pRW/tz5cmLRr/AhAVFHVMxQCvebATdmS5/lRkXxT0nWMRFJSEvfddx+33357MO3OO+/kiSeeoGvXrsycOZNp06YxceJEYmNjWbhwIfXq1WPjxo307NmTXbt2AfDHP/6ROnXqsGXLFk6dOsWPP/5YUlUyDMMoVqyhzwOaiypeSZDDNEdByytUHUWkgqqeLCp7AnTp0oXt27dnScsugduzZ08mTpxIu3btgve0bt2an3/+maNHjxITE8PMmTP5+uuvATjnnHOIjY0talMNwzBKJdbQl0NEZCLwvao+48//COwFYoCb/fd7elpF8K+41fuVgWdU9UWfnoGLQ98TeAD4NNIzi0sCN8D8+fNp164dMTExpKenA/DII4+wfPlymjRpwowZM7jwwgvzZY9hGMbZSKmSwDWKBy+9+66qXioi5+BkdR8GrgHuxq3Yfx+YqqorRKSWqv4oIucBa4CufjW+Areo6tsRnlOsErgB0tLSGDduHFOnTqV+/focPHiQAQMGMGHCBLp27crbb7/N1q1befjhh/NlT1FgUp8O84PD/OAwPzjKvAQjWFA6AAAScElEQVSufYr3AyzGCd30At4BnsBJ7Sb7z1bgDn/vBNw2vfW4rX0Byd8TQIW8PK+4JHB37typTZs21U8//TSYdurUKa1SpYqePHlSVVW//fZbbdWqVYHtKQwm9ekwPzjMDw7zg6M8SOAaxctfcBr4w4CZuF78JHWhcBNV9RJVfVlEuuEC41yhqm1xUsIBdcGfNQrz8rkRSQI3PT2d3r17M2nSJDp16hS8X0To27cvy5cvB2DJkiW0atXqjHINwzDKItbQl1/ew/XmOwAf+c9wEakGICL1RaQOLsjOAVXNFJEWQMfiNHLw4MFcccUVpKamEhcXx8svv8ycOXOC2+Tq1asXlMCdMWMGW7duZeLEiSQmJpKYmBh8KZgyZQoTJkygTZs2vP766zz55JPFWQ3DMIwSwxbjlVNU9ZiILMPFEjgJfCwiLYHPndIwGcB/AouAESKyAReqdlWkMqNBfiRwx40bx7hx48Le37BhQ1asWFGkthmGYZwNWENfTvGL8DoSshdf3Sr8Z8Lcfl24MjQPMekNwzCMksWG7sshItIKt9huiap+U9L2RCKcKt4tt9wSHJZv1KgRiYmnt/5PmjSJSy65hObNm/PRRx8F0xs1akRCQgKJiYlcdlnhFq8ahmGcbViPvhyiLghN45K2IzfCqeK99dZbweMHHniAGjXcFrzNmzczd+5cNm3axO7du7n22mvZsmULFSpUAGDZsmUmkmMYRrnEevSlBBGZJSKDiqisJBGZURRl+fJqisg92dIaiMjHIvKViGz2e/OLlC5dugTjyWdHVXn77bcZPHgwAAsWLODWW28lJiaGiy++mEsuuYQvvviiqE0yDMM467AevZEXagL3AH8KSXsN+KOqLvYr9U/lVEB+lPEiKeKFsnLlSi688EKaNm0KwK5du+jY8fSGgLi4uKDOvYjQo0cPRIS7776bu+66K092GIZhlAWsoY8iIlIVeBuIAyoAE4HmQF/gPOAfwN1eFCE0X3uctGw14HsgSV2s+/8CRuCEajar6q15sKEvMA6oBPwADFHVvSJSGxdO9wKc2l0voL2qfh+mmMlAEx9BbzHwClBRVRcDqGpGhGeHKuPxaMKJ3MwFCO53B6eKd+TIkSxpAE899RSXX355MP27777jq6++Cp7v2bOHTZs2ERsby7Rp04iNjeXAgQOMGjWKn376ibZt2+bJlqImIyPjjLqUR8wPDvODw/zgiJofCqu4Y58c1eduBF4KOa8B1Ao5fx3o649nAYOAc3EvALV9+i3ATH+8G4jxxzVzeG4SMMMfn89pqeM7gSf98QzgIX/cC1AgNkJ5jYCNIecDgA+Ad3ECOtPIRSGvoMp44VTxjh8/rnXq1NGdO3cG0x5//HF9/PHHg+c9evTQf/zjH2eUN378eJ02bVqBbCkKTAHMYX5wmB8c5geHKeOdnaQA14rIFBG5UlUPAleJyGoRSQGuBlpny9MciAcW+x70ONyIAMAG4A0R+U9crz4vxAEf+eeNDnleZ2AugKouAg7ko14VgSuBUTjBnca4l4ti4e9//zstWrQgLi4umNavXz/mzp3L0aNHSUtL45tvvuHyyy/nyJEjHD58GIAjR47w8ccfZ1nFbxiGUdaxhj6KqOoWoD2uwZ8kIo/i5rkHqWoC8BKn5WQDCLBJT0vRJqhqD3+tN/CcL3OdiORl6mU6rnefgAtYE3ieFKJq3wH/VNVtqnoC+CtwaSHKC0s4VTyAuXPnBhfhBWjdujU333wzrVq1olevXjz33HNUqFCBvXv30rlzZ9q2bcvll19O79696dWrV1GbahiGUWqxOfooIiL1gB9VdbYP6ZrkL33vF7ANwgWUCSUVqC0iV6jq5yJyLtAM+Aq4SFWXicinwK9xc/jpuZhRA9jlj4eGpH+KC0k7RUR64Ib4I3EY+EXI+RrgfBGprar7cSMTa3OxI99EUsWbNWtW2PSxY8cyduzYLGmNGzdm/fr1RW2aYRjGWYM19NElAZgmIqeA48BvcfPbKbhIcWuyZ1AnTTsIeFZEauD+jZ4GtgCzfZoAT6lqbo08uMhz80RkF06+9mKf/ntgjojcAnwC7ME16GegLiTtZyKyEfg/VR0tIqOAJeL0ctfhRicMwzCMUoY19FFEVQPBYkJZi5t3z35vUshxMtAlTJGd8/jcWbjFfajqAmBBmNsOAj1V9YSIXAFcpapHcyjz19nOFwNt8mJPQRg+fDgffPABderUYePGjcH06dOnM2PGDCpWrEjv3r2ZOnUqP/zwA4MGDWLNmjUkJSUxY8ZpCYGxY8fy2muvceDAATIywm4OMAzDKNPYHH35pQGwRkTWA88Cv4l0Y3bBHBHpJiIfRNO4pKQkFi1alCVt2bJlLFiwgA0bNrBp0yZGjRoFQOXKlZk4cSJPPPHEGeX07dvXhHMMwyjXWI/+LEZEhgHZw7h9pqr35pZXncZ9u2zlXQAsCXN7EmcK5kSVLl26sH379ixpzz//PGPGjCEmJgaAOnXqAFC1alU6d+7M1q1bzygnVETHMAyjPGIN/VmMqr6CE68JIiKNRORr3GK7jsB6f8/vgTrAEFxAm5m4bXGZwF2qugH4HfClT28APK2qz4rIXLIK5nwIVBORd3BbAdcB/+n3fIalKJTxtmzZwsqVKxk7diyVK1fmiSeeoEOHDnkq0zAMo7xiDX3Z5BJc+Nm7cAv+fo2b3+8HPAzsxG2PGyAiV+PkbANh4FoAV+FW2aeKyPPAGCBeVRPBDd3jRgNa40R8PgM64V4ughRWGS+7Kt7BgwdJSUlh8uTJfP311/Tr148333wTtx4Qvv76a3bt2hVWWerkyZOlQnnLFMAc5geH+cFhfnCYMp598vTBqdh9E3L+Gk72FlxPPRmnZtc45J6duG14E4CxIelf4QR3GpFVGa8bsDjk/Hlcjz6iXQVRxsuuitezZ88sylGNGzfWffv2Bc9feeUVvffee8OWVbVq1Xw/PxqYApjD/OAwPzjMDw5TxjPyQ+jq+VMh56dwozjhxHICw+6heU8SedQnr/cVGQMGDGDp0qWAG8Y/duyYhZ41DMPIBWvoyycrcHP1gWH471X1UA73ZxfMiTrhVPGGDx/Otm3biI+P59Zbb+XVV18NDts3atSI+++/n1mzZhEXF8fmzZsBePDBB4mLiyMzM5O4uDgmTJhQnNUwDMMocWyOvnwyAXhFRDbgFuMNzelmzSaYg1uMF1UiqeLNnj07bHr2FfoBpk6dytSpU4vKLMMwjLMOa+jLGKq6HbcSPnCeFOFa/zB5J2Q7Dy3n19luXx5y7b4CG2wYhmFEFRu6NwzDMIwyjDX0hmEYhlGGsYbeMAzDMMow1tAbhmEYRhnGGnrDMAzDKMOIE94xjOgiIoeB1JK2oxQQC3xf0kaUAswPDvODw/zgCOeHhqpauzCF2vY6o7hIVdXLStqIkkZE1pofzA8BzA8O84MjWn6woXvDMAzDKMNYQ28YhmEYZRhr6I3i4sWSNqCUYH5wmB8c5geH+cERFT/YYjzDMAzDKMNYj94wDMMwyjDW0BuGYRhGGcYaeiPqiEgvEUkVka0iMqak7SkKRGSmiOzzoXsDabVEZLGIfOO/z/fpIiLP+vpvEJFLQ/IM9fd/IyJDQ9Lbi0iKz/OsiEjx1jB3ROQiEVkmIl+JyCYRGenTy5sfKovIFyKy3vvh9z79YhFZ7ev0lohU8ukx/nyrv94opKyHfHqqiPQMST9rfkMiUkFE/ikiH/jzcucHEdnu/98mi8han1ZyvwtVtY99ovYBKgD/AhoDlYD1QKuStqsI6tUFuBTYGJI2FRjjj8cAU/zx9cD/AQJ0BFb79FrANv99vj8+31/7ArjC5/k/4LqSrnMYH9QFLvXHvwC2AK3KoR8EqOaPzwVW+/q9Ddzq018AfuuP7wFe8Me3Am/541b+9xEDXOx/NxXOtt8QcD/wJvCBPy93fgC2A7HZ0krsd2E9eiPaXA5sVdVtqnoMmAv0L2GbCo2qrgB+zJbcH3jVH78KDAhJf00dq4CaIlIX6AksVtUfVfUAsBjo5a9VV9XP1f2qXwspq9SgqntU9Ut/fBj4CqhP+fODqmqGPz3XfxS4GnjHp2f3Q8A/7wDX+B5Zf2Cuqh5V1TRgK+73c9b8hkQkDugN/MWfC+XQDxEosd+FNfRGtKkP7Aw5/86nlUUuVNU94BpBoI5Pj+SDnNK/C5NeavHDru1wvdly5wc/XJ0M7MP9Qf4XkK6qJ/wtobYH6+uvHwQuIP/+KY08DTwInPLnF1A+/aDAxyKyTkTu8mkl9rswCVwj2oSbOypvezoj+SC/6aUSEakGzAf+W1UP5TBdWGb9oKongUQRqQm8B7QMd5v/zm99w3XISp0fRKQPsE9V14lIt0BymFvLtB88nVR1t4jUARaLyNc53Bv134X16I1o8x1wUch5HLC7hGyJNnv9sBr+e59Pj+SDnNLjwqSXOkTkXFwj/4aqvuuTy50fAqhqOrAcN9daU0QCnalQ24P19ddr4KaB8uuf0kYnoJ+IbMcNq1+N6+GXNz+gqrv99z7ci9/llODvwhp6I9qsAZr6lbeVcItu3i9hm6LF+0BgZexQYEFI+u1+dW1H4KAfuvsI6CEi5/sVuD2Aj/y1wyLS0c9Z3h5SVqnB2/Yy8JWq/m/IpfLmh9q+J4+InAdci1uvsAwY5G/L7oeAfwYBS/1c6/vArX41+sVAU9yiq7PiN6SqD6lqnKo2wtm4VFWHUM78ICJVReQXgWPc/+eNlOTvoqRXJ9qn7H9wq0q34OYtx5a0PUVUpznAHuA47g37Dtz84hLgG/9dy98rwHO+/inAZSHlDMctNtoKDAtJv8z/cfgXMAOvYlmaPkBn3JDhBiDZf64vh35oA/zT+2Ej8KhPb4xroLYC84AYn17Zn2/11xuHlDXW1zWVkJXUZ9tvCOjG6VX35coPvr7r/WdTwM6S/F2YBK5hGIZhlGFs6N4wDMMwyjDW0BuGYRhGGcYaesMwDMMow1hDbxiGYRhlGGvoDcMwDKMMYw29YRiFQkRO+ihdgU+jApRRU0TuKXrrguX3K+5oZyIyQERaFeczDSMctr3OMIxCISIZqlqtkGU0wu27js9nvgrq5GdLFV7p7S+4Or2T2/2GEU2sR28YRpHjg7xME5E1Psb23T69mogsEZEvfTztQPSxyUATPyIwTUS6iY9n7vPNEJEkf7xdRB4VkU+Bm0SkiYgs8gFEVopIizD2JInIDH88S0SeF5FlIrJNRLqKyEwR+UpEZoXkyRCRJ72tS0Sktk9PFJFVvl7vyem44stF5HER+QT4H6AfMM3XqYmI/Mb7Y72IzBeRKiH2PCsi//D2DAqx4UHvp/UiMtmn5VpfwwjFgtoYhlFYzhMXuQ0gTVUH4pQCD6pqBxGJAT4TkY9x0bgGqgt+EwusEpH3cfG541U1EUBOB0WJxM+q2tnfuwQYoarfiMgvgT/hdNZz4nx/Tz9gIU6n/U5gjYgkqmoyUBX4UlUfEJFHgfHAfbiwoL9T1U9E5A8+/b99uTVVtau3qykhPXoRSVfVl/zxY95H032+ujilwRY4SdR3ROQ6XPjRX6pqpojU8ve+WID6GuUYa+gNwygsPwUa6BB6AG1Ceqc1cJrl3wGPi0gXXCjT+sCFBXjmWxCMnPcrYJ6cjpoXk4f8C1VVRSQF2KuqKb68TUAjnJzvqcBzgNnAuyJSA9eYf+LTX8XJuGaxKwLxvoGvCVTDaZkH+KuqngI2i0jAH9cCr6hqJoCq/liI+hrlGGvoDcOIBoLr9X6UJdENv9cG2qvqcXGRziqHyX+CrFOL2e854r/PwcU7z/6ikRtH/fepkOPAeaS/i3lZ0HQkh2uzgAGqut77oVsYe+B0GFIJ88yC1tcox9gcvWEY0eAj4LfiwtgiIs18JK8auJjlx0XkKqChv/8w8IuQ/DuAVuIimNUArgn3EFU9BKSJyE3+OSIibYuoDudwOurar4FPVfUgcEBErvTptwGfhMvMmXX6BbDH+2RIHp7/MTA8ZC6/VpTra5RRrKE3DCMa/AXYDHwpIhuBP+N6ym8Al4nIWlxj9zWAqv6Am8ffKCLTVHUn8DYuItwbuOhwkRgC3CEigWhh/XO4Nz8cAVqLyDrcHPgffPpQ3CK7DUBiSHp25gKjReSfItIEeARYDSzG1zsnVHURbr5+rV8DMcpfilZ9jTKKba8zDMMIgxTBtkHDKA1Yj94wDMMwyjDWozcMwzCMMoz16A3DMAyjDGMNvWEYhmGUYayhNwzDMIwyjDX0hmEYhlGGsYbeMAzDMMow/x/WC7Y9knFizgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lgb.Booster(model_file = \"model_12.lgb\")\n",
    "lgb.plot_importance(model, max_num_features = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884079</td>\n",
       "      <td>0.810047</td>\n",
       "      <td>0.665188</td>\n",
       "      <td>0.536858</td>\n",
       "      <td>0.600088</td>\n",
       "      <td>0.608176</td>\n",
       "      <td>0.635881</td>\n",
       "      <td>0.441680</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.849171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648355</td>\n",
       "      <td>1.000473</td>\n",
       "      <td>0.940563</td>\n",
       "      <td>0.713077</td>\n",
       "      <td>0.722681</td>\n",
       "      <td>0.755162</td>\n",
       "      <td>0.816956</td>\n",
       "      <td>0.950633</td>\n",
       "      <td>1.173078</td>\n",
       "      <td>1.068204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676351</td>\n",
       "      <td>0.643886</td>\n",
       "      <td>0.626739</td>\n",
       "      <td>0.570801</td>\n",
       "      <td>0.565174</td>\n",
       "      <td>0.558689</td>\n",
       "      <td>0.504319</td>\n",
       "      <td>0.365608</td>\n",
       "      <td>0.292932</td>\n",
       "      <td>0.287678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301704</td>\n",
       "      <td>0.350675</td>\n",
       "      <td>0.353399</td>\n",
       "      <td>0.281118</td>\n",
       "      <td>0.268107</td>\n",
       "      <td>0.340739</td>\n",
       "      <td>0.328905</td>\n",
       "      <td>0.382318</td>\n",
       "      <td>0.433263</td>\n",
       "      <td>0.430802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368973</td>\n",
       "      <td>0.340823</td>\n",
       "      <td>0.330948</td>\n",
       "      <td>0.328530</td>\n",
       "      <td>0.378835</td>\n",
       "      <td>0.479276</td>\n",
       "      <td>0.408887</td>\n",
       "      <td>0.304108</td>\n",
       "      <td>0.303706</td>\n",
       "      <td>0.286856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638779</td>\n",
       "      <td>0.882802</td>\n",
       "      <td>1.102983</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.826818</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>0.787003</td>\n",
       "      <td>0.812953</td>\n",
       "      <td>0.966192</td>\n",
       "      <td>1.008331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.036799</td>\n",
       "      <td>2.312012</td>\n",
       "      <td>2.175457</td>\n",
       "      <td>2.168854</td>\n",
       "      <td>1.997716</td>\n",
       "      <td>2.361458</td>\n",
       "      <td>2.026224</td>\n",
       "      <td>1.284937</td>\n",
       "      <td>1.521321</td>\n",
       "      <td>1.465837</td>\n",
       "      <td>...</td>\n",
       "      <td>2.127772</td>\n",
       "      <td>2.402758</td>\n",
       "      <td>2.469033</td>\n",
       "      <td>1.978603</td>\n",
       "      <td>1.860428</td>\n",
       "      <td>1.778195</td>\n",
       "      <td>1.556206</td>\n",
       "      <td>2.114291</td>\n",
       "      <td>3.536713</td>\n",
       "      <td>3.493385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.069282</td>\n",
       "      <td>0.757482</td>\n",
       "      <td>0.986796</td>\n",
       "      <td>1.401343</td>\n",
       "      <td>1.421766</td>\n",
       "      <td>1.455440</td>\n",
       "      <td>2.040420</td>\n",
       "      <td>1.514513</td>\n",
       "      <td>1.538276</td>\n",
       "      <td>1.429306</td>\n",
       "      <td>...</td>\n",
       "      <td>1.207285</td>\n",
       "      <td>1.523440</td>\n",
       "      <td>1.578005</td>\n",
       "      <td>1.167557</td>\n",
       "      <td>1.042056</td>\n",
       "      <td>1.059923</td>\n",
       "      <td>1.131947</td>\n",
       "      <td>1.286538</td>\n",
       "      <td>1.661443</td>\n",
       "      <td>1.938959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0  0.884079  0.810047  0.665188  0.536858  0.600088  0.608176  0.635881   \n",
       "1  0.676351  0.643886  0.626739  0.570801  0.565174  0.558689  0.504319   \n",
       "2  0.368973  0.340823  0.330948  0.328530  0.378835  0.479276  0.408887   \n",
       "3  3.036799  2.312012  2.175457  2.168854  1.997716  2.361458  2.026224   \n",
       "4  1.069282  0.757482  0.986796  1.401343  1.421766  1.455440  2.040420   \n",
       "\n",
       "         F8        F9       F10  ...       F19       F20       F21       F22  \\\n",
       "0  0.441680  0.754566  0.849171  ...  0.648355  1.000473  0.940563  0.713077   \n",
       "1  0.365608  0.292932  0.287678  ...  0.301704  0.350675  0.353399  0.281118   \n",
       "2  0.304108  0.303706  0.286856  ...  0.638779  0.882802  1.102983  0.867685   \n",
       "3  1.284937  1.521321  1.465837  ...  2.127772  2.402758  2.469033  1.978603   \n",
       "4  1.514513  1.538276  1.429306  ...  1.207285  1.523440  1.578005  1.167557   \n",
       "\n",
       "        F23       F24       F25       F26       F27       F28  \n",
       "0  0.722681  0.755162  0.816956  0.950633  1.173078  1.068204  \n",
       "1  0.268107  0.340739  0.328905  0.382318  0.433263  0.430802  \n",
       "2  0.826818  0.822888  0.787003  0.812953  0.966192  1.008331  \n",
       "3  1.860428  1.778195  1.556206  2.114291  3.536713  3.493385  \n",
       "4  1.042056  1.059923  1.131947  1.286538  1.661443  1.938959  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = pd.read_csv('model_18_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = testing_df.iloc[0:30490, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = testing_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5750162016266516"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.score(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18415960</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>8.38</td>\n",
       "      <td>6.928186</td>\n",
       "      <td>0.826752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18415961</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.926548</td>\n",
       "      <td>0.737166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18415962</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2.97</td>\n",
       "      <td>1.532861</td>\n",
       "      <td>0.516115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18415963</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>4.64</td>\n",
       "      <td>11.953349</td>\n",
       "      <td>2.576153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18415964</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.475952</td>\n",
       "      <td>0.859705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        date  sell_price    revenue  \\\n",
       "18415960  HOBBIES_1_001_CA_1_validation  2016-04-25        8.38   6.928186   \n",
       "18415961  HOBBIES_1_002_CA_1_validation  2016-04-25        3.97   2.926548   \n",
       "18415962  HOBBIES_1_003_CA_1_validation  2016-04-25        2.97   1.532861   \n",
       "18415963  HOBBIES_1_004_CA_1_validation  2016-04-25        4.64  11.953349   \n",
       "18415964  HOBBIES_1_005_CA_1_validation  2016-04-25        2.88   2.475952   \n",
       "\n",
       "            demand  \n",
       "18415960  0.826752  \n",
       "18415961  0.737166  \n",
       "18415962  0.516115  \n",
       "18415963  2.576153  \n",
       "18415964  0.859705  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>demand_rolling_mean_t5</th>\n",
       "      <th>demand_rolling_std_t5</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19269675</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.480000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269676</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.473000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269677</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.480000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269678</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.342000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3330</td>\n",
       "      <td>1.3660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1430</td>\n",
       "      <td>1.3450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269679</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  revenue  demand                           id  item_id  \\\n",
       "19269675  2016-05-22      0.0       0  FOODS_3_823_WI_3_validation     1432   \n",
       "19269676  2016-05-22      0.0       0  FOODS_3_824_WI_3_validation     1433   \n",
       "19269677  2016-05-22      0.0       0  FOODS_3_825_WI_3_validation     1434   \n",
       "19269678  2016-05-22      0.0       0  FOODS_3_826_WI_3_validation     1435   \n",
       "19269679  2016-05-22      0.0       0  FOODS_3_827_WI_3_validation     1436   \n",
       "\n",
       "          dept_id  cat_id  store_id  state_id  event_name_1  ...  \\\n",
       "19269675        2       0         9         2            30  ...   \n",
       "19269676        2       0         9         2            30  ...   \n",
       "19269677        2       0         9         2            30  ...   \n",
       "19269678        2       0         9         2            30  ...   \n",
       "19269679        2       0         9         2            30  ...   \n",
       "\n",
       "          demand_rolling_mean_t5  demand_rolling_std_t5  sales_lag_t5  \\\n",
       "19269675                     0.4           5.480000e-01           0.0   \n",
       "19269676                     0.2           4.473000e-01           0.0   \n",
       "19269677                     0.4           5.480000e-01           0.0   \n",
       "19269678                     1.6           1.342000e+00           0.0   \n",
       "19269679                     0.0           1.000000e-07           0.0   \n",
       "\n",
       "          demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "19269675                  0.3333                 0.5166           0.0   \n",
       "19269676                  0.1666                 0.4082           0.0   \n",
       "19269677                  0.3333                 0.5166           2.0   \n",
       "19269678                  1.3330                 1.3660           0.0   \n",
       "19269679                  0.0000                 0.0000           0.0   \n",
       "\n",
       "          demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \n",
       "19269675                  0.2856                 0.4880           0.0       0  \n",
       "19269676                  0.1428                 0.3780           0.0       0  \n",
       "19269677                  0.5713                 0.7866           0.0       0  \n",
       "19269678                  1.1430                 1.3450           1.0       0  \n",
       "19269679                  0.0000                 0.0000           0.0       0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out of stock feature stuff, ignore for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_finder(ts):\n",
    "    \n",
    "    #ts: 0 = day with sales, 1 = days with 0 sales\n",
    "    for i, gap in enumerate(ts):\n",
    "        if gap == 0: \n",
    "            continue\n",
    "        elif i!=0: \n",
    "            ts[i] += ts[i-1]\n",
    "            if ts[i-1]!=0: ts[i-1] = -1\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_114_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_114</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.969727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_115_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_115</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.470703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_116_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_116</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_117_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_117</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_118_WI_3_validation</td>\n",
       "      <td>HOBBIES_2_118</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>11407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_114_WI_3_validation  HOBBIES_2_114  HOBBIES_2  HOBBIES     WI_3   \n",
       "1  HOBBIES_2_115_WI_3_validation  HOBBIES_2_115  HOBBIES_2  HOBBIES     WI_3   \n",
       "2  HOBBIES_2_116_WI_3_validation  HOBBIES_2_116  HOBBIES_2  HOBBIES     WI_3   \n",
       "3  HOBBIES_2_117_WI_3_validation  HOBBIES_2_117  HOBBIES_2  HOBBIES     WI_3   \n",
       "4  HOBBIES_2_118_WI_3_validation  HOBBIES_2_118  HOBBIES_2  HOBBIES     WI_3   \n",
       "\n",
       "  state_id  demand   part        date  wm_yr_wk event_name_1 event_type_1  \\\n",
       "0       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "1       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "2       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "3       WI       0  train  2014-03-21     11407          NaN          NaN   \n",
       "4       WI       1  train  2014-03-21     11407          NaN          NaN   \n",
       "\n",
       "  event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0          NaN          NaN        0        0        0    1.969727  \n",
       "1          NaN          NaN        0        0        0    2.470703  \n",
       "2          NaN          NaN        0        0        0    2.970703  \n",
       "3          NaN          NaN        0        0        0    2.769531  \n",
       "4          NaN          NaN        0        0        0    3.970703  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gaps'] = (~(data['demand'] > 0)).astype(int)\n",
    "total_days = 632\n",
    "\n",
    "prods = list(data.id.unique())\n",
    "s_list = [] #list to hold gaps in days\n",
    "e_list = [] #list to hold expected values of gaps\n",
    "p_list = [] #list to hold avg probability of no sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = truncate(data, '2014-05-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752\n"
     ]
    }
   ],
   "source": [
    "print(data['date'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:58<00:00, 170.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for prod_id, df in tqdm(data.groupby(\"id\")):   \n",
    "    # extract gap_series for a prod_id\n",
    "    sales_gaps = df.loc[:,'gaps']\n",
    "\n",
    "    # calculate initial probability\n",
    "    zero_days = sum(sales_gaps)\n",
    "    p = zero_days/total_days\n",
    "\n",
    "    # find and mark gaps\n",
    "    accum_add_prod = np.frompyfunc(lambda x, y: int((x+y)*y), 2, 1)\n",
    "    sales_gaps[:] = accum_add_prod.accumulate(df[\"gaps\"], dtype=np.object).astype(int)\n",
    "    sales_gaps[sales_gaps < sales_gaps.shift(-1)] = np.NaN\n",
    "    sales_gaps = sales_gaps.fillna(method=\"bfill\").fillna(method='ffill')\n",
    "    s_list += [sales_gaps]\n",
    "\n",
    "del sales_gaps\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gap_days'] = pd.concat(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del s_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gap_confirm'] = data['gaps'] * data['gap_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['gap_days']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_stock(data):\n",
    "    out_of_stock = []\n",
    "    sales_dict = {}\n",
    "    for prod_id, df in tqdm(data.groupby(\"id\")):   \n",
    "        # extract gap_series for a prod_id\n",
    "        sales_gaps = df.loc[:,'gap_confirm']\n",
    "        avg_sales = float(df.loc[:, 'demand'].mean())\n",
    "        if (avg_sales != 0):\n",
    "            threshold = 1/(avg_sales) * 20\n",
    "        else:\n",
    "            threshold = 1000\n",
    "              \n",
    "        sales_dict[prod_id] = avg_sales\n",
    "        out_of_stock += [sales_gaps.where(sales_gaps < threshold, np.NaN)]\n",
    "    \n",
    "    data['out_of_stock'] = pd.concat(out_of_stock)\n",
    "    return data, sales_dict\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [01:24<00:00, 361.70it/s] \n"
     ]
    }
   ],
   "source": [
    "data, avg_sales = out_of_stock(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2580.22 Mb (17.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del avg_sales\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['true'] = data['out_of_stock'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['imputed_demand'] = data['demand']\n",
    "\n",
    "rows = data[data.true == True].index\n",
    "for row in rows:\n",
    "    data['imputed_demand'].iloc[row] = data['demand'].iloc[row - (7 * 30490)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2558.36 Mb (3.3% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "item_id\n",
      "dept_id\n",
      "cat_id\n",
      "store_id\n",
      "state_id\n",
      "demand\n",
      "part\n",
      "date\n",
      "wm_yr_wk\n",
      "event_name_1\n",
      "event_type_1\n",
      "event_name_2\n",
      "event_type_2\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "sell_price\n",
      "year\n",
      "month\n",
      "quarter\n",
      "week\n",
      "day\n",
      "dayofweek\n",
      "dayofyear\n",
      "imputed_price\n",
      "scaled_weight\n",
      "date_time\n",
      "totalSnow_cm\n",
      "uvIndex\n",
      "FeelsLikeC\n",
      "HeatIndexC\n",
      "WindChillC\n",
      "WindGustKmph\n",
      "cloudcover\n",
      "humidity\n",
      "precipMM\n",
      "pressure\n",
      "population\n",
      "lag_0\n",
      "lag_1\n",
      "lag_7\n",
      "lag_28\n",
      "shift_1_rolling_mean_7\n",
      "shift_1_rolling_std_7\n",
      "shift_1_rolling_mean_14\n",
      "shift_1_rolling_std_14\n",
      "shift_1_rolling_mean_28\n",
      "shift_1_rolling_std_28\n",
      "shift_7_rolling_std_7\n",
      "shift_7_rolling_std_14\n",
      "shift_7_rolling_std_28\n",
      "shift_7_rolling_mean_7\n",
      "shift_7_rolling_mean_14\n",
      "shift_7_rolling_mean_28\n",
      "lag_3\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       object\n",
      "revenue                   float64\n",
      "demand                      int64\n",
      "id                         object\n",
      "item_id                     int64\n",
      "dept_id                     int64\n",
      "cat_id                      int64\n",
      "store_id                    int64\n",
      "state_id                    int64\n",
      "event_name_1                int64\n",
      "event_type_1                int64\n",
      "event_name_2                int64\n",
      "event_type_2                int64\n",
      "snap_CA                     int64\n",
      "snap_TX                     int64\n",
      "snap_WI                     int64\n",
      "sell_price                float64\n",
      "year                        int64\n",
      "month                       int64\n",
      "quarter                     int64\n",
      "week                        int64\n",
      "day                         int64\n",
      "dayofweek                   int64\n",
      "dayofyear                   int64\n",
      "demand_rolling_mean_t1    float64\n",
      "demand_rolling_std_t1     float64\n",
      "sales_lag_t1              float64\n",
      "demand_rolling_mean_t2    float64\n",
      "demand_rolling_std_t2     float64\n",
      "sales_lag_t2              float64\n",
      "demand_rolling_mean_t3    float64\n",
      "demand_rolling_std_t3     float64\n",
      "sales_lag_t3              float64\n",
      "demand_rolling_mean_t4    float64\n",
      "demand_rolling_std_t4     float64\n",
      "sales_lag_t4              float64\n",
      "demand_rolling_mean_t5    float64\n",
      "demand_rolling_std_t5     float64\n",
      "sales_lag_t5              float64\n",
      "demand_rolling_mean_t6    float64\n",
      "demand_rolling_std_t6     float64\n",
      "sales_lag_t6              float64\n",
      "demand_rolling_mean_t7    float64\n",
      "demand_rolling_std_t7     float64\n",
      "sales_lag_t7              float64\n",
      "season                      int64\n",
      "gaps                        int64\n",
      "gap_days                  float64\n",
      "gap_confirm               float64\n",
      "out_of_stock              float64\n",
      "imputed_demand              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_t5</th>\n",
       "      <th>demand_rolling_mean_t6</th>\n",
       "      <th>demand_rolling_std_t6</th>\n",
       "      <th>sales_lag_t6</th>\n",
       "      <th>demand_rolling_mean_t7</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>sales_lag_t7</th>\n",
       "      <th>season</th>\n",
       "      <th>daily_scales</th>\n",
       "      <th>new_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3658800</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3658801</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4285</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.145767e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3658802</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3658803</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>1.5060</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5720</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.312132e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3658804</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.735425e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             id  item_id  dept_id  cat_id  \\\n",
       "0     3658800  HOBBIES_1_001_CA_1_validation     1437        3       1   \n",
       "1     3658801  HOBBIES_1_002_CA_1_validation     1438        3       1   \n",
       "2     3658802  HOBBIES_1_003_CA_1_validation     1439        3       1   \n",
       "3     3658803  HOBBIES_1_004_CA_1_validation     1440        3       1   \n",
       "4     3658804  HOBBIES_1_005_CA_1_validation     1441        3       1   \n",
       "\n",
       "   store_id  state_id  demand   part        date  ...  sales_lag_t5  \\\n",
       "0         0         0       0  train  2014-08-30  ...           1.0   \n",
       "1         0         0       1  train  2014-08-30  ...           1.0   \n",
       "2         0         0       0  train  2014-08-30  ...           0.0   \n",
       "3         0         0       3  train  2014-08-30  ...           2.0   \n",
       "4         0         0       3  train  2014-08-30  ...           1.0   \n",
       "\n",
       "   demand_rolling_mean_t6  demand_rolling_std_t6  sales_lag_t6  \\\n",
       "0                  0.3333                 0.5166           1.0   \n",
       "1                  0.5000                 0.8364           0.0   \n",
       "2                  0.0000                 0.0000           0.0   \n",
       "3                  1.6670                 1.5060           8.0   \n",
       "4                  0.6665                 0.8164           2.0   \n",
       "\n",
       "   demand_rolling_mean_t7  demand_rolling_std_t7  sales_lag_t7  season  \\\n",
       "0                  0.4285                 0.5347           0.0       1   \n",
       "1                  0.4285                 0.7866           0.0       1   \n",
       "2                  0.0000                 0.0000           0.0       1   \n",
       "3                  2.5720                 2.7600           3.0       1   \n",
       "4                  0.8570                 0.9000           2.0       1   \n",
       "\n",
       "   daily_scales   new_weights  \n",
       "0           0.0  1.000000e-07  \n",
       "1           1.0  2.145767e-06  \n",
       "2           0.0  1.000000e-07  \n",
       "3           1.0  6.312132e-05  \n",
       "4           3.0  9.735425e-06  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "id\n",
      "item_id\n",
      "dept_id\n",
      "cat_id\n",
      "store_id\n",
      "state_id\n",
      "demand\n",
      "part\n",
      "date\n",
      "wm_yr_wk\n",
      "event_name_1\n",
      "event_type_1\n",
      "event_name_2\n",
      "event_type_2\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "sell_price\n",
      "Level_id\n",
      "Agg_Level_1\n",
      "Agg_Level_2\n",
      "weight\n",
      "scale\n",
      "combined\n",
      "year\n",
      "month\n",
      "quarter\n",
      "week\n",
      "day\n",
      "dayofweek\n",
      "dayofyear\n",
      "demand_rolling_mean_t1\n",
      "demand_rolling_std_t1\n",
      "sales_lag_t1\n",
      "demand_rolling_mean_t2\n",
      "demand_rolling_std_t2\n",
      "sales_lag_t2\n",
      "demand_rolling_mean_t3\n",
      "demand_rolling_std_t3\n",
      "sales_lag_t3\n",
      "demand_rolling_mean_t4\n",
      "demand_rolling_std_t4\n",
      "sales_lag_t4\n",
      "demand_rolling_mean_t5\n",
      "demand_rolling_std_t5\n",
      "sales_lag_t5\n",
      "demand_rolling_mean_t6\n",
      "demand_rolling_std_t6\n",
      "sales_lag_t6\n",
      "demand_rolling_mean_t7\n",
      "demand_rolling_std_t7\n",
      "sales_lag_t7\n",
      "season\n",
      "daily_scales\n",
      "new_weights\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['new_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['daily_scales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unmelt(data):\n",
    "    rect = data.pivot(index = 'id', columns = 'date', values = 'demand')\n",
    "    return rect\n",
    "rect = unmelt(data)\n",
    "\n",
    "def add_lags(grid_df, shift):\n",
    "    \n",
    "    lags = [0, 1, 3, 7, 28]\n",
    "    start_time = time()\n",
    "    print( 72 * '#', '\\nAdding lag columns')\n",
    "    for i in lags:\n",
    "        grid_df[f'lag_{i}'] = grid_df['demand'].shift(30490 * (i + shift)).astype(np.float16)\n",
    "    \n",
    "    print(f'Time: {(time() - start_time):.2f} seconds')\n",
    "        \n",
    "        \n",
    "############################################################       \n",
    "################# Rolling window columns ###################\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def make_rolling_col(rw, window, function): \n",
    "    # We need to take off the last columns to\n",
    "    # get the rolling feature shifted one day.\n",
    "    \n",
    "    split_rw = np.split(rw, 10, axis=0)\n",
    "    split_col = [function(rw, -1) for rw in split_rw]\n",
    "    col = np.concatenate(split_col)\n",
    "    col = col[:, :-1].T.reshape(-1,)\n",
    "\n",
    "    # The new column must be prepended with np.nans \n",
    "    # to account for missing gaps\n",
    "    return np.append(np.zeros(30490 * window) + np.nan, col).astype(np.float16)\n",
    "\n",
    "\n",
    "def add_rolling_cols(df: pd.DataFrame, rec: np.array, windows: list, functions: list, function_names: list): \n",
    "    \"\"\"Adds rolling features to df.\"\"\"\n",
    "    \n",
    "    print( 72 * '#', '\\nAdding rolling columns\\n',  )\n",
    "    start_time = time()\n",
    "    f = list(zip(functions, function_names))\n",
    "    \n",
    "    for window in windows: \n",
    "        rw = rolling_window(rec, window)\n",
    "        for function in f: \n",
    "            s_time = time()\n",
    "            df[f'shift_1_rolling_{function[1]}_{str(window)}'] = make_rolling_col(rw, window, function[0])\n",
    "            print(f'{function[1]} with window {window} time: {(time() - s_time):.2f} seconds')\n",
    "            \n",
    "    print(f'Total time for rolling cols: {(time() - start_time)/60:.2f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "############################################################       \n",
    "################# Shifting function ########################\n",
    "def add_shift_cols(grid_df, shifts, cols, num_series=30490): \n",
    "    \n",
    "    print( 72 * '#', '\\nAdding shift columns',  )\n",
    "    start_time = time()\n",
    "    for shift in shifts: \n",
    "        for col in cols: \n",
    "            grid_df[f\"{col.replace('shift_1', f'shift_{shift}')}\"] = grid_df[col].shift((shift - 1) * num_series)\n",
    "    print(f'Time: {(time() - start_time):.2f} seconds')\n",
    "\n",
    "\n",
    "         \n",
    "            \n",
    "############################################################       \n",
    "################# Create lags df ###########################\n",
    "def make_lags_df_1(data, rec): \n",
    "    \n",
    "    start_time = time()\n",
    "\n",
    "    window = 7\n",
    "    add_lags(data, window)\n",
    "    add_rolling_cols(data, \n",
    "                     rec, \n",
    "                     windows=[7, 14, 28], \n",
    "                     functions=[np.mean, np.std], \n",
    "                     function_names=['mean', 'std'])\n",
    "    \n",
    "    \n",
    "    shifts = [7]\n",
    "    cols = [f'shift_1_rolling_std_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, cols, num_series=30490)\n",
    "    ocols = [f'shift_1_rolling_mean_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, ocols, num_series=30490)\n",
    "    \n",
    "    print(72 * '#', f'Total time: {(time() - start_time)//60:} : {(time() - start_time)%60:.2f}')\n",
    "    return data\n",
    "\n",
    "def make_lags_df_2(data, rec): \n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    window = 14\n",
    "    add_lags(data, window)\n",
    "    add_rolling_cols(data, \n",
    "                     rec, \n",
    "                     windows=[7, 14, 28], \n",
    "                     functions=[np.mean, np.std], \n",
    "                     function_names=['mean', 'std'])\n",
    "    \n",
    "    \n",
    "    shifts = [14]\n",
    "    cols = [f'shift_1_rolling_std_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, cols, num_series=30490)\n",
    "    ocols = [f'shift_1_rolling_mean_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, ocols, num_series=30490)\n",
    "    \n",
    "    print(72 * '#', f'Total time: {(time() - start_time)//60:} : {(time() - start_time)%60:.2f}')\n",
    "    return data\n",
    "\n",
    "def make_lags_df_3(data, rec): \n",
    "    \n",
    "    start_time = time()\n",
    "\n",
    "    window = 21\n",
    "    add_lags(data, window)\n",
    "    add_rolling_cols(data, \n",
    "                     rec, \n",
    "                     windows=[7, 14, 28], \n",
    "                     functions=[np.mean, np.std], \n",
    "                     function_names=['mean', 'std'])\n",
    "    \n",
    "    \n",
    "    shifts = [21]\n",
    "    cols = [f'shift_1_rolling_std_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, cols, num_series=30490)\n",
    "    ocols = [f'shift_1_rolling_mean_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, ocols, num_series=30490)\n",
    "    \n",
    "    print(72 * '#', f'Total time: {(time() - start_time)//60:} : {(time() - start_time)%60:.2f}')\n",
    "    return data\n",
    "\n",
    "def make_lags_df_4(data, rec): \n",
    "    \n",
    "    start_time = time()\n",
    "\n",
    "    \n",
    "    window = 28\n",
    "    add_lags(data, window)\n",
    "    add_rolling_cols(data, \n",
    "                     rec, \n",
    "                     windows=[7, 14, 28], \n",
    "                     functions=[np.mean, np.std], \n",
    "                     function_names=['mean', 'std'])\n",
    "    \n",
    "    \n",
    "    shifts = [28]\n",
    "    cols = [f'shift_1_rolling_std_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, cols, num_series=30490)\n",
    "    ocols = [f'shift_1_rolling_mean_{i}' for i in [7, 14, 28]]\n",
    "    add_shift_cols(data, shifts, ocols, num_series=30490)\n",
    "    \n",
    "    print(72 * '#', f'Total time: {(time() - start_time)//60:} : {(time() - start_time)%60:.2f}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1427.82 Mb (54.7% reduction)\n",
      "######################################################################## \n",
      "Adding lag columns\n",
      "Time: 2.57 seconds\n",
      "######################################################################## \n",
      "Adding rolling columns\n",
      "\n",
      "mean with window 7 time: 1.74 seconds\n",
      "std with window 7 time: 3.35 seconds\n",
      "mean with window 14 time: 1.84 seconds\n",
      "std with window 14 time: 5.34 seconds\n",
      "mean with window 28 time: 2.10 seconds\n",
      "std with window 28 time: 8.36 seconds\n",
      "Total time for rolling cols: 0.38\n",
      "######################################################################## \n",
      "Adding shift columns\n",
      "Time: 0.16 seconds\n",
      "######################################################################## \n",
      "Adding shift columns\n",
      "Time: 0.18 seconds\n",
      "######################################################################## Total time: 0.0 : 25.65\n",
      "Mem. usage decreased to 1928.89 Mb (0.0% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = transform(data)\n",
    "gc.collect()\n",
    "\n",
    "from time import time \n",
    "\n",
    "rec = unmelt(data)\n",
    "rec = rec.values\n",
    "data = make_lags_df(data, rec)\n",
    "data = truncate(data, '2014-07-01')\n",
    "data = reduce_mem_usage(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_1_rolling_mean_14</th>\n",
       "      <th>shift_1_rolling_std_14</th>\n",
       "      <th>shift_1_rolling_mean_28</th>\n",
       "      <th>shift_1_rolling_std_28</th>\n",
       "      <th>shift_28_rolling_std_7</th>\n",
       "      <th>shift_28_rolling_std_14</th>\n",
       "      <th>shift_28_rolling_std_28</th>\n",
       "      <th>shift_28_rolling_mean_7</th>\n",
       "      <th>shift_28_rolling_mean_14</th>\n",
       "      <th>shift_28_rolling_mean_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3112500</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>11422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>0.673828</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>1.641602</td>\n",
       "      <td>1.288086</td>\n",
       "      <td>1.166992</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>0.643066</td>\n",
       "      <td>0.821289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112501</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>11422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.795410</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.089844</td>\n",
       "      <td>4.558594</td>\n",
       "      <td>3.507812</td>\n",
       "      <td>2.677734</td>\n",
       "      <td>3.285156</td>\n",
       "      <td>2.214844</td>\n",
       "      <td>1.571289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112502</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>11422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772461</td>\n",
       "      <td>0.600586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.178589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112503</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>11422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>0.451660</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.214233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112504</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>11422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.118164</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>1.049805</td>\n",
       "      <td>0.903320</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.464355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  item_id  dept_id  cat_id  store_id  \\\n",
       "3112500  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "3112501  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "3112502  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3112503  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "3112504  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "         state_id  demand   part       date  wm_yr_wk  ...  \\\n",
       "3112500         0       0  train 2014-07-02     11422  ...   \n",
       "3112501         0       0  train 2014-07-02     11422  ...   \n",
       "3112502         0       0  train 2014-07-02     11422  ...   \n",
       "3112503         0       1  train 2014-07-02     11422  ...   \n",
       "3112504         0       0  train 2014-07-02     11422  ...   \n",
       "\n",
       "         shift_1_rolling_mean_14  shift_1_rolling_std_14  \\\n",
       "3112500                 0.785645                0.673828   \n",
       "3112501                 0.714355                0.795410   \n",
       "3112502                 0.000000                0.000000   \n",
       "3112503                 0.285645                0.588867   \n",
       "3112504                 0.500000                1.118164   \n",
       "\n",
       "         shift_1_rolling_mean_28  shift_1_rolling_std_28  \\\n",
       "3112500                 0.893066                0.938965   \n",
       "3112501                 0.750000                1.089844   \n",
       "3112502                 0.035706                0.185547   \n",
       "3112503                 0.250000                0.508789   \n",
       "3112504                 0.392822                0.899902   \n",
       "\n",
       "         shift_28_rolling_std_7  shift_28_rolling_std_14  \\\n",
       "3112500                1.641602                 1.288086   \n",
       "3112501                4.558594                 3.507812   \n",
       "3112502                0.000000                 0.772461   \n",
       "3112503                0.451660                 0.410400   \n",
       "3112504                1.049805                 0.903320   \n",
       "\n",
       "         shift_28_rolling_std_28  shift_28_rolling_mean_7  \\\n",
       "3112500                 1.166992                 1.142578   \n",
       "3112501                 2.677734                 3.285156   \n",
       "3112502                 0.600586                 0.000000   \n",
       "3112503                 0.410400                 0.285645   \n",
       "3112504                 0.905762                 0.571289   \n",
       "\n",
       "         shift_28_rolling_mean_14  shift_28_rolling_mean_28  \n",
       "3112500                  0.643066                  0.821289  \n",
       "3112501                  2.214844                  1.571289  \n",
       "3112502                  0.214233                  0.178589  \n",
       "3112503                  0.214233                  0.214233  \n",
       "3112504                  0.428467                  0.464355  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del temp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = data['id'].unique()\n",
    "num_days = data['date'].nunique()\n",
    "merger = []\n",
    "for id_name in id_list:\n",
    "    for i in range(num_days):\n",
    "        merger.append(id_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2652.00 Mb (6.5% reduction)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'HOBBIES_2_114_WI_3_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b5dfd4b55335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_mem_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[1;32m   4918\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlexsort_indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4920\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4921\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexsort_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4918\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlexsort_indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4920\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4921\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexsort_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled4/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HOBBIES_2_114_WI_3_validation'"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "data = data.sort_values(by = merger)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = data['date'].nunique()\n",
    "\n",
    "index_list = []\n",
    "for i in range(30490):\n",
    "        index = i\n",
    "        index_list.append(i)\n",
    "        for j in range(num_days - 1):\n",
    "            index += (30490)\n",
    "            index_list.append(index)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = truncate(data, '2014-04-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>FeelsLikeC</th>\n",
       "      <th>HeatIndexC</th>\n",
       "      <th>WindChillC</th>\n",
       "      <th>WindGustKmph</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>1014</td>\n",
       "      <td>27511000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1018</td>\n",
       "      <td>27511476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>11409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1013</td>\n",
       "      <td>27511950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-05</td>\n",
       "      <td>11410</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015</td>\n",
       "      <td>27512424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>11410</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1019</td>\n",
       "      <td>27512900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "2  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "3  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "4  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "\n",
       "   state_id  demand   part       date  wm_yr_wk  ...  uvIndex  FeelsLikeC  \\\n",
       "0         0       0  train 2014-04-02     11409  ...        1           4   \n",
       "1         0       0  train 2014-04-03     11409  ...        1           9   \n",
       "2         0       0  train 2014-04-04     11409  ...        1          10   \n",
       "3         0       0  train 2014-04-05     11410  ...        1           8   \n",
       "4         0       0  train 2014-04-06     11410  ...        1          14   \n",
       "\n",
       "   HeatIndexC  WindChillC  WindGustKmph  cloudcover  humidity  precipMM  \\\n",
       "0           8           4            29          10        49  0.199951   \n",
       "1          10           9            19          25        39  0.000000   \n",
       "2          12          10            22          22        32  0.000000   \n",
       "3          10           8            26           3        49  0.000000   \n",
       "4          15          14            11           1        29  0.000000   \n",
       "\n",
       "   pressure  population  \n",
       "0      1014  27511000.0  \n",
       "1      1018  27511476.0  \n",
       "2      1013  27511950.0  \n",
       "3      1015  27512424.0  \n",
       "4      1019  27512900.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843180\n"
     ]
    }
   ],
   "source": [
    "print(len(index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843179\n"
     ]
    }
   ],
   "source": [
    "print(index_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23843175</th>\n",
       "      <td>24181085</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843176</th>\n",
       "      <td>24181086</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843177</th>\n",
       "      <td>24181087</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843178</th>\n",
       "      <td>24181088</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843179</th>\n",
       "      <td>24181089</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>test1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index                           id      item_id  dept_id cat_id  \\\n",
       "23843175  24181085  FOODS_3_823_WI_3_validation  FOODS_3_823  FOODS_3  FOODS   \n",
       "23843176  24181086  FOODS_3_824_WI_3_validation  FOODS_3_824  FOODS_3  FOODS   \n",
       "23843177  24181087  FOODS_3_825_WI_3_validation  FOODS_3_825  FOODS_3  FOODS   \n",
       "23843178  24181088  FOODS_3_826_WI_3_validation  FOODS_3_826  FOODS_3  FOODS   \n",
       "23843179  24181089  FOODS_3_827_WI_3_validation  FOODS_3_827  FOODS_3  FOODS   \n",
       "\n",
       "         store_id state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "23843175     WI_3       WI       0  test1 2016-05-22     11617          NaN   \n",
       "23843176     WI_3       WI       0  test1 2016-05-22     11617          NaN   \n",
       "23843177     WI_3       WI       0  test1 2016-05-22     11617          NaN   \n",
       "23843178     WI_3       WI       0  test1 2016-05-22     11617          NaN   \n",
       "23843179     WI_3       WI       0  test1 2016-05-22     11617          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "23843175          NaN          NaN          NaN        0        0        0   \n",
       "23843176          NaN          NaN          NaN        0        0        0   \n",
       "23843177          NaN          NaN          NaN        0        0        0   \n",
       "23843178          NaN          NaN          NaN        0        0        0   \n",
       "23843179          NaN          NaN          NaN        0        0        0   \n",
       "\n",
       "          sell_price  \n",
       "23843175    2.980469  \n",
       "23843176    2.480469  \n",
       "23843177    3.980469  \n",
       "23843178    1.280273  \n",
       "23843179    1.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1955.52 Mb (32.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "del data['level_0']\n",
    "data = transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 272.86 Mb (25.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "data['sell_price'] = data['sell_price'].astype('float32')\n",
    "data = impute_price(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = pd.read_csv('weight_scale_1914.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "level12 = wdf[wdf.Level_id == 'Level12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del wdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>weight</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>12350</td>\n",
       "      <td>Level12</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>1.972157e-05</td>\n",
       "      <td>2.922071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12351</th>\n",
       "      <td>12351</td>\n",
       "      <td>Level12</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>1.852632e-05</td>\n",
       "      <td>5.740586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12352</th>\n",
       "      <td>12352</td>\n",
       "      <td>Level12</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>1.434296e-05</td>\n",
       "      <td>10.198222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12353</th>\n",
       "      <td>12353</td>\n",
       "      <td>Level12</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>5.378610e-06</td>\n",
       "      <td>1.019362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12354</th>\n",
       "      <td>12354</td>\n",
       "      <td>Level12</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>5.976234e-07</td>\n",
       "      <td>3.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 Level_id  Agg_Level_1 Agg_Level_2        weight      scale\n",
       "12350       12350  Level12  FOODS_1_001        CA_1  1.972157e-05   2.922071\n",
       "12351       12351  Level12  FOODS_1_001        CA_2  1.852632e-05   5.740586\n",
       "12352       12352  Level12  FOODS_1_001        CA_3  1.434296e-05  10.198222\n",
       "12353       12353  Level12  FOODS_1_001        CA_4  5.378610e-06   1.019362\n",
       "12354       12354  Level12  FOODS_1_001        TX_1  5.976234e-07   3.461538"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d8192eb016c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlevel12Weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m30490\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30490\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaled_weight' is not defined"
     ]
    }
   ],
   "source": [
    "def level12Weighted(y_pred, y_true, scaled_weight = scaled_weight):\n",
    "    y_true = y_true.get_label()\n",
    "    num_days = int(len(y_pred) / 30490)\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    for i in range(30490): \n",
    "        residual[i * num_days:(i+1) * num_days] = scaled_weight[i * num_days:(i+1) * num_days] * residual[i * num_days:(i+1) * num_days]\n",
    "\n",
    "    grad = -10 * residual\n",
    "    hess = 10 * np.ones(residual.shape)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupByDay(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    num_days = int(len(y_pred) / 30490)\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.zeros(y_pred.shape)\n",
    "    hess = np.zeros(y_pred.shape)\n",
    "    for i in range(num_days):\n",
    "        all_series = residual[range(i, total, num_days)]\n",
    "        grad[range(i, total, num_days)] -= all_series.sum() / (30490 * 2.0)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined1(y_pred, y_true):\n",
    "    l12grad, l12hess = level12Weighted(y_pred, y_true)\n",
    "    groupgrad, grouphess = groupByDay(y_pred, y_true)\n",
    "    return l12grad + groupgrad, l12hess + grouphess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level1Weight(y_pred, y_true, weight = weight, scale = scale):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    num_days = int(len(y_pred) / 30490)\n",
    "    res_1 = []\n",
    "    for i in len(num_days):\n",
    "        tempsum = 0\n",
    "        tracker = 0\n",
    "        index_list = [i] \n",
    "        index = i\n",
    "        while (tracker < 30490):\n",
    "            tracker += 1\n",
    "            tempsum += residual[i]\n",
    "            index += num_days\n",
    "            index_list.append[index]\n",
    "            \n",
    "        for index in index_list:\n",
    "            residual[index] = tempsum * weight / np.sqrt(scale)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = truncate(data, '2014-03-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33010</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>11408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33011</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>11408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33012</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>11408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33013</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>11408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33014</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>11408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        item_id    dept_id   cat_id  \\\n",
       "33010  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "33011  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "33012  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "33013  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "33014  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "\n",
       "      store_id state_id  demand   part       date  wm_yr_wk event_name_1  \\\n",
       "33010     CA_1       CA       0  train 2014-03-23     11408          NaN   \n",
       "33011     CA_1       CA       0  train 2014-03-23     11408          NaN   \n",
       "33012     CA_1       CA       0  train 2014-03-23     11408          NaN   \n",
       "33013     CA_1       CA       2  train 2014-03-23     11408          NaN   \n",
       "33014     CA_1       CA       1  train 2014-03-23     11408          NaN   \n",
       "\n",
       "      event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "33010          NaN          NaN          NaN        0        0        0   \n",
       "33011          NaN          NaN          NaN        0        0        0   \n",
       "33012          NaN          NaN          NaN        0        0        0   \n",
       "33013          NaN          NaN          NaN        0        0        0   \n",
       "33014          NaN          NaN          NaN        0        0        0   \n",
       "\n",
       "       sell_price  \n",
       "33010    8.257812  \n",
       "33011    3.970703  \n",
       "33012    2.970703  \n",
       "33013    4.640625  \n",
       "33014    3.080078  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
